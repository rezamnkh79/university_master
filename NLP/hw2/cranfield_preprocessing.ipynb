{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import tarfile\n",
    "import re\n",
    "\n",
    "folder_path = ''\n",
    "# Step 1: Extract the .tar.gz file\n",
    "with tarfile.open(folder_path+\"cran.tar.gz\", \"r:\") as tar:\n",
    "    tar.extractall(folder_path+\"cranfield_dataset\")\n",
    "\n",
    "# Paths to the extracted files\n",
    "docs_path = folder_path+\"cranfield_dataset/cran.all.1400\"\n",
    "queries_path = folder_path+\"cranfield_dataset/cran.qry\"\n",
    "qrels_path = folder_path+\"cranfield_dataset/cranqrel\"\n",
    "\n",
    "# Step 1: Load documents from 'cran.all.1400'\n",
    "documents = {}\n",
    "with open(docs_path, 'r') as file:\n",
    "    content = file.read()\n",
    "    docs = re.split(r\"\\.I \", content)[1:]  # Split by document identifier prefix\n",
    "    for doc in docs:\n",
    "        lines = doc.splitlines()\n",
    "        doc_id = lines[0].strip()\n",
    "        doc_text = \"\\n\".join(lines[2:])  # Skip .T and first line for title/author, rest is content\n",
    "        documents[doc_id] = doc_text\n",
    "\n",
    "# Step 2: Load queries from 'cran.qry'\n",
    "queries = {}\n",
    "with open(queries_path, 'r') as file:\n",
    "    content = file.read()\n",
    "    qry_sections = re.split(r\"\\.I \", content)[1:]  # Split by query identifier prefix\n",
    "    for idx, qry in enumerate(qry_sections):\n",
    "        lines = qry.splitlines()\n",
    "        query_text = \"\\n\".join(lines[2:])  # Skip the first 2 lines to get query text\n",
    "        queries[idx + 1] = query_text  # Use a continuous index from 1 to total count\n",
    "\n",
    "# Step 3: Load and remap relevance judgments from 'cranqrel'\n",
    "relevance_judgments = {i + 1: set() for i in range(len(queries))}\n",
    "# query_id_map = {old_id: new_id for new_id, old_id in enumerate(sorted(queries.keys()), start=1)}\n",
    "\n",
    "with open(qrels_path, 'r') as file:\n",
    "    for line in file:\n",
    "        query_id, doc_id, relevance = map(int, line.split())\n",
    "        # new_query_id = query_id_map.get(query_id)\n",
    "        if query_id and relevance >= 2:  # Only consider relevance >= 2\n",
    "            relevance_judgments[query_id].add(str(doc_id))\n",
    "\n",
    "# Step 4: Define qrels_defs() and metadata() equivalents\n",
    "def qrels_defs():\n",
    "    print(\"Qrels Definitions:\")\n",
    "    print(\"0: Not Relevant\")\n",
    "    print(\"1: Marginally Relevant\")\n",
    "    print(\"2: Relevant\")\n",
    "    print(\"3: Highly Relevant\")\n",
    "\n",
    "def metadata(documents, queries, relevance_judgments):\n",
    "    print(\"Dataset Metadata:\")\n",
    "    print(f\"Total number of documents: {len(documents)}\")\n",
    "    print(f\"Total number of queries: {len(queries)}\")\n",
    "    total_rels = sum(len(docs) for docs in relevance_judgments.values())\n",
    "    print(f\"Total number of relevance judgments: {total_rels}\")\n",
    "    print(f\"Average judgments per query: {total_rels / len(queries):.2f}\")\n",
    "\n",
    "# Call the functions to print qrels definitions and metadata\n",
    "qrels_defs()\n",
    "metadata(documents, queries, relevance_judgments)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qFIY856MlZ9a",
    "outputId": "b370fa90-7f9e-4dfe-eb7a-97b22e76e49c",
    "ExecuteTime": {
     "end_time": "2024-11-05T13:11:40.794439Z",
     "start_time": "2024-11-05T13:11:40.747718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qrels Definitions:\n",
      "0: Not Relevant\n",
      "1: Marginally Relevant\n",
      "2: Relevant\n",
      "3: Highly Relevant\n",
      "Dataset Metadata:\n",
      "Total number of documents: 1400\n",
      "Total number of queries: 225\n",
      "Total number of relevance judgments: 1484\n",
      "Average judgments per query: 6.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15888/982564107.py:7: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(folder_path+\"cranfield_dataset\")\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ]
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlrrsi07MDhO"
   },
   "source": [
    "<h1 dir=\"rtl\" style=\"font-family: Vazir; width: 85%;\">ØªÙ…Ø±ÛŒÙ† Ø´Ù…Ø§Ø±Ù‡ 4: Ø¯Ø±Ø³ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ - Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØªÙ‡Ø±Ø§Ù†ØŒ Ù¾Ø§Ø¦ÛŒØ² Û±Û´Û°Û³</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T42xpmfrMDhQ"
   },
   "source": [
    "<div dir=\"rtl\" style=\"font-family: Vazir; width: 85%; font-size: 18px;\">\n",
    "Ù†Ø§Ù…:\n",
    "<br/>\n",
    "Ø´Ù…Ø§Ø±Ù‡ Ø¯Ø§Ù†Ø´Ø¬ÙˆÛŒÛŒ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58azWVGxMDhQ"
   },
   "source": [
    "<div dir=\"rtl\" style=\"font-family: Vazir; width: 85%; font-size: 16px;\">\n",
    "Ø³ÙˆØ§Ù„Ø§Øª Ø®ÙˆØ¯ØªØ§Ù† Ø±Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø·Ø±ÛŒÙ‚ Ø§ÛŒÙ…ÛŒÙ„\n",
    "<code>ali.fartout@ut.ac.ir</code>\n",
    " Ø§Ø² Ø·Ø±Ø§Ø­ ØªÙ…Ø±ÛŒÙ† 4 Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„ Ø§ÙˆÙ„ Ø¨Ù¾Ø±Ø³ÛŒØ¯."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foW-gR1HMDhR"
   },
   "source": [
    "<div dir=\"rtl\" style=\"font-family: Vazir; width: 85%; font-size: 18px; color: red; font-weight: bold;\">\n",
    "Ù‚ÙˆØ§Ù†ÛŒÙ† Ùˆ ØªÙˆØ¶ÛŒØ­Ø§ØªÛŒ Ø¢Ø®Ø± ÙØ§ÛŒÙ„ ØªÙ…Ø±ÛŒÙ† Ø­ØªÙ…Ø§ Ø¨Ù‡ Ø¯Ù‚Øª Ù…Ø·Ø§Ù„Ø¹Ù‡ Ø´ÙˆØ¯.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYOgIt4psPHa"
   },
   "source": [
    "# **Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡:**"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T19:49:09.007528Z",
     "start_time": "2024-12-24T19:49:09.004184Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"https://chatgpt.com/share/676b101d-c81c-8006-b803-720db788fa81\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://chatgpt.com/share/676b101d-c81c-8006-b803-720db788fa81\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1rN-aSosPHa"
   },
   "source": [
    "*Ø¨Ø®Ø´ Ø§ÙˆÙ„:*\n",
    "---\n",
    "# Ù¾Ø§Ø³Ø® Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:45:12.367413Z",
     "start_time": "2024-12-14T17:44:56.263522Z"
    },
    "vscode": {
     "languageId": "plaintext"
    },
    "id": "73CHDYfysPHb"
   },
   "outputs": [],
   "source": [
    "#write your code here\n",
    "from datasets import load_dataset\n",
    "\n",
    "persian_dataset = load_dataset(\"AliFartout/PEYMA-ARMAN-Mixed\")\n",
    "english_dataset = load_dataset(\"conll2003\", trust_remote_code=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T16:21:58.914155Z",
     "start_time": "2024-12-14T16:21:58.905648Z"
    },
    "id": "CDFJ7sMOsPHb",
    "outputId": "05388f60-20fd-4667-cb32-d60b43b13d4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ØªØ±Ú©ÛŒØ¨ Ø¯ÛŒØªØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ Ùˆ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ø§ Ú†Ø§Ù„Ø´â€ŒÙ‡Ø§ÛŒÛŒ Ú†ÙˆÙ† Ù†Ø§Ù‡Ù…Ø§Ù‡Ù†Ú¯ÛŒ Ø¯Ø± ÙØ±Ù…Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ØŒ Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ØŒ Ùˆ ØªÙØ§ÙˆØªâ€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ Ù…Ø§Ù†Ù†Ø¯ Ù†ÙˆØ´ØªØ§Ø± Ø±Ø§Ø³Øª Ø¨Ù‡ Ú†Ù¾ Ùˆ Ú©Ù„Ù…Ø§Øª Ù…Ø±Ú©Ø¨ Ù‡Ù…Ø±Ø§Ù‡ Ø§Ø³Øª. Ù‡Ù…Ú†Ù†ÛŒÙ†ØŒ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø²Ø¨Ø§Ù† Ùˆ Ù…Ø´Ú©Ù„Ø§Øª ØªÙˆÚ©Ù†â€ŒØ³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†Ø¯. Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø§Ù†Ø´ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø²Ø¨Ø§Ù† Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø§Ø¹Ø« Ú©Ø§Ù‡Ø´ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø´ÙˆØ¯ØŒ Ùˆ ØªÙØ§ÙˆØªâ€ŒÙ‡Ø§ÛŒ ÙØ±Ù‡Ù†Ú¯ÛŒ Ùˆ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¨ÛŒÙ† Ø¯Ùˆ Ø²Ø¨Ø§Ù† Ù†ÛŒØ² Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ù‡ Ú†Ø§Ù„Ø´ Ø¨Ú©Ø´Ø¯. Ø¯Ø± Ù†Ù‡Ø§ÛŒØªØŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„ Ø¯Ø± Ø¯Ùˆ Ø²Ø¨Ø§Ù† Ù…Ø®ØªÙ„Ù Ø¨Ø§ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù…ØªÙØ§ÙˆØª Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ù‚Øª Ø±Ø§ ØªØ­Øª ØªØ§Ø«ÛŒØ± Ù‚Ø±Ø§Ø± Ø¯Ù‡Ø¯.                                                         \n",
      "\n",
      "Ø±Ø§Ù‡ Ø­Ù„:                                                                         \n",
      "Ø¨Ø±Ø§ÛŒ ÛŒÚ©Ø³Ø§Ù†â€ŒØ³Ø§Ø²ÛŒ ÙØ±Ù…Øªâ€ŒÙ‡Ø§ØŒ Ø§Ø¨ØªØ¯Ø§ Ø¯ÛŒØªØ§Ø³Øªâ€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø§ Ù‡Ù… ØªØ·Ø§Ø¨Ù‚ Ù…ÛŒØ¯Ù‡ÛŒÙ… Ùˆ ÙØ±Ù…Øªâ€ŒÙ‡Ø§ Ø±Ø§ ÛŒÚ©Ø³Ø§Ù† Ù…ÛŒÚ©Ù†ÛŒÙ…. Ø³Ù¾Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ ÙØ±Ù…Øª BIO ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒÚ©Ù†ÛŒÙ…. Ø¨Ø¹Ø¯ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø²Ø´ØŒ Ø¯ÛŒØªØ§Ø³Øªâ€ŒÙ‡Ø§ Ø±Ø§ Ù…Ø±Ø¬ Ù…ÛŒÚ©Ù†ÛŒÙ… ØªØ§ ÛŒÚ© Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ø´ÙˆØ¯. Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø²Ø¨Ø§Ù†ØŒ ØªÙˆÚ©Ù†â€ŒØ³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø±Ø§ Ø§Ø¹Ù…Ø§Ù„ Ú©Ø±Ø¯Ù‡ ØªØ§ Ù…Ø¯Ù„ Ø¨ØªÙˆØ§Ù†Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ Ù…Ø®ØªÙ„Ù Ø±Ø§ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†Ø¯. Ø¯Ø± Ù†Ù‡Ø§ÛŒØªØŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ ØªØ¹Ø§Ø¯Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ØŒ Ù…Ø´Ú©Ù„Ø§Øª Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„  Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ Ø±Ø§ Ø±ÙØ¹ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ù‡ÛŒØ¯.                                     \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "ØªØ±Ú©ÛŒØ¨ Ø¯ÛŒØªØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ Ùˆ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ø§ Ú†Ø§Ù„Ø´â€ŒÙ‡Ø§ÛŒÛŒ Ú†ÙˆÙ† Ù†Ø§Ù‡Ù…Ø§Ù‡Ù†Ú¯ÛŒ Ø¯Ø± ÙØ±Ù…Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ØŒ Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ØŒ Ùˆ ØªÙØ§ÙˆØªâ€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ Ù…Ø§Ù†Ù†Ø¯ Ù†ÙˆØ´ØªØ§Ø± Ø±Ø§Ø³Øª Ø¨Ù‡ Ú†Ù¾ Ùˆ Ú©Ù„Ù…Ø§Øª Ù…Ø±Ú©Ø¨ Ù‡Ù…Ø±Ø§Ù‡ Ø§Ø³Øª. Ù‡Ù…Ú†Ù†ÛŒÙ†ØŒ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø²Ø¨Ø§Ù† Ùˆ Ù…Ø´Ú©Ù„Ø§Øª ØªÙˆÚ©Ù†â€ŒØ³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†Ø¯. Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø§Ù†Ø´ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø²Ø¨Ø§Ù† Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø§Ø¹Ø« Ú©Ø§Ù‡Ø´ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø´ÙˆØ¯ØŒ Ùˆ ØªÙØ§ÙˆØªâ€ŒÙ‡Ø§ÛŒ ÙØ±Ù‡Ù†Ú¯ÛŒ Ùˆ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¨ÛŒÙ† Ø¯Ùˆ Ø²Ø¨Ø§Ù† Ù†ÛŒØ² Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ù‡ Ú†Ø§Ù„Ø´ Ø¨Ú©Ø´Ø¯. Ø¯Ø± Ù†Ù‡Ø§ÛŒØªØŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„ Ø¯Ø± Ø¯Ùˆ Ø²Ø¨Ø§Ù† Ù…Ø®ØªÙ„Ù Ø¨Ø§ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù…ØªÙØ§ÙˆØª Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ù‚Øª Ø±Ø§ ØªØ­Øª ØªØ§Ø«ÛŒØ± Ù‚Ø±Ø§Ø± Ø¯Ù‡Ø¯.\n",
    "\n",
    "Ø±Ø§Ù‡ Ø­Ù„:\n",
    "Ø¨Ø±Ø§ÛŒ ÛŒÚ©Ø³Ø§Ù†â€ŒØ³Ø§Ø²ÛŒ ÙØ±Ù…Øªâ€ŒÙ‡Ø§ØŒ Ø§Ø¨ØªØ¯Ø§ Ø¯ÛŒØªØ§Ø³Øªâ€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø§ Ù‡Ù… ØªØ·Ø§Ø¨Ù‚ Ù…ÛŒØ¯Ù‡ÛŒÙ… Ùˆ ÙØ±Ù…Øªâ€ŒÙ‡Ø§ Ø±Ø§ ÛŒÚ©Ø³Ø§Ù† Ù…ÛŒÚ©Ù†ÛŒÙ…. Ø³Ù¾Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ ÙØ±Ù…Øª BIO ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒÚ©Ù†ÛŒÙ…. Ø¨Ø¹Ø¯ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø²Ø´ØŒ Ø¯ÛŒØªØ§Ø³Øªâ€ŒÙ‡Ø§ Ø±Ø§ Ù…Ø±Ø¬ Ù…ÛŒÚ©Ù†ÛŒÙ… ØªØ§ ÛŒÚ© Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ø´ÙˆØ¯. Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø²Ø¨Ø§Ù†ØŒ ØªÙˆÚ©Ù†â€ŒØ³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø±Ø§ Ø§Ø¹Ù…Ø§Ù„ Ú©Ø±Ø¯Ù‡ ØªØ§ Ù…Ø¯Ù„ Ø¨ØªÙˆØ§Ù†Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ Ù…Ø®ØªÙ„Ù Ø±Ø§ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†Ø¯. Ø¯Ø± Ù†Ù‡Ø§ÛŒØªØŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ ØªØ¹Ø§Ø¯Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ØŒ Ù…Ø´Ú©Ù„Ø§Øª Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„  Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ Ø±Ø§ Ø±ÙØ¹ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ù‡ÛŒØ¯.\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52tAk_6dMWnF"
   },
   "source": [
    "# **Ø³ÙˆØ§Ù„ Ø§ÙˆÙ„:**"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install datasets"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZrAiEJAOvyt",
    "outputId": "938ac1eb-2917-434e-d04c-c13d4a28c9fe"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m480.6/480.6 kB\u001B[0m \u001B[31m14.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m116.3/116.3 kB\u001B[0m \u001B[31m11.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m179.3/179.3 kB\u001B[0m \u001B[31m19.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m134.8/134.8 kB\u001B[0m \u001B[31m15.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m194.1/194.1 kB\u001B[0m \u001B[31m16.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkAAw0haMdyS"
   },
   "source": [
    "*Ø¨Ø®Ø´ Ø§ÙˆÙ„:*\n",
    "---\n",
    "# Ù¾Ø§Ø³Ø® Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:58:19.972756Z",
     "start_time": "2024-12-16T11:58:02.601079Z"
    },
    "id": "WpB_Eep5MDhR",
    "vscode": {
     "languageId": "plaintext"
    },
    "outputId": "74fe2dc9-e122-48c3-8c7b-42fd62ea4783",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905,
     "referenced_widgets": [
      "7caada25255a4a2ea79fd4946350ce6f",
      "bcabe00f8cd44488a60fe2ef9720d544",
      "4be3c92d41484d9990e2f427f70c05fb",
      "3e7ea66a14d344e29137dfa1b70ae242",
      "78152d8d7f4d42f082d958eefff2c456",
      "d6702447046f4c0eb22443e46b8d267c",
      "fd5f54010d134e788b24dedaff4a245c",
      "e88f13cba91d469b908a97a2c349c401",
      "c123173aa3fb48fd842c3d432e0c1852",
      "573cb53a00784628b8b1a70e9b44a819",
      "591ecaf181ce46998684df7398bd0d04",
      "1204782198724a6489a97a1360def9b7",
      "c2288099b79b4f01b989110606af3f99",
      "5258ad3d9c614684901455cdccca5464",
      "0081b87457d74ff296ccf0bf7a44c1ea",
      "c29abfebe6d64184aec032e1fc5f386a",
      "6866f5e2121c45c99056d17aff0389e3",
      "6223496a27a74c018d32c640def1602c",
      "e192f92c737245bcb543ade156c17734",
      "6591d105216c4cffad68fe6a9f08b5e0",
      "8691d7f7c463456e8d8a61edd8e14424",
      "180a7f59f3504de39ceeaf196c344349",
      "9e2a6aaa33ea48579b2e48156809677e",
      "56752dbb306c491b96950db734080ea6",
      "5f4b7c1b6638482e9f91ff02350f796c",
      "f444c7714a3e497b974bb6cba3f94f0f",
      "f0b196963d82478cbfaeb8952f226d40",
      "b76e1b20069349b385b879c3a508683d",
      "c27391262e87428b97bf2af3c9ebf4f8",
      "4be7077397484a66be454d94fdb7d29a",
      "c53e5ad6d48c42879c70286d8b5e026d",
      "76dcb0f4857f4b00ae053048bc7b2439",
      "c3bc90276a734f058b59568bdbf5cb76",
      "0b384c1a1fe04a88b99402d863be256b",
      "ee8a859a7e3f4051af73afe3596284c6",
      "472d3e34c7be4f7ab1880cc1a2590ec3",
      "0e71556a6d18400daa83b898c37fbfc8",
      "066074ed0023419fa79c3dc0735836ef",
      "bc734652ac54484ba21e111aa1124b7c",
      "1219365db1ee430e820c57cc69766d21",
      "45ff2cd9367448208c03418cccb1e163",
      "676acf218792492eae3b6a76fd27a76f",
      "3ea4a612a0c44b8d9e403e31665b6ee8",
      "b4932ec1661f419cbe9355bf0213a4a3",
      "5773a61f5e83417b87da26415ed9f64e",
      "e301df9235a14e21b912aee03994bc54",
      "f2daa4e9e411415ca1d16879be88d1d6",
      "f9ba0df5051149a29f4a3ba34c6b17f7",
      "a306af4e7f5d4ed5a0e695b6cba1438f",
      "dd068ea7c9d84b54aa7c2d08e93e0c55",
      "d5ff20bcb8304853aad3a37bd8d62206",
      "88c543eac77548f9a568c04d95026500",
      "09800f60c0ac4fc8b80fb8ed792ae5df",
      "39bb3ee089844427b02fd004abe24fb2",
      "9c732a1cc6a64c89950a69b5b3ca3f7e",
      "351b7477ea0049a6852f0cc80c64f785",
      "72ab6d70b7c7432a840a691e267ea7f8",
      "6d15bbf859de4125a090d4dfc7e52d91",
      "4bcf1637435c4b3eb7840bb3a309a50a",
      "a1ce14a7425d477bb45ce7d417dc21fb",
      "8ff0cbc21fdb4733972f56ac299c12dc",
      "0b4672e88cea4a7bbf3d7c5b035c3367",
      "3dde3fbd007941bb94e814586a556a73",
      "5f254fa72f6f4e9281da4fbbaa1e8ec5",
      "8a5d4411b8244d79bd515f563ee07f91",
      "81ac9011c8ef4cffb1a6f7ca8eca94f6",
      "efef75d0e65c4048b6cf3dbf600e1503",
      "e8b4ec3474a14e2e893feac4b0429d33",
      "c2afb53b64ff42fdbbca34b950072055",
      "c365d5e6d609433aa4f5777f70fdfa13",
      "0ebc9049dce948faac4eb677ead240c8",
      "33b97d361e5640e791e455878cd72afb",
      "40f17fa1eb3248b8b725b4333173a5ff",
      "2ab0ea6224964bbab151ebef3c6ef23c",
      "2d1a9ce408094d1dbf00bfb87a068b73",
      "7bfaaff485e64f7fb4bba5a42f33b629",
      "cb08945e33c14d88b9cf82ca58e357e2",
      "6e1cb8126fd34316a399d45119233698",
      "a8c13cd56ad445a3a0eee1944d616b54",
      "823ff306347e4b89a922914b2e799d20",
      "d3d120d6aab1489bba742bed82be3663",
      "980d1bf3e8b34d6d85df0126020ee64f",
      "bd14e958c84e4975bc8391ae766833b0",
      "6bbfe0e4aafd4b0a889167a1120b9957",
      "6ee55133e5ea479d9582a8ecc4b68074",
      "93ff055c233f4074b698547455cf85cf",
      "df4a322fdbd04a10860c8a3d03b8e584",
      "c7bfaf4f6a0742c4ab71ae2151646c3f",
      "5b5d45d3637448c8a379fa31de96fe33",
      "660d1ba3ad464a1fb05562852893acee",
      "970e5a5684a64ee7ba5ebf9f0e3db14c",
      "6356ea46d8674dab9b9eb610e30e5247",
      "af26c7aed95240dfadc723d799153e70",
      "cc4fef0370ab42ea8ddeb0fc65a3b6db",
      "1dd751001a6c49fb908c0d82cef674ea",
      "93ffbea052b24d4fb4371a8a7d964db6",
      "e3f71056b3f6478f96c66f21bd1966ec",
      "f210ca931aa44d83a9cb4e38d20d85cf",
      "d8773a146c85401eaca7b27e2e60f521",
      "2a1cad5fde8f4cb6a5b7113f3668499b",
      "ca4da00629df41b19ca878ccc50c3d47",
      "6170cfb70e344f04bda70ee1b6e06d1a",
      "d1c789f25bba4bac9fade77b51f1a8ba",
      "d15765fa3759480d8d4a20f3076140e4",
      "c2c138db0ab148f7a675173b658f25a2",
      "0538617c89204a4d81c51eab56ec8b20",
      "b6ab15911ade4ab49c254f2d35ec526a",
      "22633176e9cd45bba5c5f40b82323ac2",
      "6c94f00ff7314a0088f85abf3cb6ca30",
      "e10ff2bfcafe4b958e0f2ebacb449692",
      "e78555d73b4d4b219e8f24b051f3cb9a",
      "ee755bbe9772403aa8fb11cc38e1b527",
      "ccee26c5278f43c2a6d905d64d681834",
      "dd6d881ab3d64210bf33879d8b7f26d9",
      "8a68efc546af451e9ddc97acc1212843",
      "d7e08ab0594948829138409404fcc159",
      "22b61430c18d490a9e2da6dd6c908f15",
      "75b0d5cbdfcf4ed29f4a1c66f45a0a56",
      "b5cdb8fdc5114ffda6d6f6f9811b80af",
      "a37ddf293b074744b167aaec6010b0ad",
      "fa4e4fbee31946db97c9b920043285b7",
      "efa64a232dd447b98d04dc484c20ac16",
      "642f89f482924223a6dc0a9cb44567c2",
      "e93ead4cb03d4dec88dad637fa73b01e",
      "57ad02fe9363477cba106bf18b05a738",
      "01db17a99d5540dd81f2d4841452945f",
      "4302b9fb8ed0470b8a53755aade7b080",
      "c5dc97f74d0545d8b6833737e67c1274",
      "8d6fd2c7600e45178cd8ec8fd21e15c3",
      "6ced072c075d4d44aee0b6e9260f383d",
      "8fba092d15b941bebe7f054729d3d88d",
      "ccfc5899af0d4ae78e3ac10f4ec9c25f",
      "e79b8697b65f487b81268f8f966546c1",
      "39be24d48be94c509700c1196bf6f992",
      "624b8f69d3804ffe8a49143ea91f90cc",
      "770e519121c34cf9abe80d1d4b84a0a2",
      "e95fd5d405f74514a571ee3e71a7dda2",
      "11117652e28047d988aa4897766c58f8",
      "9733c58d2941491e868db3a3c6448209",
      "aa601664bdae4d1cab1709dce8b7677f",
      "2ddd0ee8cbe443a7916e791db747bbd0",
      "b071c191fa8947cdbe9dbd0c3bd36ef9",
      "6de100dda56c456b9aa75162a8cef5c6"
     ]
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/3.27k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7caada25255a4a2ea79fd4946350ce6f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/3.31M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1204782198724a6489a97a1360def9b7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/431k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e2a6aaa33ea48579b2e48156809677e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/423k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b384c1a1fe04a88b99402d863be256b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/26384 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5773a61f5e83417b87da26415ed9f64e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating validation split:   0%|          | 0/3296 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "351b7477ea0049a6852f0cc80c64f785"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/3296 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efef75d0e65c4048b6cf3dbf600e1503"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Persian Dataset Columns: ['tokens', 'ner_tags', 'ner_tags_names']\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/12.3k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e1cb8126fd34316a399d45119233698"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "conll2003.py:   0%|          | 0.00/9.57k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b5d45d3637448c8a379fa31de96fe33"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The repository for conll2003 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2003.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N] y\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a1cad5fde8f4cb6a5b7113f3668499b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e78555d73b4d4b219e8f24b051f3cb9a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efa64a232dd447b98d04dc484c20ac16"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e79b8697b65f487b81268f8f966546c1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "English Dataset Columns: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags']\n",
      "Combined Dataset Sample:\n",
      "                                              tokens  \\\n",
      "0  ÛŒÙˆÚ©ÙˆÙˆÛŒÚ† Ù…ØªÙˆÙ„Ø¯ Ø¯Ø§Ù†Ù…Ø§Ø±Ú© Ø§Ø³Øª Ø§Ù…Ø§ ÙˆØ§Ù„Ø¯ÛŒÙ† Ø§Ùˆ ØµØ±Ø¨ Ù‡Ø³...   \n",
      "1  0 Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡ Ø§ÛŒØ±Ø§Ù†ÛŒ Ø§Ø² Ø§ÙˆÚ©ÛŒ Ù‡Ø§Ø±Ùˆ ÛŒØ§Ø³ÙˆØ§Ø¦ÙˆÚ©Ø§ ÙˆØ²ÛŒØ± Ø¯...   \n",
      "2  ÙˆÙŠ Ø¨Ø§ Ø¨ÛŒØ§Ù† Ø§ÛŒÙ† ÙƒÙ‡ Ù‚Ø±Ø§Ø± Ø´Ø¯ Ø®Ø¨Ø±Ú¯Ø§Ù† Ù…Ù„Øª Ù…ÙˆØ§Ø¸Ø¨Øª Ø¨ÛŒ...   \n",
      "3  Ø¨Ù‡ Ú¯Ø²Ø§Ø±Ø´ Ø§ÛŒØ³Ù†Ø§ ØŒ Ø§Ø·Ù‡Ø±Ù‡ Ù†Ú˜Ø§Ø¯ÛŒ Ù…Ø¹Ø§ÙˆÙ† Ù‡Ù…Ø§Ù‡Ù†Ú¯ÛŒ Ùˆ Ø¨...   \n",
      "4  Ø¨Ù‡ Ú¯Ø²Ø§Ø±Ø´ Ø®Ø¨Ø±Ù†Ú¯Ø§Ø± Ù¾Ø§Ø±Ù„Ù…Ø§Ù†ÛŒ Ø§ÛŒØ³Ù†Ø§ ØŒ ØªØ±Ú©ÛŒØ¨ Ø§Ø¹Ø¶Ø§ÛŒ ...   \n",
      "\n",
      "                                            ner_tags  \n",
      "0                         5 20 1 20 20 20 20 1 20 20  \n",
      "1  20 20 20 20 5 12 12 20 3 10 20 20 20 20 20 20 ...  \n",
      "2  20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 2...  \n",
      "3  20 20 3 20 5 12 20 20 20 20 3 10 20 20 20 20 5...  \n",
      "4  20 20 20 20 3 20 20 20 3 10 10 10 20 20 20 20 ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_persian_dataset = load_dataset(\"AliFartout/PEYMA-ARMAN-Mixed\", split=\"train\")\n",
    "\n",
    "print(\"Persian Dataset Columns:\", train_persian_dataset.column_names) \n",
    "\n",
    "persian_df = pd.DataFrame({\n",
    "    'tokens': [' '.join(tokens) for tokens in train_persian_dataset['tokens']],\n",
    "    'ner_tags': [' '.join(map(str, tags)) for tags in train_persian_dataset['ner_tags']],  \n",
    "})\n",
    "\n",
    "train_english_dataset = load_dataset(\"conll2003\", split=\"train\")\n",
    "\n",
    "print(\"English Dataset Columns:\",\n",
    "      train_english_dataset.column_names) \n",
    "\n",
    "english_df = pd.DataFrame({\n",
    "    'tokens': [' '.join(tokens) for tokens in train_english_dataset['tokens']],  \n",
    "    'ner_tags': [' '.join(map(str, tags)) for tags in train_english_dataset['ner_tags']], \n",
    "})\n",
    "train_combined_df = pd.concat([persian_df, english_df], ignore_index=True)\n",
    "print(\"Combined Dataset Sample:\")\n",
    "print(train_combined_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5vi1eJVMkCH"
   },
   "source": [
    "*Ø¨Ø®Ø´ Ø¯ÙˆÙ…:*\n",
    "---\n",
    "# Ù¾Ø§Ø³Ø® Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhQuXmbUsPHd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1f2d8c1c-d305-49fa-bc36-2eadb1e3169e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Ú†Ø±Ø§ Ø¨Ø§ÛŒØ¯ Alignment Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯\n",
      "Ø¯Ø± Ù…Ø³Ø§Ø¦Ù„ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ØªÙˆÚ©Ù† (Ù…Ø§Ù†Ù†Ø¯ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡)ØŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± ØªÙ‚Ø³ÛŒÙ… ØªÙˆÚ©Ù† Ø¨Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©â€ŒØªØ± Ù…Ù…Ú©Ù† Ø§Ø³Øª ÛŒÚ© Ú©Ù„Ù…Ù‡ Ø±Ø§ Ø¨Ù‡ Ú†Ù†Ø¯ÛŒÙ† ØªÙˆÚ©Ù† ØªÙ‚Ø³ÛŒÙ… Ú©Ù†Ù†Ø¯ØŒ Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¨Ø§ ØªØ¹Ø¯Ø§Ø¯ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ Ù‡Ù…Ø§Ù‡Ù†Ú¯ Ù†ÛŒØ³Øª. Ø§ÛŒÙ† Ø§Ù…Ø± Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù‡Ù…â€ŒØ±Ø§Ø³ØªØ§ÛŒÛŒ Ø¯Ø§Ø±Ø¯ØŒ ÛŒØ¹Ù†ÛŒ ØªØ®ØµÛŒØµ ØµØ­ÛŒØ­ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ Ø¨Ù‡ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§. ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ ÙØ±Ø¹ÛŒ Ø¨Ø§ÛŒØ¯ ÙÙ‚Ø· Ø¨Ø±Ú†Ø³Ø¨ Ú©Ù„Ù…Ù‡ Ø§ØµÙ„ÛŒ Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†Ù†Ø¯ Ùˆ Ø¨Ù‚ÛŒÙ‡ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ Ù…Ù‚Ø¯Ø§Ø±ÛŒ Ù…Ø´Ø®Øµ Ø¨Ø±Ú†Ø³Ø¨â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø´ÙˆÙ†Ø¯. Ù‡Ù…Ú†Ù†ÛŒÙ†ØŒ Ù‡Ù†Ú¯Ø§Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù¾Ø¯ÛŒÙ†Ú¯ØŒ Ø¨Ø§ÛŒØ¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ø±Ø¯ Ú©Ù‡ Ù¾Ø¯ÛŒÙ†Ú¯â€ŒÙ‡Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø®Ø·Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´ÙˆÙ†Ø¯.\n",
      "\n",
      "Ø±Ø§Ù‡ Ø­Ù„ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ùˆ Ú†Ú¯ÙˆÙ†Ú¯ÛŒ Ø­Ù„ Ù…Ø´Ú©Ù„\n",
      "Ø¨Ø±Ø§ÛŒ Ø­Ù„ Ù…Ø´Ú©Ù„ Ù‡Ù…â€ŒØ±Ø§Ø³ØªØ§ÛŒÛŒ Ø¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ØªÙˆÚ©Ù†ØŒ Ø§Ø¨ØªØ¯Ø§ Ù…ØªÙˆÙ† Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÙˆÚ©Ù†Ø§ÛŒØ²Ø± ØªÙ‚Ø³ÛŒÙ…â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø¨Ù‡ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©â€ŒØªØ± ØªÙ‚Ø³ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…. Ø³Ù¾Ø³ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ø¯Ù‚ÛŒÙ‚ Ø¨Ù‡ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ù‡Ø± Ú©Ù„Ù…Ù‡ Ø§Ø®ØªØµØ§Øµ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ Ùˆ Ø¨Ø±Ø§ÛŒ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ ÙØ±Ø¹ÛŒ Ø¨Ø±Ú†Ø³Ø¨ ÙˆÛŒÚ˜Ù‡â€ŒØ§ÛŒ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ… ØªØ§ Ù…Ø¯Ù„ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ø¨Ú¯ÛŒØ±Ø¯. Ø¯Ø± Ù†Ù‡Ø§ÛŒØªØŒ Ù¾Ø¯ÛŒÙ†Ú¯â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø®Ø·Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ… ØªØ§ ØªØ£Ø«ÛŒØ±ÛŒ Ø¨Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯. Ø§ÛŒÙ† ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ø§Ø¹Ø« Ù‡Ù…â€ŒØ±Ø§Ø³ØªØ§ÛŒÛŒ ØµØ­ÛŒØ­ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ùˆ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ù…Ø¯Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Ú†Ø±Ø§ Ø¨Ø§ÛŒØ¯ Alignment Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯\n",
    "Ø¯Ø± Ù…Ø³Ø§Ø¦Ù„ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ØªÙˆÚ©Ù† (Ù…Ø§Ù†Ù†Ø¯ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡)ØŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± ØªÙ‚Ø³ÛŒÙ… ØªÙˆÚ©Ù† Ø¨Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©â€ŒØªØ± Ù…Ù…Ú©Ù† Ø§Ø³Øª ÛŒÚ© Ú©Ù„Ù…Ù‡ Ø±Ø§ Ø¨Ù‡ Ú†Ù†Ø¯ÛŒÙ† ØªÙˆÚ©Ù† ØªÙ‚Ø³ÛŒÙ… Ú©Ù†Ù†Ø¯ØŒ Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¨Ø§ ØªØ¹Ø¯Ø§Ø¯ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ Ù‡Ù…Ø§Ù‡Ù†Ú¯ Ù†ÛŒØ³Øª. Ø§ÛŒÙ† Ø§Ù…Ø± Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù‡Ù…â€ŒØ±Ø§Ø³ØªØ§ÛŒÛŒ Ø¯Ø§Ø±Ø¯ØŒ ÛŒØ¹Ù†ÛŒ ØªØ®ØµÛŒØµ ØµØ­ÛŒØ­ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ Ø¨Ù‡ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§. ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ ÙØ±Ø¹ÛŒ Ø¨Ø§ÛŒØ¯ ÙÙ‚Ø· Ø¨Ø±Ú†Ø³Ø¨ Ú©Ù„Ù…Ù‡ Ø§ØµÙ„ÛŒ Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†Ù†Ø¯ Ùˆ Ø¨Ù‚ÛŒÙ‡ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ Ù…Ù‚Ø¯Ø§Ø±ÛŒ Ù…Ø´Ø®Øµ Ø¨Ø±Ú†Ø³Ø¨â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø´ÙˆÙ†Ø¯. Ù‡Ù…Ú†Ù†ÛŒÙ†ØŒ Ù‡Ù†Ú¯Ø§Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù¾Ø¯ÛŒÙ†Ú¯ØŒ Ø¨Ø§ÛŒØ¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ø±Ø¯ Ú©Ù‡ Ù¾Ø¯ÛŒÙ†Ú¯â€ŒÙ‡Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø®Ø·Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´ÙˆÙ†Ø¯.\n",
    "\n",
    "Ø±Ø§Ù‡ Ø­Ù„ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ùˆ Ú†Ú¯ÙˆÙ†Ú¯ÛŒ Ø­Ù„ Ù…Ø´Ú©Ù„\n",
    "Ø¨Ø±Ø§ÛŒ Ø­Ù„ Ù…Ø´Ú©Ù„ Ù‡Ù…â€ŒØ±Ø§Ø³ØªØ§ÛŒÛŒ Ø¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ØªÙˆÚ©Ù†ØŒ Ø§Ø¨ØªØ¯Ø§ Ù…ØªÙˆÙ† Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÙˆÚ©Ù†Ø§ÛŒØ²Ø± ØªÙ‚Ø³ÛŒÙ…â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø¨Ù‡ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©â€ŒØªØ± ØªÙ‚Ø³ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…. Ø³Ù¾Ø³ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ø¯Ù‚ÛŒÙ‚ Ø¨Ù‡ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ù‡Ø± Ú©Ù„Ù…Ù‡ Ø§Ø®ØªØµØ§Øµ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ Ùˆ Ø¨Ø±Ø§ÛŒ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ ÙØ±Ø¹ÛŒ Ø¨Ø±Ú†Ø³Ø¨ ÙˆÛŒÚ˜Ù‡â€ŒØ§ÛŒ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ… ØªØ§ Ù…Ø¯Ù„ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ø¨Ú¯ÛŒØ±Ø¯. Ø¯Ø± Ù†Ù‡Ø§ÛŒØªØŒ Ù¾Ø¯ÛŒÙ†Ú¯â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø®Ø·Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ… ØªØ§ ØªØ£Ø«ÛŒØ±ÛŒ Ø¨Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯. Ø§ÛŒÙ† ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ø§Ø¹Ø« Ù‡Ù…â€ŒØ±Ø§Ø³ØªØ§ÛŒÛŒ ØµØ­ÛŒØ­ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ùˆ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ù…Ø¯Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-16T11:59:40.466970Z"
    },
    "jupyter": {
     "is_executing": true
    },
    "id": "YJuIhL_OsPHd",
    "outputId": "62e1f4a8-220a-465d-ea24-ed2b35d0f0ac",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e90d96525b434f2e91736d030129b935",
      "fc1215796e3c4e2588a922ee7e5a0d8c",
      "5a1c0565b3574d3d826f597942aeacc6",
      "8b641f0a4b664c048fb4dc63d3152e21",
      "52f616c9e004473e891376d48d3b034f",
      "99cf32c1b07c4b0a966f3e9359e03a89",
      "8006ce3b7b8740b7a31d0f2878695da0",
      "77692a74cf9d4b18bb6abef4f4c01b06",
      "65cc0c0f112647df89cda1ce613e057b",
      "853df5f5b24a487eab1eb212d953cad4",
      "b0b6aa3442b642c19a83a69e1f098efd",
      "ce8fabadfb0b49c399264e03c5c80512",
      "a2f33b7c0b8148ba87c35c29a032b837",
      "1a4bd0c6b90744058263256a92f85fb4",
      "38b1f2749c2c491e8178ff727eeceb63",
      "351f39be330f45c69372637194c370af",
      "ce713fc43e414c3b82b33a0c29a32db9",
      "c1f857b71c554182be6412cf74bc29c4",
      "fc96f05b39514f2fa1f9556f3ff26722",
      "0e5455fcda034a7c96ff6ff473fdbd89",
      "3195f2f67e33454bbca7f19c9c5fbd0a",
      "be656821ff4748199a15d0dd4bd166dc",
      "1b8c2e9cad9a4f6a945f94ea5cf531e2",
      "fdf8b0fa4e0e4d8da06aed72c9561f6a",
      "d255dfb86b4d462e84883acad0cd1cbb",
      "f75b8522cea143fc86eca83aab1b18bf",
      "980e3c44abbd49cc852af65838efe594",
      "b3f0f4e29b484597af7fbc7241740cc4",
      "762d54fc44444633acef4634b8ecf849",
      "7f476ceb4a404b55878fde3ab336c6d4",
      "8bb5fab06baf426081ad003ed56ecf3a",
      "f5e47ee35b874ba6a7f435a1b1fd8c55",
      "995fc8fed17e43dca6b6a8b634c063d8",
      "b778bb683adc4a96ae39a98c4f348b6d",
      "2d57fbffabdd4014b250141a3598c59c",
      "26ca477c68084b938aed846905ab07ff",
      "c6383433cf40443a8d94068c463d318c",
      "a4ff9e79ab244fd1998b87ca3af31779",
      "c752a7d2e29a40379165ecc78c95900b",
      "bff1276dee3141fb89a25b0260e98160",
      "59feaf523a1c4f1d9e4a80a45989cafc",
      "2384fda426f54d03a57d620a0ac3058f",
      "7be3b29483f8492c93ba4a6844f28e09",
      "a894ef720a464d97aa058d692986a2d2",
      "135ad4f73aa14752aef9f17395f141ed",
      "9119f811bbb74dafa56c716b9ac7ab7d",
      "011ef2810e604f638e1b6409c5da3e12",
      "0ef9fefd6cce471ba7b7c1f6388c22b0",
      "8de229941d9349c7995e9784a3435cb5",
      "192b22f0af3f4a669f118d1146472898",
      "2685df12faf84d50abcbc0f8d831eec8",
      "1ac0975ac6834d8084337138df628829",
      "f8cdb01566444ebf91bff5b033bc8458",
      "cac20a4b199d4129aff696b17af4cc69",
      "f762c14507bf4af99c449bbb01992f24",
      "05ca30b2b0a8417986902dcfb4be483d",
      "31a500ef0eb8433bb3c6adc06a28a68e",
      "313cfcef43f14fdab8658988443938a5",
      "8486b3704212407a9c87d5f548f7e36a",
      "957f1247667249bca7f6397a16b69ce6",
      "dfe113f5e0ad4162a76db9d6dc4d6e55",
      "e1892d6ebc714348bbc6794c17693ff6",
      "b49958cceae6434988bdff8808443546",
      "c9bfd2dfbd1f4a46b24b6df332e95a3a",
      "24535e1ab4944c3280b5a8e26cab0eae",
      "3a0986e168f84358ba6c4b505a0eacbe"
     ]
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e90d96525b434f2e91736d030129b935"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce8fabadfb0b49c399264e03c5c80512"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b8c2e9cad9a4f6a945f94ea5cf531e2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b778bb683adc4a96ae39a98c4f348b6d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "135ad4f73aa14752aef9f17395f141ed"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05ca30b2b0a8417986902dcfb4be483d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "<ipython-input-6-bc3e3f0d7a02>:155: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20241223_155930-bokndk6y</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rezamansourikhah-student/huggingface/runs/bokndk6y' target=\"_blank\">./output</a></strong> to <a href='https://wandb.ai/rezamansourikhah-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/rezamansourikhah-student/huggingface' target=\"_blank\">https://wandb.ai/rezamansourikhah-student/huggingface</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/rezamansourikhah-student/huggingface/runs/bokndk6y' target=\"_blank\">https://wandb.ai/rezamansourikhah-student/huggingface/runs/bokndk6y</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2526' max='2526' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2526/2526 28:50, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.587500</td>\n",
       "      <td>0.596129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.079900</td>\n",
       "      <td>0.465346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.526600</td>\n",
       "      <td>0.386122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.462900</td>\n",
       "      <td>0.350279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.568600</td>\n",
       "      <td>0.333421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.241100</td>\n",
       "      <td>0.306356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.056900</td>\n",
       "      <td>0.284705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.003700</td>\n",
       "      <td>0.268118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.076500</td>\n",
       "      <td>0.260206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.151800</td>\n",
       "      <td>0.248899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.098300</td>\n",
       "      <td>0.243461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.098700</td>\n",
       "      <td>0.235142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1636' max='1636' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1636/1636 00:30]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'eval_loss': 0.2351417988538742, 'eval_runtime': 31.3387, 'eval_samples_per_second': 208.879, 'eval_steps_per_second': 52.236, 'epoch': 0.9998020977637048}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaModel, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "model_name = \"xlm-roberta-base\"\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "class TokenClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=16): \n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = self.texts[item]\n",
    "        label = self.labels[item]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\",\n",
    "            is_split_into_words=True\n",
    "        )\n",
    "        input_ids = encoding[\"input_ids\"].flatten()\n",
    "        attention_mask = encoding[\"attention_mask\"].flatten()\n",
    "        num_tokens = len(input_ids)\n",
    "        label = list(label)\n",
    "\n",
    "        if len(label) < num_tokens:\n",
    "            label = label + [0] * (num_tokens - len(label)) \n",
    "        elif len(label) > num_tokens:\n",
    "            label = label[:num_tokens]  \n",
    "        labels = torch.tensor(label, dtype=torch.long)\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "def preprocess_data(df):\n",
    "    texts = df['tokens'].tolist()\n",
    "    labels = [list(map(int, tag.split())) for tag in df['ner_tags'].tolist()]\n",
    "    return texts, labels\n",
    "\n",
    "train_texts, train_labels = preprocess_data(train_combined_df)\n",
    "test_texts, test_labels = preprocess_data(test_combined_df)\n",
    "label_encoder = LabelEncoder()\n",
    "all_labels = np.concatenate(train_labels + test_labels)\n",
    "label_encoder.fit(all_labels)\n",
    "train_labels = [label_encoder.transform(label) for label in train_labels]\n",
    "test_labels = [label_encoder.transform(label) for label in test_labels]\n",
    "num_labels = len(label_encoder.classes_)\n",
    "\n",
    "train_dataset = TokenClassificationDataset(train_texts, train_labels, tokenizer)\n",
    "test_dataset = TokenClassificationDataset(test_texts, test_labels, tokenizer)\n",
    "\n",
    "class TokenClassificationModel(nn.Module):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super(TokenClassificationModel, self).__init__()\n",
    "        self.xlm_roberta = XLMRobertaModel.from_pretrained(model_name)\n",
    "        self.classifier = nn.Linear(self.xlm_roberta.config.hidden_size, num_labels)\n",
    "        self.loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        outputs = self.xlm_roberta(input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state \n",
    "        logits = self.classifier(sequence_output) \n",
    "        if labels is not None:\n",
    "            loss = self.loss_fct(logits.view(-1, num_labels), labels.view(-1))\n",
    "            return loss, logits\n",
    "        return logits\n",
    "\n",
    "model = TokenClassificationModel(model_name=\"xlm-roberta-base\", num_labels=num_labels)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",\n",
    "    num_train_epochs=1,  \n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,  \n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    disable_tqdm=False,\n",
    "    seed=42,\n",
    "    load_best_model_at_end=True,\n",
    "    gradient_accumulation_steps=4,  \n",
    "    fp16=True, \n",
    "    dataloader_num_workers=8, \n",
    "    dataloader_pin_memory=True, \n",
    "    max_grad_norm=1.0,  \n",
    "    dataloader_drop_last=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "results = trainer.evaluate()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lATubiqRsPHd"
   },
   "source": [
    "*Ø¨Ø®Ø´ Ø³ÙˆÙ…:*\n",
    "---\n",
    "# Ù¾Ø§Ø³Ø® Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T13:05:36.791086Z",
     "start_time": "2024-12-16T13:05:36.750128Z"
    },
    "vscode": {
     "languageId": "plaintext"
    },
    "id": "Ms82ha89sPHd",
    "outputId": "0efc9cf5-e305-44d2-9bcb-a5e64ddb4043",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0: {'precision': 0.946338641622431, 'recall': 0.9852972436760433, 'f1-score': 0.9654250702954144, 'support': 28226.0}, 1: {'precision': 0.8288996372430472, 'recall': 0.6430581613508443, 'f1-score': 0.7242472266244057, 'support': 2132.0}, 2: {'precision': 0.9138576779026217, 'recall': 0.7778958554729012, 'f1-score': 0.8404133180252583, 'support': 941.0}, 3: {'precision': 0.8200836820083682, 'recall': 0.6426229508196721, 'f1-score': 0.7205882352941176, 'support': 2440.0}, 4: {'precision': 0.7794759825327511, 'recall': 0.649090909090909, 'f1-score': 0.7083333333333334, 'support': 550.0}, 5: {'precision': 0.8679430535100638, 'recall': 0.7491525423728813, 'f1-score': 0.804184671366841, 'support': 2360.0}, 6: {'precision': 0.8206896551724138, 'recall': 0.5458715596330275, 'f1-score': 0.6556473829201102, 'support': 218.0}, 7: {'precision': 0.7870722433460076, 'recall': 0.5376623376623376, 'f1-score': 0.6388888888888888, 'support': 770.0}, 8: {'precision': 0.7391304347826086, 'recall': 0.40669856459330145, 'f1-score': 0.5246913580246914, 'support': 418.0}, 9: {'precision': 0.43478260869565216, 'recall': 0.47619047619047616, 'f1-score': 0.45454545454545453, 'support': 21.0}, 10: {'precision': 0.8235632183908046, 'recall': 0.7704301075268817, 'f1-score': 0.7961111111111111, 'support': 1860.0}, 11: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13.0}, 12: {'precision': 0.8737864077669902, 'recall': 0.7058823529411765, 'f1-score': 0.7809110629067245, 'support': 510.0}, 13: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 32.0}, 14: {'precision': 0.5263157894736842, 'recall': 0.36585365853658536, 'f1-score': 0.4316546762589928, 'support': 82.0}, 15: {'precision': 0.4878048780487805, 'recall': 0.5, 'f1-score': 0.49382716049382713, 'support': 160.0}, 16: {'precision': 0.5192307692307693, 'recall': 0.27835051546391754, 'f1-score': 0.3624161073825503, 'support': 97.0}, 17: {'precision': 0.7041420118343196, 'recall': 0.6819484240687679, 'f1-score': 0.6928675400291121, 'support': 349.0}, 18: {'precision': 0.7777777777777778, 'recall': 0.4666666666666667, 'f1-score': 0.5833333333333334, 'support': 120.0}, 19: {'precision': 0.6923076923076923, 'recall': 0.6136363636363636, 'f1-score': 0.6506024096385542, 'support': 88.0}, 20: {'precision': 0.951196823596143, 'recall': 0.9801052016364699, 'f1-score': 0.9654346574553828, 'support': 42775.0}, 'accuracy': 0.9329863834034362, 'macro avg': {'precision': 0.680685665963949, 'recall': 0.5607816138732964, 'f1-score': 0.6092439522822907, 'support': 84162.0}, 'weighted avg': {'precision': 0.9286386959098631, 'recall': 0.9329863834034362, 'f1-score': 0.9290246605124725, 'support': 84162.0}}\n",
      "Predicted labels: [1 0 5 0 0 0 0 0 0]\n",
      "\n",
      "Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÙ†Ù‡Ø§ Ø¯Ù‚Øª Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ø¯Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ Ú©Ø§ÙÛŒ Ù†ÛŒØ³ØªØŒ Ø²ÛŒØ±Ø§ Ø¯Ø± Ù…Ø´Ú©Ù„Ø§Øª Ø¨Ø§ ØªÙˆØ²ÛŒØ¹ Ù†Ø§Ø¨Ø±Ø§Ø¨Ø± Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ØŒ Ø¯Ù‚Øª Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ø¯Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ø¯Ø± Ø±Ø§ Ù†Ø´Ø§Ù† Ø¯Ù‡Ø¯. Ø¨Ù‡â€ŒÙˆÛŒÚ˜Ù‡ØŒ Ù…Ø¯Ù„ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ØªÚ©Ø±Ø§Ø± Ù…Ø§Ù†Ù†Ø¯ Ø±Ø§ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©Ù†Ø¯ØŒ Ø§Ù…Ø§ Ø¯Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¶Ø¹ÛŒÙÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯. Ø¨Ù‡ Ù‡Ù…ÛŒÙ† Ø¯Ù„ÛŒÙ„ØŒ Ø¨Ø§ÛŒØ¯ Ø§Ø² Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¯Ù‚Øª Ù…Ø«Ø¨ØªØŒ ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ Ùˆ Ø§Ù…ØªÛŒØ§Ø² ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ù…Ø¯Ù„ Ø¯Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù‡Ø± Ú©Ù„Ø§Ø³ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ….\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "predictions = trainer.predict(test_dataset)\n",
    "pred_labels = np.argmax(predictions.predictions, axis=2)\n",
    "\n",
    "true_labels = []\n",
    "pred_labels_flat = []\n",
    "\n",
    "for true, pred in zip(test_labels, pred_labels):\n",
    "    true_labels.extend([t for t, p in zip(true, pred) if t != -100])\n",
    "    pred_labels_flat.extend([p for t, p in zip(true, pred) if t != -100])\n",
    "\n",
    "report = classification_report(true_labels, pred_labels_flat, target_names=label_encoder.classes_, output_dict=True)\n",
    "print(report)\n",
    "\n",
    "sample_text = [\"John visited Paris last summer.\"]\n",
    "encoding = tokenizer(sample_text, padding=True, truncation=True, return_tensors=\"pt\", max_length=16)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_ids = encoding[\"input_ids\"].to(device)\n",
    "attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "model.eval()  \n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=encoding[\"input_ids\"].to(device), attention_mask=encoding[\"attention_mask\"].to(device))\n",
    "\n",
    "predictions = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "predicted_labels = predictions.flatten().cpu().numpy()\n",
    "\n",
    "predicted_label_names = label_encoder.inverse_transform(predicted_labels)\n",
    "\n",
    "\n",
    "print(\"Predicted labels:\", predicted_label_names)\n",
    "\n",
    "print(\"\"\"\n",
    "Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÙ†Ù‡Ø§ Ø¯Ù‚Øª Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ø¯Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ Ú©Ø§ÙÛŒ Ù†ÛŒØ³ØªØŒ Ø²ÛŒØ±Ø§ Ø¯Ø± Ù…Ø´Ú©Ù„Ø§Øª Ø¨Ø§ ØªÙˆØ²ÛŒØ¹ Ù†Ø§Ø¨Ø±Ø§Ø¨Ø± Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ØŒ Ø¯Ù‚Øª Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ø¯Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ø¯Ø± Ø±Ø§ Ù†Ø´Ø§Ù† Ø¯Ù‡Ø¯. Ø¨Ù‡â€ŒÙˆÛŒÚ˜Ù‡ØŒ Ù…Ø¯Ù„ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ØªÚ©Ø±Ø§Ø± Ù…Ø§Ù†Ù†Ø¯ Ø±Ø§ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©Ù†Ø¯ØŒ Ø§Ù…Ø§ Ø¯Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¶Ø¹ÛŒÙÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯. Ø¨Ù‡ Ù‡Ù…ÛŒÙ† Ø¯Ù„ÛŒÙ„ØŒ Ø¨Ø§ÛŒØ¯ Ø§Ø² Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¯Ù‚Øª Ù…Ø«Ø¨ØªØŒ ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ Ùˆ Ø§Ù…ØªÛŒØ§Ø² ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ù…Ø¯Ù„ Ø¯Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù‡Ø± Ú©Ù„Ø§Ø³ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ….\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3u2F7h_YMmvp"
   },
   "source": [
    "# **Ø³ÙˆØ§Ù„ Ø¯ÙˆÙ…:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "id": "K9vruwaVsPHe",
    "outputId": "43633056-ff67-47b0-e80f-6c3e8544a7d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported Â£20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don't think I'll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he'll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I'll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe's earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say 'kid star goes off the rails,'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter's latest Â» . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer's \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he's legally an adult: \"I just think I'm going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.\n",
      "Summary: Harry Potter star Daniel Radcliffe gets Â£20M fortune as he turns 18 Monday .\n",
      "Young actor says he has no plans to fritter his cash away .\n",
      "Radcliffe's earnings from first five Potter films have been held in trust fund .\n",
      "Min text length: 8, Max: 2347, Avg: 691.8703263175126\n",
      "Min summary length: 4, Max: 1296, Avg: 51.574101486174435\n",
      "\n",
      "Ø¢ÛŒØ§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾ÛŒØ´ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ú¯Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø³ÙˆØ§Ù„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŸ                                                                                          \n",
      "Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ LLM Ù…Ø§Ù†Ù†Ø¯ LLAMA Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒÛŒ Ø¯Ø± ØªØ¹Ø¯Ø§Ø¯ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¯Ø§Ø±Ù†Ø¯ØŒ Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ù…ØªÙˆÙ† Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø¨Ø§ÛŒØ¯ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ø´ (Truncation) ÛŒØ§ ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯. Ù…ØªÙ†â€ŒÙ‡Ø§ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø­Ø§ÙˆÛŒ Ù†ÙˆÛŒØ²Ù‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ØŒ Ù†Ø§Ù…â€ŒÙ‡Ø§ Ùˆ Ú©Ù„Ù…Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒ Ù‡Ø³ØªÙ†Ø¯ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø­Ø°Ù Ø´ÙˆÙ†Ø¯ ØªØ§ Ù…Ø¯Ù„ Ø±ÙˆÛŒ Ù…Ø­ØªÙˆØ§ÛŒ Ø§ØµÙ„ÛŒ ØªÙ…Ø±Ú©Ø² Ú©Ù†Ø¯. Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ØŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ ÙˆØ§Ø­Ø¯Ù‡Ø§ÛŒ ØªÙˆÚ©Ù† ØªØ¨Ø¯ÛŒÙ„ Ø´ÙˆÙ†Ø¯ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙˆÚ©Ù†â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø±Ù†Ø¯. Ø¯Ø± ØªØ³Ú© Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒØŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„ Ù…ØªÙ† Ø§ØµÙ„ÛŒ Ùˆ Ø®Ù„Ø§ØµÙ‡ Ù‡Ø³ØªÙ†Ø¯ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡â€ŒØ·ÙˆØ± Ø¯Ù‚ÛŒÙ‚ Ø§Ø² Ù‡Ù… Ø¬Ø¯Ø§ Ø´ÙˆÙ†Ø¯. Ù‡Ù…Ú†Ù†ÛŒÙ†ØŒ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†ÛŒØ§Ø² Ø¨Ø§Ø´Ø¯ Ú©Ù‡ Ø·ÙˆÙ„ Ø®Ù„Ø§ØµÙ‡â€ŒÙ‡Ø§ ØªÙ†Ø¸ÛŒÙ… Ø´ÙˆØ¯ ØªØ§ Ù…Ø¯Ù„ Ø¨Ù‡ Ø·ÙˆØ± Ø¨Ù‡ÛŒÙ†Ù‡ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†Ø¯.                          \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('cnn_dailymail', '3.0.0')\n",
    "\n",
    "train_data = dataset['train'].select(range(400))\n",
    "val_data = dataset['validation'].select(range(100))\n",
    "test_data = dataset['test'].select(range(100))\n",
    "\n",
    "sample = train_data[0]\n",
    "print(f\"Text: {sample['article']}\")\n",
    "print(f\"Summary: {sample['highlights']}\")\n",
    "\n",
    "lengths_text = [len(sample['article'].split()) for sample in dataset['train']]\n",
    "lengths_summary = [len(sample['highlights'].split()) for sample in dataset['train']]\n",
    "\n",
    "min_text_length = min(lengths_text)\n",
    "max_text_length = max(lengths_text)\n",
    "avg_text_length = sum(lengths_text) / len(lengths_text)\n",
    "\n",
    "min_summary_length = min(lengths_summary)\n",
    "max_summary_length = max(lengths_summary)\n",
    "avg_summary_length = sum(lengths_summary) / len(lengths_summary)\n",
    "\n",
    "print(f\"Min text length: {min_text_length}, Max: {max_text_length}, Avg: {avg_text_length}\")\n",
    "print(f\"Min summary length: {min_summary_length}, Max: {max_summary_length}, Avg: {avg_summary_length}\")\n",
    "\n",
    "print(\"\"\"\n",
    "Ø¢ÛŒØ§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾ÛŒØ´ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ú¯Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø³ÙˆØ§Ù„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŸ\n",
    "Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ LLM Ù…Ø§Ù†Ù†Ø¯ LLAMA Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒÛŒ Ø¯Ø± ØªØ¹Ø¯Ø§Ø¯ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¯Ø§Ø±Ù†Ø¯ØŒ Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ù…ØªÙˆÙ† Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø¨Ø§ÛŒØ¯ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ø´ (Truncation) ÛŒØ§ ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯. Ù…ØªÙ†â€ŒÙ‡Ø§ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø­Ø§ÙˆÛŒ Ù†ÙˆÛŒØ²Ù‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ØŒ Ù†Ø§Ù…â€ŒÙ‡Ø§ Ùˆ Ú©Ù„Ù…Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒ Ù‡Ø³ØªÙ†Ø¯ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø­Ø°Ù Ø´ÙˆÙ†Ø¯ ØªØ§ Ù…Ø¯Ù„ Ø±ÙˆÛŒ Ù…Ø­ØªÙˆØ§ÛŒ Ø§ØµÙ„ÛŒ ØªÙ…Ø±Ú©Ø² Ú©Ù†Ø¯. Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ØŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ ÙˆØ§Ø­Ø¯Ù‡Ø§ÛŒ ØªÙˆÚ©Ù† ØªØ¨Ø¯ÛŒÙ„ Ø´ÙˆÙ†Ø¯ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙˆÚ©Ù†â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø±Ù†Ø¯. Ø¯Ø± ØªØ³Ú© Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒØŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„ Ù…ØªÙ† Ø§ØµÙ„ÛŒ Ùˆ Ø®Ù„Ø§ØµÙ‡ Ù‡Ø³ØªÙ†Ø¯ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡â€ŒØ·ÙˆØ± Ø¯Ù‚ÛŒÙ‚ Ø§Ø² Ù‡Ù… Ø¬Ø¯Ø§ Ø´ÙˆÙ†Ø¯. Ù‡Ù…Ú†Ù†ÛŒÙ†ØŒ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†ÛŒØ§Ø² Ø¨Ø§Ø´Ø¯ Ú©Ù‡ Ø·ÙˆÙ„ Ø®Ù„Ø§ØµÙ‡â€ŒÙ‡Ø§ ØªÙ†Ø¸ÛŒÙ… Ø´ÙˆØ¯ ØªØ§ Ù…Ø¯Ù„ Ø¨Ù‡ Ø·ÙˆØ± Ø¨Ù‡ÛŒÙ†Ù‡ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†Ø¯.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgyQYySusPHe"
   },
   "source": [
    "<div dir=\"rtl\" style=\"font-family: Vazir; width: 85%; font-size: 16px;\">\n",
    "Ø³ÙˆØ§Ù„Ø§Øª Ø®ÙˆØ¯ØªØ§Ù† Ø±Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø·Ø±ÛŒÙ‚ Ø§ÛŒÙ…ÛŒÙ„\n",
    "<code>mohamadgorjicode@gmail.com</code>\n",
    " Ø§Ø² Ø·Ø±Ø§Ø­ ØªÙ…Ø±ÛŒÙ† 4 Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„ Ø¯ÙˆÙ… Ø¨Ù¾Ø±Ø³ÛŒØ¯."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vAFTulEMpUx"
   },
   "source": [
    "*Ø¨Ø®Ø´ Ø§ÙˆÙ„:*\n",
    "---\n",
    "# Ù¾Ø§Ø³Ø® Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-19T09:34:33.208027Z"
    },
    "jupyter": {
     "is_executing": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ObA0618bsPHe",
    "outputId": "6159a67b-aed9-434d-9a97-418d48a4d8e3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting transformers==4.36.2\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "\u001B[?25l     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m0.0/126.8 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m126.8/126.8 kB\u001B[0m \u001B[31m10.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting datasets==2.16.1\n",
      "  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting accelerate==0.26.1\n",
      "  Downloading accelerate-0.26.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting evaluate==0.4.1\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting bitsandbytes==0.42.0\n",
      "  Downloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (2.32.3)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.36.2)\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (17.0.0)\n",
      "Collecting pyarrow-hotfix (from datasets==2.16.1)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets==2.16.1)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (2.2.2)\n",
      "Collecting xxhash (from datasets==2.16.1)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets==2.16.1)\n",
      "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.16.1)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (3.11.10)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1) (2.5.1+cu121)\n",
      "Collecting responses<0.19 (from evaluate==0.4.1)\n",
      "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.42.0) (1.13.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (2024.12.14)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.26.1) (1.3.0)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets==2.16.1)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.16.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.16.1) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.16.1) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.16.1) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.26.1) (3.0.2)\n",
      "Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m8.2/8.2 MB\u001B[0m \u001B[31m82.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m507.1/507.1 kB\u001B[0m \u001B[31m35.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m270.9/270.9 kB\u001B[0m \u001B[31m23.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m84.1/84.1 kB\u001B[0m \u001B[31m8.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m105.0/105.0 MB\u001B[0m \u001B[31m8.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m115.3/115.3 kB\u001B[0m \u001B[31m11.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m166.4/166.4 kB\u001B[0m \u001B[31m16.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m3.6/3.6 MB\u001B[0m \u001B[31m98.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m134.8/134.8 kB\u001B[0m \u001B[31m13.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m194.1/194.1 kB\u001B[0m \u001B[31m20.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: xxhash, pyarrow-hotfix, fsspec, dill, responses, multiprocess, bitsandbytes, tokenizers, accelerate, transformers, datasets, evaluate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.0\n",
      "    Uninstalling tokenizers-0.21.0:\n",
      "      Successfully uninstalled tokenizers-0.21.0\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.2.1\n",
      "    Uninstalling accelerate-1.2.1:\n",
      "      Successfully uninstalled accelerate-1.2.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.47.1\n",
      "    Uninstalling transformers-4.47.1:\n",
      "      Successfully uninstalled transformers-4.47.1\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2023.10.0 which is incompatible.\n",
      "sentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.36.2 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed accelerate-0.26.1 bitsandbytes-0.42.0 datasets-2.16.1 dill-0.3.7 evaluate-0.4.1 fsspec-2023.10.0 multiprocess-0.70.15 pyarrow-hotfix-0.6 responses-0.18.0 tokenizers-0.15.2 transformers-4.36.2 xxhash-3.5.0\n",
      "Collecting git+https://github.com/huggingface/trl@a3c5b7178ac4f65569975efadc97db2f3749c65e\n",
      "  Cloning https://github.com/huggingface/trl (to revision a3c5b7178ac4f65569975efadc97db2f3749c65e) to /tmp/pip-req-build-5y_gl88g\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl /tmp/pip-req-build-5y_gl88g\n",
      "  Running command git rev-parse -q --verify 'sha^a3c5b7178ac4f65569975efadc97db2f3749c65e'\n",
      "  Running command git fetch -q https://github.com/huggingface/trl a3c5b7178ac4f65569975efadc97db2f3749c65e\n",
      "  Running command git checkout -q a3c5b7178ac4f65569975efadc97db2f3749c65e\n",
      "  Resolved https://github.com/huggingface/trl to commit a3c5b7178ac4f65569975efadc97db2f3749c65e\n",
      "  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl==0.7.11.dev0) (2.5.1+cu121)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from trl==0.7.11.dev0) (4.36.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl==0.7.11.dev0) (1.26.4)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl==0.7.11.dev0) (0.26.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl==0.7.11.dev0) (2.16.1)\n",
      "Collecting tyro>=0.5.11 (from trl==0.7.11.dev0)\n",
      "  Downloading tyro-0.9.4-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.7.11.dev0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.7.11.dev0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.7.11.dev0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.7.11.dev0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.7.11.dev0) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.7.11.dev0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.4.0->trl==0.7.11.dev0) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl==0.7.11.dev0) (0.27.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl==0.7.11.dev0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl==0.7.11.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl==0.7.11.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl==0.7.11.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl==0.7.11.dev0) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl==0.7.11.dev0) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl==0.7.11.dev0) (4.67.1)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.7.11.dev0) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.7.11.dev0) (13.9.4)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.7.11.dev0)\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.7.11.dev0) (4.4.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl==0.7.11.dev0) (5.9.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.11.dev0) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.11.dev0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.11.dev0) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.11.dev0) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.11.dev0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.11.dev0) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.11.dev0) (3.11.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.11.dev0) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.11.dev0) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.11.dev0) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.11.dev0) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.11.dev0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.11.dev0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.11.dev0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.11.dev0) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl==0.7.11.dev0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl==0.7.11.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl==0.7.11.dev0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl==0.7.11.dev0) (2024.12.14)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11.dev0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11.dev0) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl==0.7.11.dev0) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl==0.7.11.dev0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl==0.7.11.dev0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl==0.7.11.dev0) (2024.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.11.dev0) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.11.dev0) (1.17.0)\n",
      "Downloading tyro-0.9.4-py3-none-any.whl (112 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m112.4/112.4 kB\u001B[0m \u001B[31m8.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: trl\n",
      "  Building wheel for trl (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for trl: filename=trl-0.7.11.dev0-py3-none-any.whl size=151116 sha256=6124ef5042a8e6168e5e28d22bad249e3fb306bb9c9e7ba639528b4a938033ac\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/fc/ec/e718a169cea1752bd9c3eb798e9d8a56686d0752c49f97e1c1\n",
      "Successfully built trl\n",
      "Installing collected packages: shtab, tyro, trl\n",
      "Successfully installed shtab-1.7.1 trl-0.7.11.dev0 tyro-0.9.4\n",
      "Collecting git+https://github.com/huggingface/peft@4a1559582281fc3c9283892caea8ccef1d6f5a4f\n",
      "  Cloning https://github.com/huggingface/peft (to revision 4a1559582281fc3c9283892caea8ccef1d6f5a4f) to /tmp/pip-req-build-z3fwgskk\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft /tmp/pip-req-build-z3fwgskk\n",
      "  Running command git rev-parse -q --verify 'sha^4a1559582281fc3c9283892caea8ccef1d6f5a4f'\n",
      "  Running command git fetch -q https://github.com/huggingface/peft 4a1559582281fc3c9283892caea8ccef1d6f5a4f\n",
      "  Running command git checkout -q 4a1559582281fc3c9283892caea8ccef1d6f5a4f\n",
      "  Resolved https://github.com/huggingface/peft to commit 4a1559582281fc3c9283892caea8ccef1d6f5a4f\n",
      "  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (2.5.1+cu121)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (4.36.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (0.26.1)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (0.4.5)\n",
      "Requirement already satisfied: huggingface_hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (0.27.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.17.0->peft==0.7.2.dev0) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.17.0->peft==0.7.2.dev0) (2023.10.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.17.0->peft==0.7.2.dev0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.17.0->peft==0.7.2.dev0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.7.2.dev0) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.7.2.dev0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.7.2.dev0) (0.15.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.7.2.dev0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.17.0->peft==0.7.2.dev0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.17.0->peft==0.7.2.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.17.0->peft==0.7.2.dev0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.17.0->peft==0.7.2.dev0) (2024.12.14)\n",
      "Building wheels for collected packages: peft\n",
      "  Building wheel for peft (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for peft: filename=peft-0.7.2.dev0-py3-none-any.whl size=183141 sha256=cfcf1011e24a0fcbb2ec0bd190ec86fe30fb8cfb1571b844e793c8a3e0d93b5c\n",
      "  Stored in directory: /root/.cache/pip/wheels/94/88/30/67a50390d00daa42c311fb8b162fb3b320e9cdab6bd0bb8568\n",
      "Successfully built peft\n",
      "Installing collected packages: peft\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.14.0\n",
      "    Uninstalling peft-0.14.0:\n",
      "      Successfully uninstalled peft-0.14.0\n",
      "Successfully installed peft-0.7.2.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip install  --upgrade \\\n",
    "  \"transformers==4.36.2\" \\\n",
    "  \"datasets==2.16.1\" \\\n",
    "  \"accelerate==0.26.1\" \\\n",
    "  \"evaluate==0.4.1\" \\\n",
    "  \"bitsandbytes==0.42.0\" \\\n",
    "\n",
    "!pip install git+https://github.com/huggingface/trl@a3c5b7178ac4f65569975efadc97db2f3749c65e --upgrade\n",
    "!pip install git+https://github.com/huggingface/peft@4a1559582281fc3c9283892caea8ccef1d6f5a4f --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('cnn_dailymail', '3.0.0')\n",
    "\n",
    "train_data = dataset['train'].select(range(5000))\n",
    "val_data = dataset['validation'].select(range(500))\n",
    "test_data = dataset['test'].select(range(100))\n",
    "\n",
    "sample = train_data[0]\n",
    "print(f\"Text: {sample['article']}\")\n",
    "print(f\"Summary: {sample['highlights']}\")\n",
    "\n",
    "lengths_text = [len(sample['article'].split()) for sample in dataset['train']]\n",
    "lengths_summary = [len(sample['highlights'].split()) for sample in dataset['train']]\n",
    "\n",
    "min_text_length = min(lengths_text)\n",
    "max_text_length = max(lengths_text)\n",
    "avg_text_length = sum(lengths_text) / len(lengths_text)\n",
    "\n",
    "min_summary_length = min(lengths_summary)\n",
    "max_summary_length = max(lengths_summary)\n",
    "avg_summary_length = sum(lengths_summary) / len(lengths_summary)\n",
    "\n",
    "print(f\"Min text length: {min_text_length}, Max: {max_text_length}, Avg: {avg_text_length}\")\n",
    "print(f\"Min summary length: {min_summary_length}, Max: {max_summary_length}, Avg: {avg_summary_length}\")\n",
    "\n",
    "print(\"\"\"\n",
    "Ø¢ÛŒØ§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾ÛŒØ´ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ú¯Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø³ÙˆØ§Ù„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŸ\n",
    "Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ LLM Ù…Ø§Ù†Ù†Ø¯ LLAMA Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒÛŒ Ø¯Ø± ØªØ¹Ø¯Ø§Ø¯ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¯Ø§Ø±Ù†Ø¯ØŒ Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ù…ØªÙˆÙ† Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø¨Ø§ÛŒØ¯ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ø´ (Truncation) ÛŒØ§ ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯. Ù…ØªÙ†â€ŒÙ‡Ø§ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø­Ø§ÙˆÛŒ Ù†ÙˆÛŒØ²Ù‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ØŒ Ù†Ø§Ù…â€ŒÙ‡Ø§ Ùˆ Ú©Ù„Ù…Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒ Ù‡Ø³ØªÙ†Ø¯ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø­Ø°Ù Ø´ÙˆÙ†Ø¯ ØªØ§ Ù…Ø¯Ù„ Ø±ÙˆÛŒ Ù…Ø­ØªÙˆØ§ÛŒ Ø§ØµÙ„ÛŒ ØªÙ…Ø±Ú©Ø² Ú©Ù†Ø¯. Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ØŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ ÙˆØ§Ø­Ø¯Ù‡Ø§ÛŒ ØªÙˆÚ©Ù† ØªØ¨Ø¯ÛŒÙ„ Ø´ÙˆÙ†Ø¯ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙˆÚ©Ù†â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø±Ù†Ø¯. Ø¯Ø± ØªØ³Ú© Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒØŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„ Ù…ØªÙ† Ø§ØµÙ„ÛŒ Ùˆ Ø®Ù„Ø§ØµÙ‡ Ù‡Ø³ØªÙ†Ø¯ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡â€ŒØ·ÙˆØ± Ø¯Ù‚ÛŒÙ‚ Ø§Ø² Ù‡Ù… Ø¬Ø¯Ø§ Ø´ÙˆÙ†Ø¯. Ù‡Ù…Ú†Ù†ÛŒÙ†ØŒ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†ÛŒØ§Ø² Ø¨Ø§Ø´Ø¯ Ú©Ù‡ Ø·ÙˆÙ„ Ø®Ù„Ø§ØµÙ‡â€ŒÙ‡Ø§ ØªÙ†Ø¸ÛŒÙ… Ø´ÙˆØ¯ ØªØ§ Ù…Ø¯Ù„ Ø¨Ù‡ Ø·ÙˆØ± Ø¨Ù‡ÛŒÙ†Ù‡ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†Ø¯.\n",
    "\"\"\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-SdWKpnbwq-u",
    "outputId": "d9c72fa6-a727-46a3-c5a5-501704c75625"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Text: LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported Â£20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don't think I'll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he'll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I'll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe's earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say 'kid star goes off the rails,'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter's latest Â» . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer's \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he's legally an adult: \"I just think I'm going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.\n",
      "Summary: Harry Potter star Daniel Radcliffe gets Â£20M fortune as he turns 18 Monday .\n",
      "Young actor says he has no plans to fritter his cash away .\n",
      "Radcliffe's earnings from first five Potter films have been held in trust fund .\n",
      "Min text length: 8, Max: 2347, Avg: 691.8703263175126\n",
      "Min summary length: 4, Max: 1296, Avg: 51.574101486174435\n",
      "\n",
      "Ø¢ÛŒØ§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾ÛŒØ´ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ú¯Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø³ÙˆØ§Ù„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŸ\n",
      "Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ LLM Ù…Ø§Ù†Ù†Ø¯ LLAMA Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒÛŒ Ø¯Ø± ØªØ¹Ø¯Ø§Ø¯ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¯Ø§Ø±Ù†Ø¯ØŒ Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ù…ØªÙˆÙ† Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø¨Ø§ÛŒØ¯ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ø´ (Truncation) ÛŒØ§ ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯. Ù…ØªÙ†â€ŒÙ‡Ø§ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø­Ø§ÙˆÛŒ Ù†ÙˆÛŒØ²Ù‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ØŒ Ù†Ø§Ù…â€ŒÙ‡Ø§ Ùˆ Ú©Ù„Ù…Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒ Ù‡Ø³ØªÙ†Ø¯ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø­Ø°Ù Ø´ÙˆÙ†Ø¯ ØªØ§ Ù…Ø¯Ù„ Ø±ÙˆÛŒ Ù…Ø­ØªÙˆØ§ÛŒ Ø§ØµÙ„ÛŒ ØªÙ…Ø±Ú©Ø² Ú©Ù†Ø¯. Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ØŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ ÙˆØ§Ø­Ø¯Ù‡Ø§ÛŒ ØªÙˆÚ©Ù† ØªØ¨Ø¯ÛŒÙ„ Ø´ÙˆÙ†Ø¯ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙˆÚ©Ù†â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø±Ù†Ø¯. Ø¯Ø± ØªØ³Ú© Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒØŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„ Ù…ØªÙ† Ø§ØµÙ„ÛŒ Ùˆ Ø®Ù„Ø§ØµÙ‡ Ù‡Ø³ØªÙ†Ø¯ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡â€ŒØ·ÙˆØ± Ø¯Ù‚ÛŒÙ‚ Ø§Ø² Ù‡Ù… Ø¬Ø¯Ø§ Ø´ÙˆÙ†Ø¯. Ù‡Ù…Ú†Ù†ÛŒÙ†ØŒ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†ÛŒØ§Ø² Ø¨Ø§Ø´Ø¯ Ú©Ù‡ Ø·ÙˆÙ„ Ø®Ù„Ø§ØµÙ‡â€ŒÙ‡Ø§ ØªÙ†Ø¸ÛŒÙ… Ø´ÙˆØ¯ ØªØ§ Ù…Ø¯Ù„ Ø¨Ù‡ Ø·ÙˆØ± Ø¨Ù‡ÛŒÙ†Ù‡ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†Ø¯.\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PgEUgHeJsPHf",
    "outputId": "31775734-7d9f-4c74-9b1c-31375771fcfd"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "model_id = \"HuggingFaceTB/SmolLM2-1.7B\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
    "import peft\n",
    "from datasets import load_dataset\n",
    "from peft import PeftModel, LoraConfig\n",
    "\n"
   ],
   "metadata": {
    "id": "nENrjv_X3rUd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4bf13b3f-1b8d-4d1b-96db-edb442fd2534"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install trl\n",
    "from trl import SFTTrainer"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MJb3K06ZLGbR",
    "outputId": "20e55b66-af78-4839-828c-37a80d212937"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.7.11.dev0)\n",
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.5.1+cu121)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.36.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl) (1.26.4)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl) (0.26.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl) (2.16.1)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl) (0.9.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.27.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (4.67.1)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.9.4)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (4.4.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl) (5.9.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.11.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2024.12.14)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2024.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.17.0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import Trainer"
   ],
   "metadata": {
    "id": "CT1pQIDH-9-v"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from peft import get_peft_model"
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token \n",
    "\n",
    "def preprocess_function(examples):\n",
    "    output_texts = []\n",
    "    for i in range(len(examples)):\n",
    "        article_text = examples['article'][i] \n",
    "        highlight_text = examples['highlights'][i]  \n",
    "        text = f\"### Article: {article_text} \\n ### Summary: {highlight_text}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,                \n",
    "    lora_alpha=32,      \n",
    "    lora_dropout=0.1,   \n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  \n",
    "    bias=\"none\",       \n",
    "    task_type=\"CAUSAL_LM\" \n",
    ")\n",
    "\n",
    "print(dataset['train'][0])\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",               \n",
    "    evaluation_strategy=\"epoch\",        \n",
    "    learning_rate=2e-5,                   \n",
    "    per_device_train_batch_size=8,        \n",
    "    per_device_eval_batch_size=8,         \n",
    "    num_train_epochs=3,                   \n",
    "    weight_decay=0.01,                    \n",
    "    logging_dir='./logs',                 \n",
    "    logging_steps=200,                    \n",
    "    save_steps=1000,                      \n",
    "    save_total_limit=2,                   \n",
    ")\n",
    "peft_config =LoraConfig(\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        r=64,\n",
    "        bias=\"none\",\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,                \n",
    "    args=training_args,              \n",
    "    train_dataset=train_data,        \n",
    "    eval_dataset=val_data,            \n",
    "    peft_config=peft_config,         \n",
    "    tokenizer=tokenizer,           \n",
    "    formatting_func=preprocess_function,\n",
    "    )\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293,
     "referenced_widgets": [
      "e9694627796b4f5786ff700dab3b170b",
      "b5ccba4f497a4c0c97ef8e6a96469844",
      "2bd1d8c3555f41ceabfb1573912152d9",
      "06074ba7900949d9b2519dfea83c94e4",
      "2379ccf18d0f4b6bb934486b0619adf0",
      "630bbc44049a46e3b325760b73e24a56",
      "183c716e62684f8a8852618d4451991e",
      "307d91a57fe44fc2a1290144f035bddb",
      "42ab117718da4cb09cdb2055f766ec1f",
      "febf915104234064b548caeae5822c88",
      "c822d8858bb346e2b6cd554e5472675a"
     ]
    },
    "id": "TagzxV29wiYW",
    "outputId": "15038599-534d-444c-9432-a2bd0e495c4f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'article': 'LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported Â£20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter\\'s latest Â» . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.', 'highlights': \"Harry Potter star Daniel Radcliffe gets Â£20M fortune as he turns 18 Monday .\\nYoung actor says he has no plans to fritter his cash away .\\nRadcliffe's earnings from first five Potter films have been held in trust fund .\", 'id': '42c027e4ff9730fbb3de84c1af0d2c506e41c3e4'}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9694627796b4f5786ff700dab3b170b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>9.717671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>9.698275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>9.689795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6, training_loss=9.71615219116211, metrics={'train_runtime': 5.6022, 'train_samples_per_second': 8.033, 'train_steps_per_second': 1.071, 'total_flos': 4090484551680.0, 'train_loss': 9.71615219116211, 'epoch': 3.0})"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install rouge-score\n",
    "!pip install bert-score"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hp3TitfKOT1I",
    "outputId": "ed01f9bb-aecf-4400-a9d9-c7f6ec511c1c"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.67.1)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=98338c61244df2594ba2527529297055e04676d6ede0b165dd3ee0bd0bf5d45f\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score\n",
      "Successfully installed rouge-score-0.1.2\n",
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.5.1+cu121)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.2.2)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.36.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.27.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2024.12.14)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m61.1/61.1 kB\u001B[0m \u001B[31m6.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "sample_article = test_data[0][\"article\"]\n",
    "expected_summary = test_data[0][\"highlights\"]\n",
    "\n",
    "generated_summary = summarizer(sample_article, max_length=150, min_length=50, do_sample=False)\n",
    "\n",
    "print(\"Generated Summary: \", generated_summary[0]['summary_text'])\n",
    "print(\"Expected Summary: \", expected_summary)\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "rouge_scores = scorer.score(expected_summary, generated_summary[0]['summary_text'])\n",
    "\n",
    "print(\"\\nROUGE Scores: \")\n",
    "print(rouge_scores)\n",
    "\n",
    "references = [expected_summary]\n",
    "candidates = [generated_summary[0]['summary_text']]\n",
    "\n",
    "P, R, F1 = score(candidates, references, lang='en')\n",
    "\n",
    "print(\"\\nBERTScore:\")\n",
    "print(f\"Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516,
     "referenced_widgets": [
      "18073111638147ff9f0955bbf81d0b05",
      "90d61c7523294e328ee30706f5a2d5db",
      "a458ea4c5e38449d9d3bcf340b4f5380",
      "fc8f2111100a4ae8b719e942fe7e0ff3",
      "7bb7bf42314e4c9f9273a6ebecb3cdb9",
      "56cbaac128e24d6e86ac5f24dae3451d",
      "dbdd1eb2ab104058b225892890743e43",
      "b698bcc7fb8a45afaca5f3725a496a8b",
      "1cf14c31ed624840a9ea685001badedc",
      "b699f76445694685a79b974c496aa5c7",
      "9f596f30b7244f19ba3e146a4f478991",
      "d239422e9076457cbb57b5fd8e42d4b9",
      "a86c70356888413e9b583650cbd36627",
      "f455532c7c0e4559a9961a83d0ba957b",
      "2a6c76f5f3334f83bd32141470b2037e",
      "2932f7c4450e47d49bb0bfc9e5b59123",
      "a09bff9b10034f3a936532a2ad59e1fe",
      "07cd0c71457c47c6853e9db6f341aad5",
      "2c12126e4d094ebba02c8ebac5901485",
      "c56a8d81f12f4622a61fea35f90fd294",
      "94e47b6e9fba461d93686337d9cc2df1",
      "277316b857694074ab7a596825887979",
      "fd5a7d13ac2f4cb3b3b3c5ffb4f88e5c",
      "2321c7ce6343443882c0e294451cc404",
      "c6b54372970549bfbb2d4c8b77128fc6",
      "23d7e33aaa3a4d96a782491688748e09",
      "5d22dcb79a134ca281a3d50a805ab4b7",
      "d2f1fcc486a8460ca049b97279bcf6d5",
      "cc6efec711f44fba9a7f4eb0035b3d34",
      "bf490ff44ef947e1986a0517c004a095",
      "a4b6c0aed69247c4bdd0610449db1166",
      "ff18ad906a0c497a91ef3bdf8cafb7c8",
      "cefec0596137440cbd8e54b5fc738029",
      "7f657ee09a724d29a00071ee7c6bd78b",
      "899248dc8031417da6225c1dc3e35547",
      "d31ec9b854ab4c14a18b9c4244c4de09",
      "1846f523c01b4bc3a5af821fb056b0dc",
      "c2118dd6916d4a8b89d0b4dfa70060e0",
      "14e255109295400587d4f38d8ccc8b75",
      "24294a1a72f64d658f4cf8bea5153555",
      "6dc977c1d42948d7a3abd0b409a45ee7",
      "f4e17b485e764d84b8c592383300903b",
      "5f17a236f4874cf0ab1e0a221f4d3ba2",
      "087000335fc44e99a64cb7bdd58e5b48",
      "9cb8c4f02f58498ab92931b0970e9fdd",
      "592d98108542433cb3a4ea93cce0b535",
      "1e10429495eb4ee6b67d988cc505da44",
      "1052aa85173a4978a09f10475e333eff",
      "3854edd65288486ea8603dab10fe70a0",
      "597982f47ea24974827927d0bbe1fd97",
      "0b94ce4927654d89b89f3af141bb9cd7",
      "076e03cf988f49229a375134d8c42c8e",
      "0baf4fd20d4142c6a611c5e9c28130a8",
      "d9fe0351536b4842a8915797af3fb31d",
      "d87cac6b2d21481eb02424d60815ae36",
      "be58fa99be5047618084db9a572296ad",
      "80c700c897e94d3983646cfc32c83120",
      "242f980b60ed401dbaeb3cb6c33f7a84",
      "ac94fbee2609457aa24d64ffbeee9214",
      "e60fc2ef178445b9ac4e052a160d0144",
      "74bfb5fab9da4f05ba3477aecb317966",
      "7189308a93e741dab59f7bcb0e92f6d2",
      "d79f1f78bb774e4bb779b28ae0439b81",
      "efca7867bf7f49d1b2f8263181dd2466",
      "da5a2d88353c4b1cae7f75f57f59e82d",
      "cdb4681e2112474697e64ae77b34fbf6"
     ]
    },
    "id": "d43owxjSM6Ec",
    "outputId": "da11a3ba-8f08-4297-fab5-a96d4ddff2c1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The model 'LlamaForCausalLM' is not supported for summarization. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generated Summary:  (CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC's founding Rome Statute in January, when they also accepted its jurisdiction over alleged crimes committed \"in the occupied Palestinian territory, including East Jerusalem, since June 13, 2014.\" Later that month, the ICC opened a preliminary examination into the situation in Palestinian territories, paving the way for possible war crimes investigations against Israelis. As members of the court, Palestinians may be subject to counter-charges as well. Israel and the United States, neither of which is an ICC member, opposed the Palestinians' efforts to join the body. But Palestinian Foreign Minister Riad al-Malki, speaking at Wednesday's ceremony, said it was a move toward greater justice. \"As Palestine formally becomes a State Party to the Rome Statute today, the world is also a step closer to ending a long era of impunity and injustice,\" he said, according to an ICC news release. \"Indeed, today brings us closer to our shared goals of justice and peace.\" Judge Kuniko Ozaki, a vice president of the ICC, said acceding to the treaty was just the first step for the Palestinians. \"As the Rome Statute today enters into force for the State of Palestine, Palestine acquires all the rights as well as responsibilities that come with being a State Party to the Statute. These are substantive commitments, which cannot be taken lightly,\" she said. Rights group Human Rights Watch welcomed the development. \"Governments seeking to penalize Palestine for joining the ICC should immediately end their pressure, and countries that support universal acceptance of the court's treaty should speak out to welcome its membership,\" said Balkees Jarrah, international justice counsel for the group. \"What's objectionable is the attempts to undermine international justice, not Palestine's decision to join a treaty to which over 100 countries around the world are members.\" In January, when the preliminary ICC examination was opened, Israeli Prime Minister Benjamin Netanyahu described it as an outrage, saying the court was overstepping its boundaries. The United States also said it \"strongly\" disagreed with the court's decision. \"As we have said repeatedly, we do not believe that Palestine is a state and therefore we do not believe that it is eligible to join the ICC,\" the State Department said in a statement. It urged the warring sides to resolve their differences through direct negotiations. \"We will continue to oppose actions against Israel at the ICC as counterproductive to the cause of peace,\" it said. But the ICC begs to differ with the definition of a state for its purposes and refers to the territories as \"Palestine.\" While a preliminary examination is not a formal investigation, it allows the court to review evidence and determine whether to investigate suspects on both sides. Prosecutor Fatou Bensouda said her office would \"conduct its analysis in full independence and impartiality.\" The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead. The inquiry will include alleged war crimes committed since June. The International Criminal Court was set up in 2002 to prosecute genocide, crimes against humanity and war crimes. CNN's Vasco Cotovio, Kareem Khadder and Faith Karimi contributed to this report.\n",
      "\n",
      "Expected Summary:  Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\n",
      "Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .\n",
      "\n",
      "ROUGE Scores: \n",
      "{'rouge1': Score(precision=0.05536332179930796, recall=0.9411764705882353, fmeasure=0.10457516339869281), 'rouge2': Score(precision=0.03119584055459272, recall=0.5454545454545454, fmeasure=0.05901639344262296), 'rougeL': Score(precision=0.04844290657439446, recall=0.8235294117647058, fmeasure=0.0915032679738562)}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18073111638147ff9f0955bbf81d0b05"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d239422e9076457cbb57b5fd8e42d4b9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd5a7d13ac2f4cb3b3b3c5ffb4f88e5c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f657ee09a724d29a00071ee7c6bd78b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9cb8c4f02f58498ab92931b0970e9fdd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be58fa99be5047618084db9a572296ad"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "BERTScore:\n",
      "Precision: 0.8005, Recall: 0.9034, F1: 0.8488\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "sample_indices = random.sample(range(len(train_data)), 3)\n",
    "sample_data = [train_data[i] for i in sample_indices]\n",
    "\n",
    "few_shot_input = \"\"\n",
    "for sample in sample_data:\n",
    "    article_text = sample['article']\n",
    "    highlight_text = sample['highlights']\n",
    "    few_shot_input += f\"Article: {article_text}\\nSummary: {highlight_text}\\n\\n\"\n",
    "\n",
    "print(\"Few-Shot Input Examples:\\n\", few_shot_input)\n",
    "\n",
    "test_article = test_data[0]['article']\n",
    "\n",
    "input_text = few_shot_input + f\"Article: {test_article}\\nSummary:\"\n",
    "\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=1024, padding=True)\n",
    "\n",
    "outputs = model.generate(inputs[\"input_ids\"], max_new_tokens=150, num_beams=4, early_stopping=True, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "generated_summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"Generated Summary: \", generated_summary)\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "expected_summary = test_data[0][\"highlights\"]\n",
    "rouge_scores = scorer.score(expected_summary, generated_summary)\n",
    "\n",
    "print(\"\\nROUGE Scores: \")\n",
    "print(rouge_scores)\n",
    "\n",
    "references = [expected_summary]\n",
    "candidates = [generated_summary]\n",
    "\n",
    "P, R, F1 = score(candidates, references, lang='en')\n",
    "print(\"\\nBERTScore:\")\n",
    "print(f\"Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRUTOdbjQLe5",
    "outputId": "97eb48a0-ef30-4986-a4de-ca14caa7e782"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Few-Shot Input Examples:\n",
      " Article: ATLANTA, Georgia (CNN)  -- The two men who claimed to have found the carcass of Bigfoot have surfaced to say: Hey, it was just a joke. Matt Whitton has been fired from his job as a police officer because of his role in the hoax. Not everyone is laughing. In an exclusive interview with CNN affiliate WSB, the two hoaxers -- car salesman Rick Dyer and now-fired police officer Matt Whitton -- said the whole situation began as a joke and then got out of hand. \"It's just a big hoax, a big joke,\" Dyer said. \"It's Bigfoot,\" Dyer explained. \"Bigfoot doesn't exist.\" Whitton chimed in: \"All this was a big joke. It got into something way bigger than it was supposed to be.\"  Watch the two men explain their \"joke\" Â» . At a news conference in California last week, the two men had stood by their claims that they had discovered Bigfoot's corpse and had it on ice. Scientific analysis would prove it, they said. Not quite. Now the two Georgia men admit that the hairy, icy blob was an Internet-purchased Sasquatch costume stuffed with possum roadkill and slaughterhouse leftovers. Whitton and Dyer say that when they came up with the hoax, they had no idea it would become a media circus. \"It got legs and ran. It's crazy now,\" Dyer told WSB. Co-hoaxer Whitton agrees: \"It started off as some YouTube videos and a Web site. We're all about having fun.\" \"Fun\" isn't exactly how Clayton County Police Chief Jeff Turner sees it. He has kicked Whitton off the police force. \"He lied on national TV,\" Turner says of Whitton, \"so a defense attorney now could say, 'How do we know you're not lying now?' \" Whitton and Dyer had announced that they had found the body of a 7-foot-7-inch, 500-pound half-ape, half-human creature while hiking in the north Georgia mountains in June. They also said they had spotted about three similar living creatures. Still unclear is how much money Whitton and Dyer got out of the hoax. Steve Kulls, who maintains the SquatchDetective Web site and hosts a similarly named Internet radio program, first interviewed Dyer on July 28 for the radio program. On August 12, Kulls said, Dyer and Whitton \"requested an undisclosed sum of money as an advance, expected from the marketing and promotion.\" Two days later, after signing a receipt and counting the money, Dyer and Whitton showed the Searching for Bigfoot team the freezer containing what they claimed was the carcass: \"Something appearing large, hairy and frozen in ice,\" Kulls wrote on the Web site. It was, as many had suspected, an ape-like costume stuffed with entrails. After the news conference last week, Dyer and Whitton disappeared from view. The truth came out over the weekend. In a Web posting this week, Kulls wrote that \"action is being instigated against the perpetrators.\" The two hoaxers have hired attorney Steve Lister to represent them. \"There have been some threats made to them for both civil and criminal prosecution,\" Lister said. The attorney says the Bigfoot incident \"got out of hand.\" Dyer, asked whether he ever thought that the hoopla had become more than just a joke, implied that everyone should have known it was a hoax. \"Well, we told 10 different stories,\" he said. \"Everyone knew we were lying.\"\n",
      "Summary: Two men surface to say Bigfoot hoax was just a joke .\n",
      "Men say their idea of \"having fun\" turned into something bigger than expected .\n",
      "Attorney for men says incident \"got out of hand\"\n",
      "\n",
      "Article: (CNN)  -- Pakistani President Asif Ali Zardari denied his nation was involved in last week's deadly attacks on Mumbai, India, and told CNN on Tuesday he's seen no evidence that a suspect in custody is a Pakistani national as Indian officials claim. Pakistani President Asif Ali Zardari says he believes the Mumbai attackers were \"stateless actors.\" \"I think these are stateless actors who have been operating all throughout the region,\" Zardari said on CNN's \"Larry King Live\" in an interview set to air Tuesday night. \"The gunmen plus the planners, whoever they are, [are] stateless actors who have been holding hostage the whole world.\" At least 179 people were killed when a band of gunmen attacked 10 targets in Mumbai on Wednesday night, triggering three days of battles with police and Indian troops in the heart of the city -- the hub of India's financial and entertainment industries. Most of the deaths occurred at the city's top two hotels: the Oberoi and the Taj Mahal.  Watch Zardari blame \"stateless actors\" Â» . Indian officials have publicly blamed Pakistani militants for the attacks, and called on Pakistan to hand over a group of wanted militant leaders suspected of plotting them. On Tuesday, Pakistani Foreign Minister Shah Mahmood Qureshi proposed a joint investigation into the attacks and said, \"This is not the time to point fingers.\" Zardari confirmed he is willing to have Pakistani security officials participate with India in a joint investigation. \"The state of Pakistan is in no way responsible,\" Zardari told King. \"... Even the White House and the American CIA have said that today. The state of Pakistan is, of course, not involved. We're part of the victims, Larry. I'm a victim. The state of Pakistan is a victim. We are the victims of this war, and I am sorry for the Indians, and I feel sorry for them.\" Indian officials have said that the only suspected attacker in custody has told police he is a Pakistani national. Indian intelligence sources have told CNN's sister network, CNN-IBN, that police believe all the attackers  were Pakistanis. Indian police say nine of the 10 attackers were killed by Indian forces. Asked about the suspect in custody, Zardari said: \"We have not been given any tangible proof to say that he is definitely a Pakistani. I very much doubt it, Larry, that he is a Pakistani.\" He said Pakistan is looking into the allegation, but added, \"Like I said, these are stateless individuals. ... We've had incidents the past two days in Karachi where we've lost more than 40 to 45 people, hundreds injured. These are stateless actors who are moving throughout this region.\" India summoned Pakistan's high commissioner, the top-ranking Pakistani diplomat in New Delhi, to External Affairs Minister Pranab Mukherjee's office Monday to inform him that last week's massacre in Mumbai \"was carried out by elements from Pakistan.\" It renewed a demand that Pakistan hand over a group of militant leaders whose extradition it has sought since a 2001 attack on India's Parliament that brought the South Asian nuclear rivals to the brink of war. \"The government expects that strong action would be taken against those elements, whosoever they may be, responsible for this outrage,\" a statement from India's Foreign Ministry said. \"It was conveyed to the Pakistan high commissioner that Pakistan's actions needed to match the sentiments expressed by its leadership that it wishes to have a qualitatively new relationship with India.\" The list reportedly includes Hafiz Mohammed, the head of Lashkar-e-Tayyiba, a now-banned Islamic militant group that denied last week that it was involved in the Mumbai attack. The group is blamed for the 2001 attack on India's Parliament. \"I am definitely going to look into all the possibility of any proof that is given to us,\" Zardari said. \"At the moment, these are just names of individuals. No proof, no investigation, nothing has been brought forward.\" If proof of the individuals' involvement is provided, he said, \"We would try them in our courts, we would try them in our land, and we would sentence them.\" Indian authorities said the suspect in custody was trained by Lashkar-e-Tayyiba. Zardari told CNN that Lashkar-e-Tayyiba is a \"banned organization\" in Pakistan and around the world. \"If indeed they are involved, we would not know,\" he said. \"Again, they are people who operate outside the system. They operate like -- al Qaeda, for instance, is not state-oriented. They operate something on that mechanism, and ... I've already offered India full cooperation on this incident, and we intend to do that.\" \"I'm firmly committed to fighting terrorism per se,\" he said. \"That's why we are fighting them every day, Larry.\" Asked about the possibility of Indian military strikes against terrorist camps in Pakistan, Zardari said: \"I would not agree with that because this is a time to come together and do a joint investigation and look at the problem in the larger context. We have a larger threat on our hands ... it's a threat throughout the region. So that would be counterproductive.\" Pakistan and India, both nuclear powers, have a tense relationship and have fought three wars since the subcontinent was divided in 1947. On whether the Mumbai attacks could trigger a fourth war, Zardari said: \"Larry, democracies don't go to war. All those wars you're talking about did not take place in any democracy. They all happened in the times of dictators. ... \"The whole nation of Pakistan is united to ... becoming friends with India,\" he said.\n",
      "Summary: Pakistani President Zardari: \"Stateless actors\" behind attacks in Mumbai, India .\n",
      "Indian intelligence sources tell CNN-IBN they believe attackers were Pakistani .\n",
      "Zardari says he doubts suspect in custody is Pakistani .\n",
      "He says he's willing to have Pakistan participate in a joint investigation with India .\n",
      "\n",
      "Article: NEW YORK (CNN) -- It's been five years since Carrie Bradshaw journeyed to Paris in search of true love on the series finale of \"Sex and the City.\" She appeared to have found it in the arms of Mr. Big, and she returned to New York -- and her now-settled friends -- ready for a new start. Sarah Jessica Parker was a driving force in creating the \"Sex and the City\" movie. Then came the inevitable cry: That's it? What happens next? Sarah Jessica Parker, who played Carrie, wanted to find out as well. But the situation had to be right, she said, which prompted a cascade of rumors as plans for a movie came together, fell apart and came together again. Now that the movie is out, Parker -- who's a producer of the film as well as one of its stars -- talked about the journey to making a big-screen \"Sex and the City\" with \"Showbiz Tonight\" anchor A.J. Hammer. The following is an edited version of that interview. CNN: I think a lot of fans, maybe a lot of people, and those of you among the cast, didn't think this day would actually ever come ... but here we are. So how are you feeling deep inside, Sarah? Sarah Jessica Parker: I feel extraordinarily privileged. I've spent the last two years cobbling this movie together. ... It's a once-in-a-lifetime kind of professional experience and one really shouldn't be greedy enough to ask for it twice.  Watch the cast talk about the thrill of \"Sex\" Â» . I have to say that, this last six, eight months, was better than those seven years [the show aired] and I think it's because we all recognize how lucky and unique those seven years were and that this is a story that you don't get to tell twice. It has been, I must say, worth every obstacle and dead end, and fit and start, and every moment that was seemingly impossible. It has been a dream. CNN: And I imagine sitting down for the first time in that room together for the table read, which was, from my understanding, the first time you all actually were in the same room [together] regardless of how much you kept in touch. Tell me a little bit about that moment. Parker: I started putting [the] script back together in April of 2006 ... and that [table read] was a really extraordinary day, because just the perfunctory details of getting people to a table read were complicated. Kim [Cattrall] had been away and Kristin [Davis] had been away and Chris [Noth] had been [doing] his other job, and this magnificent script had arrived and had been everything we hoped for and more. It was basically like being in an alternate universe for about three hours. ... It was a kind of reunion that is very, very special, because you really want to be there. It's not the reunion where you're forced by your parents to meet your aunts and uncles that you see rarely. It's the reunion that you want. I think even more so was that first day on [the] set. When we thought, good God, [writer/director] Michael Patrick [King] and I are actually making this movie, like we got it done, we're here, we're doing it -- what a privilege. CNN: I think we as fans and viewers actually got a sense of what that feeling was like when we saw you all together on \"Oprah,\" because the energy was ... palpable. ... But we're talking about the perceived drama around this whole project. (Rumors have abounded about friction between the stars.) One of my producers said while we were watching the TV, \"Are they going to sit near each other?\" \"Why are they putting Chris in the middle of all of them?\" Hearing that, does it make you mad? Parker: I find it slightly -- it's not that I'm mad. I expect better from people. I think it's really beneath me, to keep defending myself. I have a 35-year career. I have an impeccable character, I really pride myself in my work ethic and the way I treat people. And I think Kim would say the same and Cynthia would say the same. And I love Kim, and I wanted her to be in this movie. We couldn't have done it without her, we couldn't have done it without Kristin, we couldn't have done it without Cynthia [Nixon], nor could we have done it without Chris.  Watch Cattrall address the rumors Â» . You know, this is a story that people like to tell about women. Why? I don't know. Is it that interesting? Probably not. So once again I just have to say it doesn't define the experience. Nobody can take the experience away. It's far more interesting for me to talk about my affection for this cast than to start to deny a sad old beaten tale. CNN: You seem to have what goes on in the media in perspective -- and you have to, being at the game as long as you've been. To that end, one of the things that I've always admired about you and [husband] Matthew [Broderick] and I think a lot of people do, is how you've managed your public or your private life while being in the glare of the spotlight. ... Now I know one of the main reasons you guys are able to make it work is because you don't talk about your private lives, which is great and I applaud that. That said, is there something that you can tell me about what it is about your relationship that enables you to make it work separate from that? Parker: I wouldn't make any proclamations about why I have a marriage that, to me, is successful. I would just say that we've chosen to live in a city where we are not the most interesting people. This is a city that is about industry and finance and publishing and architecture and the arts and education and academia, and the movie industry fits into it in some small way, but there are a lot of people of important interest and I think that it's a conscious choice to live in a place where we're bumping up against humanity. We run to the market on our own, we take the subway, and we integrate into our city, and we become a part of the fabric and I think it's really been to our benefit and certainly to our son. Does it mean that we are not scrutinized and that we don't have paparazzi every single day at our house? No, but it is a city where you can't live behind a gate, you can't drive up in a car and be protected. You walk out the door and it is what it is. So you reconcile those things and you make the best choices you can. CNN: Is it the end of \"Sex and the City\"? What does your gut tell you? Parker: My gut tells me it's up to you and your colleagues and the critics and the people who show up. The future is dictated not by us at this point, and I think Michael Patrick and I have been so focused at getting this movie up on the big screen, that we haven't thought about the future. Doing this was more than we could have asked for. So anything beyond that is really kind of out of our hands in a perfectly wonderful way.\n",
      "Summary: Sarah Jessica Parker: \"Sex and the City\" \"has been a dream\"\n",
      "Rumors of friction? \"Beneath me to keep defending myself\"\n",
      "Marriage to Matthew Broderick works because pair lives normal N.Y. life .\n",
      "\n",
      "\n",
      "Generated Summary:  Article: ATLANTA, Georgia (CNN)  -- The two men who claimed to have found the carcass of Bigfoot have surfaced to say: Hey, it was just a joke. Matt Whitton has been fired from his job as a police officer because of his role in the hoax. Not everyone is laughing. In an exclusive interview with CNN affiliate WSB, the two hoaxers -- car salesman Rick Dyer and now-fired police officer Matt Whitton -- said the whole situation began as a joke and then got out of hand. \"It's just a big hoax, a big joke,\" Dyer said. \"It's Bigfoot,\" Dyer explained. \"Bigfoot doesn't exist.\" Whitton chimed in: \"All this was a big joke. It got into something way bigger than it was supposed to be.\"  Watch the two men explain their \"joke\" Â» . At a news conference in California last week, the two men had stood by their claims that they had discovered Bigfoot's corpse and had it on ice. Scientific analysis would prove it, they said. Not quite. Now the two Georgia men admit that the hairy, icy blob was an Internet-purchased Sasquatch costume stuffed with possum roadkill and slaughterhouse leftovers. Whitton and Dyer say that when they came up with the hoax, they had no idea it would become a media circus. \"It got legs and ran. It's crazy now,\" Dyer told WSB. Co-hoaxer Whitton agrees: \"It started off as some YouTube videos and a Web site. We're all about having fun.\" \"Fun\" isn't exactly how Clayton County Police Chief Jeff Turner sees it. He has kicked Whitton off the police force. \"He lied on national TV,\" Turner says of Whitton, \"so a defense attorney now could say, 'How do we know you're not lying now?' \" Whitton and Dyer had announced that they had found the body of a 7-foot-7-inch, 500-pound half-ape, half-human creature while hiking in the north Georgia mountains in June. They also said they had spotted about three similar living creatures. Still unclear is how much money Whitton and Dyer got out of the hoax. Steve Kulls, who maintains the SquatchDetective Web site and hosts a similarly named Internet radio program, first interviewed Dyer on July 28 for the radio program. On August 12, Kulls said, Dyer and Whitton \"requested an undisclosed sum of money as an advance, expected from the marketing and promotion.\" Two days later, after signing a receipt and counting the money, Dyer and Whitton showed the Searching for Bigfoot team the freezer containing what they claimed was the carcass: \"Something appearing large, hairy and frozen in ice,\" Kulls wrote on the Web site. It was, as many had suspected, an ape-like costume stuffed with entrails. After the news conference last week, Dyer and Whitton disappeared from view. The truth came out over the weekend. In a Web posting this week, Kulls wrote that \"action is being instigated against the perpetrators.\" The two hoaxers have hired attorney Steve Lister to represent them. \"There have been some threats made to them for both civil and criminal prosecution,\" Lister said. The attorney says the Bigfoot incident \"got out of hand.\" Dyer, asked whether he ever thought that the hoopla had become more than just a joke, implied that everyone should have known it was a hoax. \"Well, we told 10 different stories,\" he said. \"Everyone knew we were lying.\"\n",
      "Summary: Two men surface to say Bigfoot hoax was just a joke .\n",
      "Men say their idea of \"having fun\" turned into something bigger than expected .\n",
      "Attorney for men says incident \"got out of hand\"\n",
      "\n",
      "Article: (CNN)  -- Pakistani President Asif Ali Zardari denied his nation was involved in last week's deadly attacks on Mumbai, India, and told CNN on Tuesday he's seen no evidence that a suspect in custody is a Pakistani national as Indian officials claim. Pakistani President Asif Ali Zardari says he believes the Mumbai attackers were \"stateless actors.\" \"I think these are stateless actors who have been operating all throughout the region,\" Zardari said on CNN's \"Larry King Live\" in an interview set to air Tuesday night. \"The gunmen plus the planners, whoever they are, [are] stateless actors who have been holding hostage the whole world.\" At least 179 people were killed when a band of gunmen attacked 10 targets in Mumbai on Wednesday night, triggering three days of battles with police and Indian troops in the heart of the city -- the hub of India's financial and entertainment industries. Most of the deaths occurred at the city's top two hotels: the Taj Mahal Palace Hotel and the Oberoi Trident Hotel. Zardari said he's seen no evidence that a suspect in custody is a Pakistani national as Indian officials claim. \"I think these are stateless actors who have been operating all throughout the region,\" Zardari said on CNN's \"Larry King Live\" in an interview set to air Tuesday night. \"The gunmen plus the planners, whoever they are, [are] stateless actors who have been holding hostage the whole world.\" At least 179 people were killed when a band of gunmen attacked 10 targets in Mumbai on Wednesday night, triggering three days of battles with police and Indian troops in the heart of the city -- the hub of India's\n",
      "\n",
      "ROUGE Scores: \n",
      "{'rouge1': Score(precision=0.013559322033898305, recall=0.35294117647058826, fmeasure=0.026115342763873773), 'rouge2': Score(precision=0.0011312217194570137, recall=0.030303030303030304, fmeasure=0.0021810250817884407), 'rougeL': Score(precision=0.010169491525423728, recall=0.2647058823529412, fmeasure=0.019586507072905327)}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "BERTScore:\n",
      "Precision: 0.7652, Recall: 0.8253, F1: 0.7941\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\"\"\n",
    "                                                                                                                                                                      Ú†Ø§Ù„Ø´â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…ØªÙ† ØªÙˆÙ„ÛŒØ¯ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø±Øª Ùˆ Ø±ÙˆÚ˜\n",
    "Ø±ÙˆÚ˜ Ø¨ÛŒØ´ØªØ± Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øªâ€ŒÙ‡Ø§ÛŒ ÙˆØ§Ú˜Ú¯Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÙ¾Ø±Ø¯Ø§Ø²Ø¯ØŒ Ø§Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¹Ù†Ø§ÛŒ Ø¹Ù…ÛŒÙ‚â€ŒØªØ± Ù…Ù†Ø§Ø³Ø¨ Ù†ÛŒØ³Øª. Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø±Øª Ø¯Ø± Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ù‡ØªØ±ÛŒ Ø¯Ø§Ø±Ø¯ Ø§Ù…Ø§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù…Ù†Ø§Ø¨Ø¹ Ø¨ÛŒØ´ØªØ± Ùˆ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡â€ŒØªØ± Ø¯Ø§Ø±Ø¯. Ø§Ù†ØªØ®Ø§Ø¨ Ø¨ÛŒÙ† Ø§ÛŒÙ† Ø¯Ùˆ Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ù‡ Ø§ÙˆÙ„ÙˆÛŒØª Ø¨ÛŒÙ† Ø¯Ù‚Øª Ù…Ø¹Ù†Ø§ÛŒÛŒ Ùˆ Ø³Ø±Ø¹Øª Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¯Ø§Ø±Ø¯.\n",
    "\n",
    "                                                                                                                                                                                            Ú†Ø±Ø§ Ø¨Ø§ÛŒØ¯ Ø§Ø² Ú©ÙˆØ§Ù†ØªØ§ÛŒØ²ÛŒØ´Ù† Û´ Ø¨ÛŒØªÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯ØŸ\n",
    "Ú©ÙˆØ§Ù†ØªØ§ÛŒØ²ÛŒØ´Ù† Û´ Ø¨ÛŒØªÛŒ Ø¨Ø§Ø¹Ø« Ú©Ø§Ù‡Ø´ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø¯Ù„ Ùˆ Ø¨Ù‡Ø¨ÙˆØ¯ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø­Ø¯ÙˆØ¯ Ù…ÙÛŒØ¯ Ø§Ø³Øª. Ø§ÛŒÙ† Ø±ÙˆØ´ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ø§Ø¯Ù‡ Ùˆ Ø¯Ø± Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¨Ø§ÛŒÙ„ ÛŒØ§ Ú©Ù…â€ŒÙ‚Ø¯Ø±Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ Ø¯Ø§Ø±Ø¯ØŒ Ø§Ù…Ø§ Ø¯Ù‚Øª Ù…Ø¯Ù„ Ú©Ø§Ù‡Ø´ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯. Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø³Ø±Ø¹Øª Ø¨Ø§Ù„Ø§ Ø§Ø³Øª.\n",
    "\n",
    "                                                                                                                                                                                             Ú†Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø±Ø§ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ú©Ù…â€ŒØ´Ø§Øª Ù‡Ø³ØªÙ†Ø¯ØŸ\n",
    "Ø¯Ø± Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ú©Ù…â€ŒØ´Ø§ØªØŒ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø±Øª Ø¨Ù‡ØªØ± Ø§Ø² Ø±ÙˆÚ˜ Ø¹Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ Ú†ÙˆÙ† Ø¯Ù‚Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø± Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ØªØ·Ø§Ø¨Ù‚ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¯Ø§Ø±Ù†Ø¯. Ø§ÛŒÙ† Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø¨Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ù†Ø¯ Ú©Ù‡ Ø¯Ø±Ú© Ø¹Ù…ÛŒÙ‚ÛŒ Ø§Ø² Ù…Ø¹Ù†Ø§ÛŒ Ù…ØªÙ† Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯. Ù…Ø¹ÛŒØ§Ø± Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ù‡ Ù†ÙˆØ¹ Ù…ØªÙ† Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ Ø®Ø§Øµ Ø¯Ø§Ø±Ø¯.\n",
    "\n",
    "                                                                                                                                                                           ØªÙØ§ÙˆØª Ø¨ÛŒÙ† Ù†Ø³Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡ ÛŒØ§ Ù†Ø³Ø®Ù‡ ØªÙ†Ø¸ÛŒÙ…â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§\n",
    "Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ÙˆØ¸Ø§ÛŒÙ Ø¹Ù…ÙˆÙ…ÛŒ Ø·Ø±Ø§Ø­ÛŒ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø¶Ø§ÙÛŒ Ø¯Ø§Ø±Ù†Ø¯. Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ÙˆØ¸Ø§ÛŒÙ Ø®Ø§ØµØŒ Ù…Ø§Ù†Ù†Ø¯ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒØŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ùˆ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ù‡ØªØ±ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯. Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ù‡ Ù†ÙˆØ¹ ÙˆØ¸ÛŒÙÙ‡ Ùˆ Ù…Ù†Ø§Ø¨Ø¹ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯.\n",
    "\n",
    "https://ai.google.dev/edge/litert/models/post_training_quantization\n",
    "https://huggingface.co/spaces/evaluate-metric/bertscore\n",
    "https://medium.com/towardsdev/unlocking-the-potential-of-few-shot-learning-a-synthetic-dataset-approach-to-efficient-machine-284deeda1294\n",
    "\"\"\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jn7-Rwy8SmzR",
    "outputId": "e471ba78-d4d1-48bd-bbc9-94c3fade7777"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "                                                                                                                                                                      Ú†Ø§Ù„Ø´â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…ØªÙ† ØªÙˆÙ„ÛŒØ¯ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø±Øª Ùˆ Ø±ÙˆÚ˜\n",
      "Ø±ÙˆÚ˜ Ø¨ÛŒØ´ØªØ± Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øªâ€ŒÙ‡Ø§ÛŒ ÙˆØ§Ú˜Ú¯Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÙ¾Ø±Ø¯Ø§Ø²Ø¯ØŒ Ø§Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¹Ù†Ø§ÛŒ Ø¹Ù…ÛŒÙ‚â€ŒØªØ± Ù…Ù†Ø§Ø³Ø¨ Ù†ÛŒØ³Øª. Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø±Øª Ø¯Ø± Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ù‡ØªØ±ÛŒ Ø¯Ø§Ø±Ø¯ Ø§Ù…Ø§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù…Ù†Ø§Ø¨Ø¹ Ø¨ÛŒØ´ØªØ± Ùˆ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡â€ŒØªØ± Ø¯Ø§Ø±Ø¯. Ø§Ù†ØªØ®Ø§Ø¨ Ø¨ÛŒÙ† Ø§ÛŒÙ† Ø¯Ùˆ Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ù‡ Ø§ÙˆÙ„ÙˆÛŒØª Ø¨ÛŒÙ† Ø¯Ù‚Øª Ù…Ø¹Ù†Ø§ÛŒÛŒ Ùˆ Ø³Ø±Ø¹Øª Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¯Ø§Ø±Ø¯.\n",
      "\n",
      "                                                                                                                                                                                            Ú†Ø±Ø§ Ø¨Ø§ÛŒØ¯ Ø§Ø² Ú©ÙˆØ§Ù†ØªØ§ÛŒØ²ÛŒØ´Ù† Û´ Ø¨ÛŒØªÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯ØŸ \n",
      "Ú©ÙˆØ§Ù†ØªØ§ÛŒØ²ÛŒØ´Ù† Û´ Ø¨ÛŒØªÛŒ Ø¨Ø§Ø¹Ø« Ú©Ø§Ù‡Ø´ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø¯Ù„ Ùˆ Ø¨Ù‡Ø¨ÙˆØ¯ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø­Ø¯ÙˆØ¯ Ù…ÙÛŒØ¯ Ø§Ø³Øª. Ø§ÛŒÙ† Ø±ÙˆØ´ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ø§Ø¯Ù‡ Ùˆ Ø¯Ø± Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¨Ø§ÛŒÙ„ ÛŒØ§ Ú©Ù…â€ŒÙ‚Ø¯Ø±Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ Ø¯Ø§Ø±Ø¯ØŒ Ø§Ù…Ø§ Ø¯Ù‚Øª Ù…Ø¯Ù„ Ú©Ø§Ù‡Ø´ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯. Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø³Ø±Ø¹Øª Ø¨Ø§Ù„Ø§ Ø§Ø³Øª.\n",
      "\n",
      "                                                                                                                                                                                             Ú†Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø±Ø§ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ú©Ù…â€ŒØ´Ø§Øª Ù‡Ø³ØªÙ†Ø¯ØŸ\n",
      "Ø¯Ø± Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ú©Ù…â€ŒØ´Ø§ØªØŒ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø±Øª Ø¨Ù‡ØªØ± Ø§Ø² Ø±ÙˆÚ˜ Ø¹Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ Ú†ÙˆÙ† Ø¯Ù‚Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø± Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ØªØ·Ø§Ø¨Ù‚ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¯Ø§Ø±Ù†Ø¯. Ø§ÛŒÙ† Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø¨Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ù†Ø¯ Ú©Ù‡ Ø¯Ø±Ú© Ø¹Ù…ÛŒÙ‚ÛŒ Ø§Ø² Ù…Ø¹Ù†Ø§ÛŒ Ù…ØªÙ† Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯. Ù…Ø¹ÛŒØ§Ø± Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ù‡ Ù†ÙˆØ¹ Ù…ØªÙ† Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ Ø®Ø§Øµ Ø¯Ø§Ø±Ø¯.\n",
      "\n",
      "                                                                                                                                                                           ØªÙØ§ÙˆØª Ø¨ÛŒÙ† Ù†Ø³Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡ ÛŒØ§ Ù†Ø³Ø®Ù‡ ØªÙ†Ø¸ÛŒÙ…â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§\n",
      "Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ÙˆØ¸Ø§ÛŒÙ Ø¹Ù…ÙˆÙ…ÛŒ Ø·Ø±Ø§Ø­ÛŒ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø¶Ø§ÙÛŒ Ø¯Ø§Ø±Ù†Ø¯. Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ÙˆØ¸Ø§ÛŒÙ Ø®Ø§ØµØŒ Ù…Ø§Ù†Ù†Ø¯ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒØŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ùˆ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ù‡ØªØ±ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯. Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ù‡ Ù†ÙˆØ¹ ÙˆØ¸ÛŒÙÙ‡ Ùˆ Ù…Ù†Ø§Ø¨Ø¹ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯.\n",
      "\n",
      "https://ai.google.dev/edge/litert/models/post_training_quantization\n",
      "https://huggingface.co/spaces/evaluate-metric/bertscore\n",
      "https://medium.com/towardsdev/unlocking-the-potential-of-few-shot-learning-a-synthetic-dataset-approach-to-efficient-machine-284deeda1294\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjwd3--csPHf"
   },
   "source": [
    "*Ø¨Ø®Ø´ Ø¯ÙˆÙ…:*\n",
    "---\n",
    "# Ù¾Ø§Ø³Ø® Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯:"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! pip install bitsandbytes\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HxNx1wyElvAW",
    "outputId": "926aa6e3-b9da-4c5e-91f1-e4d85e05d37d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.42.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->bitsandbytes) (1.26.4)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T08:00:32.993528Z",
     "start_time": "2024-12-19T08:00:15.629945Z"
    },
    "id": "MTebNhZVsPHf"
   },
   "outputs": [],
   "source": [
    "\n",
    "model_id = \"HuggingFaceTB/SmolLM2-360M\"  \n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  \n",
    "    bnb_4bit_use_double_quant=True,  \n",
    "    bnb_4bit_quant_type=\"nf4\",  \n",
    "    bnb_4bit_compute_dtype=torch.float16  \n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T08:09:09.384987Z",
     "start_time": "2024-12-19T08:09:07.500714Z"
    },
    "id": "W_8hj9wKsPHf",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "outputId": "98cb72ef-c829-41ba-8f30-1747b2cd3c56"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.865652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.865570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.865474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.865410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.865255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token  \n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    output_texts = []\n",
    "    for i in range(len(examples)):\n",
    "        article_text = examples['article'][i] \n",
    "        highlight_text = examples['highlights'][i] \n",
    "        text = f\"### Article: {article_text} \\n ### Summary: {highlight_text}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,                \n",
    "    lora_alpha=32,      \n",
    "    lora_dropout=0.1,   \n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  \n",
    "    bias=\"none\",        \n",
    "    task_type=\"CAUSAL_LM\"  \n",
    ")\n",
    "\n",
    "dataset = load_dataset('cnn_dailymail', '3.0.0')\n",
    "train_data = dataset['train'].select(range(5000))\n",
    "val_data = dataset['validation'].select(range(500))\n",
    "test_data = dataset['test'].select(range(100))\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",               \n",
    "    evaluation_strategy=\"epoch\",          \n",
    "    learning_rate=2e-5,                   \n",
    "    per_device_train_batch_size=2,        \n",
    "    per_device_eval_batch_size=2,         \n",
    "    num_train_epochs=5,                   \n",
    "    weight_decay=0.01,                    \n",
    "    logging_dir='./logs',                 \n",
    "    logging_steps=200,                    \n",
    "    save_steps=1000,                      \n",
    "    save_total_limit=2,                   \n",
    "    fp16=True,                            \n",
    "    gradient_accumulation_steps=8,        \n",
    "    max_grad_norm=1.0,                    \n",
    "    dataloader_num_workers=4,             \n",
    ")\n",
    "\n",
    "peft_config =LoraConfig(\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        r=64,\n",
    "        bias=\"none\",\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,                \n",
    "    args=training_args,              \n",
    "    train_dataset=train_data,         \n",
    "    eval_dataset=val_data,            \n",
    "    peft_config=peft_config,         \n",
    "    tokenizer=tokenizer,         \n",
    "    formatting_func=preprocess_function,\n",
    "    )\n",
    "trainer.train()\n",
    "trainer.save_model(\"./fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./fine_tuned_model\")\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "rouge1_scores = []\n",
    "rouge2_scores = []\n",
    "rougeL_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    sample_article = test_data[i][\"article\"]\n",
    "    expected_summary = test_data[i][\"highlights\"]\n",
    "\n",
    "    generated_summary = summarizer(sample_article, max_length=150, min_length=50, do_sample=False)\n",
    "\n",
    "    generated_summary_text = generated_summary[0]['summary_text']\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_scores = scorer.score(expected_summary, generated_summary_text)\n",
    "\n",
    "    rouge1_scores.append(rouge_scores['rouge1'].fmeasure)\n",
    "    rouge2_scores.append(rouge_scores['rouge2'].fmeasure)\n",
    "    rougeL_scores.append(rouge_scores['rougeL'].fmeasure)\n",
    "\n",
    "    references = [expected_summary]\n",
    "    candidates = [generated_summary_text]\n",
    "\n",
    "    P, R, F1 = score(candidates, references, lang='en')\n",
    "\n",
    "    precision_scores.append(P.mean().item()) \n",
    "    recall_scores.append(R.mean().item())\n",
    "    f1_scores.append(F1.mean().item())\n",
    "\n",
    "avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores)\n",
    "avg_rouge2 = sum(rouge2_scores) / len(rouge2_scores)\n",
    "avg_rougeL = sum(rougeL_scores) / len(rougeL_scores)\n",
    "\n",
    "avg_precision = sum(precision_scores) / len(precision_scores)\n",
    "avg_recall = sum(recall_scores) / len(recall_scores)\n",
    "avg_f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print(\"\\nAverage ROUGE Scores:\")\n",
    "print(f\"ROUGE-1: {avg_rouge1:.4f}\")\n",
    "print(f\"ROUGE-2: {avg_rouge2:.4f}\")\n",
    "print(f\"ROUGE-L: {avg_rougeL:.4f}\")\n",
    "print(\"\\nAverage BERTScore:\")\n",
    "print(f\"Precision: {avg_precision:.4f}, Recall: {avg_recall:.4f}, F1: {avg_f1:.4f}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "eab432c4acb04f0b936a0bd5899f29bf",
      "5196cb64fb4f4bda97c6545dc9f65e81",
      "ffee2c1d9ef8400095373494e131c6c5",
      "380aec84eb1544b3999a732ec671c385",
      "0202d562c6484b79970cc687f9818e53",
      "006ba9e9a1184ad0964b7cdbdade1ea3",
      "e480823dfc724f928c40c05b3a9b6baa",
      "04f407a173584ca286d66bf25175dc08",
      "b763559aad484f3a99f3b9bb6e8faef8",
      "45f8a1fc9f384dab945e2db2da9979b6",
      "be7fe67b4b1048909d17d3f42e3c4359",
      "d7862d5423844ef297e6ea1556cc247f",
      "f650743c65b04be584e5efb68ce6428b",
      "9f4be734797d44659f1cc7fff4388c9a",
      "34bfd5c375e94d2d9c4530c8abe142f2",
      "17e38805f88548c4909bbb6f9309a62c",
      "4de0c773fe59434c8fa8f9ecef17da4d",
      "b170865c91794352addec7549f7f7edb",
      "6de28b34e8374a72b5694e4478446cd3",
      "89f10c4cfaa44424adc54328a62c2b88",
      "82ab2586529248f18555f8cdee44e3e1",
      "0f97fa14fcb04fc6baf86b3e8579a9c8",
      "413bab98de724648a1c0268851d353d6",
      "ac432e42ed5f4b398890a07dd8e0b25c",
      "e3c47102172144f1a859bb52441695e1",
      "d45e11c95e9a43faa1c67b98b5b54f4c",
      "b77865c232734782ab7875a89365bad9",
      "dbe55f668dcc4a36a3a937dec252e09c",
      "97739abf70e849b3afe47969d93d15ae",
      "152964a4a68a4bf5b30a7a43fc4a7a32",
      "17c163e26dd74c81bcffc84a9e3ac304",
      "d3a919fa9f5d414483373a4fd16ad551",
      "4c421abe451d432d9313d1ea1a0ce50d",
      "4ddea80f1bd44bf2a3f47532230554ce",
      "72e832e88bba421f91f73387ad6fbf9f",
      "554288cc81ff470abee2fcb950da5d87",
      "8c62428b3635486986f5069a8625afa3",
      "7d691f3bc547472097fbe59ef85f8583",
      "59d5c60c520c4b00916e43bdaee592df",
      "057987f750d74e439eacbc7ec5bb645b",
      "5977480e65fd418bbcaf96a9943e1c2e",
      "01489587cb41469ca5905f08a0301aea",
      "044bbc64e2e044cb809cba03e119d99d",
      "beed7bd115844affa65a31b0a00bf63b",
      "853441bf4798409b96442626fcd898ec",
      "1e0c1bcee7c845e998d2a313dd705dac",
      "90ad93fb42bf40bf82f4aeeec2a1e35d",
      "432395dc6aa04dbba7242d1994cf9138",
      "9d0cc52f7c4c4cbdacaa98a0d354e44a",
      "18c9681cdb844845ae2e61bfadf22ef1",
      "48704318a284471ea88f61b111114080",
      "5fa883f7aa2244ab8b839713c3a3038b",
      "14ca400510c845d9bef73c448f0bd7c1",
      "ee9e83493a8a41e5b2d71651d76f2503",
      "c59280b697fb4f78976b95d3bad62360",
      "484385bb0f964adfbbb894fbe6a1a6cd",
      "e0a3e168a37a4799b5708e4134bf582e",
      "43762be424e84b93a81effc525c22fd3",
      "c0698dae2e8a45138fbc7ca8a3a83607",
      "3529dee8539c41e4893ab21f06686fbe",
      "7bb879d313f543d7a28aea2a9867fc78",
      "85a4db0019994a5daedc3eaaa5bd782b",
      "41c37905f551467d966c94e2ea10e858",
      "d4c6e32402d74a84b6d6aea59884d59b",
      "10310e310dcf49fca5088ad989f07cf6",
      "29c25c51eb604113b32e927b7f28429d"
     ]
    },
    "id": "L5pqwsmlfLz-",
    "outputId": "012f76eb-93e8-4c32-915e-ece23d774a32"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The model 'LlamaForCausalLM' is not supported for summarization. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 720, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eab432c4acb04f0b936a0bd5899f29bf"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7862d5423844ef297e6ea1556cc247f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "413bab98de724648a1c0268851d353d6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ddea80f1bd44bf2a3f47532230554ce"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "853441bf4798409b96442626fcd898ec"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "484385bb0f964adfbbb894fbe6a1a6cd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 511, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 958, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 245, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 442, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 604, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1033, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 491, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 399, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 151, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Your max_length is set to 150, but your input_length is only 147. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=73)\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 646, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 613, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1235, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 376, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1340, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 904, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1501, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1156, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 522, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1181, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 991, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1208, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 457, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 509, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1295, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 368, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 568, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 802, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 831, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 480, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1967, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 619, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 570, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 416, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1015, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1327, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1511, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 687, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 2457, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 293, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1937, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 392, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 465, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 944, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 275, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 375, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1258, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 620, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 254, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1165, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 879, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 807, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 623, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 954, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 343, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 295, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 950, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 652, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 595, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 309, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1632, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 184, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 152, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 255, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 175, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1220, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 474, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 289, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 241, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 382, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 759, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1325, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 150, but your input_length is only 127. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=63)\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 758, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 354, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 767, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1030, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 178, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1613, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 379, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 482, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 512, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 202, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1244, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 438, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 537, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 464, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 498, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 215, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 612, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 952, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1086, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 559, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1239, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 308, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 515, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1281, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Average ROUGE Scores:\n",
      "ROUGE-1: 0.1347\n",
      "ROUGE-2: 0.0695\n",
      "ROUGE-L: 0.1004\n",
      "\n",
      "Average BERTScore:\n",
      "Precision: 0.8034, Recall: 0.8861, F1: 0.8426\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\"\"\n",
    "Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø³Ø±ÛŒØ¹â€ŒØªØ± Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù…ØªØ± Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ø¯Ø± Ù…Ø¯Ù„ Ø§Ø³Ù…ÙˆÙ„â€ŒØ§Ù„â€ŒØ§Ù…Û²-Û³Û¶Û°M Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒ Ø¨Ø§Ø´Ø¯. Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù†ØªØ§ÛŒØ¬ Ø±ÙˆÚ˜ Ùˆ Ø¨Ø±ØªØ±Ø³Ú©ÙˆØ± Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù…Ø¯Ù„ Ù…Ø´Ø§Ø¨Ù‡ Ù…Ø¯Ù„ Ø¨Ø²Ø±Ú¯â€ŒØªØ± Ø§Ø³ØªØŒ Ø§ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø§ Ù…ØµØ±Ù Ù…Ù†Ø§Ø¨Ø¹ Ú©Ù…ØªØ± Ùˆ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ù‡ Ú©Ø§Ø± Ù…ÛŒâ€ŒØ¢ÛŒØ¯.\n",
    "\n",
    "Ø§Ù…Ø§ Ø§Ú¯Ø± Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ØªØ± Ùˆ ØªÙˆØ§Ù†Ø§ÛŒÛŒ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ø¯Ø§Ø±Ù… Ùˆ Ù…Ù†Ø§Ø¨Ø¹ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø± Ø§Ø®ØªÛŒØ§Ø± Ø¯Ø§Ø±Ù…ØŒ Ù…Ø¯Ù„ Ø§Ø³Ù…ÙˆÙ„â€ŒØ§Ù„â€ŒØ§Ù…Û²-Û±.Û·B Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ú¯Ø²ÛŒÙ†Ù‡ Ø¨Ù‡ØªØ±ÛŒ Ø¨Ø§Ø´Ø¯. Ø§Ú¯Ø±Ú†Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± ØªÙØ§ÙˆØª Ø¹Ù…Ù„Ú©Ø±Ø¯ÛŒ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø¨Ø§ Ù…Ø¯Ù„ Ú©ÙˆÚ†Ú©â€ŒØªØ± Ù†Ø¯Ø§Ø±Ø¯ØŒ Ø§Ù…Ø§ Ø¯Ø± Ø´Ø±Ø§ÛŒØ· Ø®Ø§Øµ ÛŒØ§ Ù¾Ø³ Ø§Ø² ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±ØŒ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ù‡ØªØ±ÛŒ Ø®ÙˆØ§Ù‡Ø¯ Ø¯Ø§Ø´Øª. Ø§Ù„Ø¨ØªÙ‡ Ù…Ù† Ø¯Ø± Ù‡Ø±Ø¯Ùˆ Ø§Ø² ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ù…Ø¯Ù„ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¢Ø¯Ø§Ù¾ØªÙˆØ±Ù‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø³Ø±ÛŒØ¹ (SFT) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯Ù… Ùˆ Ù†Ù…ÛŒâ€ŒØ¯Ø§Ù†Ø³ØªÙ… Ú©Ù‡ Ù‚Ø±Ø§Ø± Ø§Ø³Øª Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯ Ùˆ ÙÚ©Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù… Ø§Ú¯Ø± Ø§Ø² SFT Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒÚ©Ø±Ø¯Ù…ØŒ Ù†ØªÛŒØ¬Ù‡ Ù…Ø¯Ù„ Ø§Ø³Ù…ÙˆÙ„â€ŒØ§Ù„â€ŒØ§Ù…Û²-Û³Û¶Û°M Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ù…ÛŒâ€ŒØ´Ø¯.\n",
    "\"\"\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vcytw01uit9V",
    "outputId": "10faacd2-4022-4598-a505-cf3ea2475129"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø³Ø±ÛŒØ¹â€ŒØªØ± Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù…ØªØ± Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ø¯Ø± Ù…Ø¯Ù„ Ø§Ø³Ù…ÙˆÙ„â€ŒØ§Ù„â€ŒØ§Ù…Û²-Û³Û¶Û°M Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒ Ø¨Ø§Ø´Ø¯. Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù†ØªØ§ÛŒØ¬ Ø±ÙˆÚ˜ Ùˆ Ø¨Ø±ØªØ±Ø³Ú©ÙˆØ± Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù…Ø¯Ù„ Ù…Ø´Ø§Ø¨Ù‡ Ù…Ø¯Ù„ Ø¨Ø²Ø±Ú¯â€ŒØªØ± Ø§Ø³ØªØŒ Ø§ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø§ Ù…ØµØ±Ù Ù…Ù†Ø§Ø¨Ø¹ Ú©Ù…ØªØ± Ùˆ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ù‡ Ú©Ø§Ø± Ù…ÛŒâ€ŒØ¢ÛŒØ¯.\n",
      "\n",
      "Ø§Ù…Ø§ Ø§Ú¯Ø± Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ØªØ± Ùˆ ØªÙˆØ§Ù†Ø§ÛŒÛŒ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ø¯Ø§Ø±Ù… Ùˆ Ù…Ù†Ø§Ø¨Ø¹ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø± Ø§Ø®ØªÛŒØ§Ø± Ø¯Ø§Ø±Ù…ØŒ Ù…Ø¯Ù„ Ø§Ø³Ù…ÙˆÙ„â€ŒØ§Ù„â€ŒØ§Ù…Û²-Û±.Û·B Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ú¯Ø²ÛŒÙ†Ù‡ Ø¨Ù‡ØªØ±ÛŒ Ø¨Ø§Ø´Ø¯. Ø§Ú¯Ø±Ú†Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± ØªÙØ§ÙˆØª Ø¹Ù…Ù„Ú©Ø±Ø¯ÛŒ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø¨Ø§ Ù…Ø¯Ù„ Ú©ÙˆÚ†Ú©â€ŒØªØ± Ù†Ø¯Ø§Ø±Ø¯ØŒ Ø§Ù…Ø§ Ø¯Ø± Ø´Ø±Ø§ÛŒØ· Ø®Ø§Øµ ÛŒØ§ Ù¾Ø³ Ø§Ø² ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±ØŒ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ù‡ØªØ±ÛŒ Ø®ÙˆØ§Ù‡Ø¯ Ø¯Ø§Ø´Øª. Ø§Ù„Ø¨ØªÙ‡ Ù…Ù† Ø¯Ø± Ù‡Ø±Ø¯Ùˆ Ø§Ø² ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ù…Ø¯Ù„ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¢Ø¯Ø§Ù¾ØªÙˆØ±Ù‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø³Ø±ÛŒØ¹ (SFT) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯Ù… Ùˆ Ù†Ù…ÛŒâ€ŒØ¯Ø§Ù†Ø³ØªÙ… Ú©Ù‡ Ù‚Ø±Ø§Ø± Ø§Ø³Øª Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯ Ùˆ ÙÚ©Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù… Ø§Ú¯Ø± Ø§Ø² SFT Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒÚ©Ø±Ø¯Ù…ØŒ Ù†ØªÛŒØ¬Ù‡ Ù…Ø¯Ù„ Ø§Ø³Ù…ÙˆÙ„â€ŒØ§Ù„â€ŒØ§Ù…Û²-Û³Û¶Û°M Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ù…ÛŒâ€ŒØ´Ø¯.\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\"\"\n",
    "    Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…â€ŒÙ…Ù†Ø¸ÙˆØ±Ù‡ Ø¨Ø²Ø±Ú¯ (Ø¨Ø¯ÙˆÙ† Ø¢Ù…ÙˆØ²Ø´) Ø¯Ø± Ú†Ù‡ Ø³Ù†Ø§Ø±ÛŒÙˆÛŒÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³ØªØŸ\n",
    "    Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…â€ŒÙ…Ù†Ø¸ÙˆØ±Ù‡ Ø¨Ø²Ø±Ú¯ Ø¨Ø±Ø§ÛŒ ÙˆØ¸Ø§ÛŒÙ Ø¹Ù…ÙˆÙ…ÛŒ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÙˆØ¹ Ø¯Ø§Ø±Ù†Ø¯ Ù…Ù†Ø§Ø³Ø¨ Ù‡Ø³ØªÙ†Ø¯. Ø¯Ø± ØµÙˆØ±ØªÛŒ Ú©Ù‡ Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒ Ø¯Ø§Ø±ÛŒÙ… Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ ÛŒÚ© Ù…Ø¯Ù„ Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ù†ÙˆØ§Ø¹ Ù…Ø®ØªÙ„Ù ÙˆØ¸Ø§ÛŒÙ Ø¯Ø§Ø±ÛŒÙ…ØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª. Ø§ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¬Ø¯Ø¯ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø¯Ø± Ø¨Ø³ÛŒØ§Ø±ÛŒ Ø§Ø² Ù…ÙˆØ§Ø±Ø¯ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø®ÙˆØ¨ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯.\n",
    "\n",
    "    Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©â€ŒØªØ± Ø¯Ø± Ú†Ù‡ Ø´Ø±Ø§ÛŒØ·ÛŒ Ù…Ù†Ø·Ù‚ÛŒ Ø§Ø³ØªØŸ\n",
    "    Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©â€ŒØªØ± Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ Ø¯Ø± ÛŒÚ© ÙˆØ¸ÛŒÙÙ‡ Ø®Ø§Øµ Ø¯Ø§Ø±ÛŒÙ…ØŒ Ø¨Ø§ÛŒØ¯ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ø´ÙˆÙ†Ø¯. Ø¯Ø± ØµÙˆØ±ØªÛŒ Ú©Ù‡ Ø¨Ø®ÙˆØ§Ù‡ÛŒÙ… Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø¯Ø§Ù…Ù†Ù‡ Ø®Ø§Øµ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´ÙˆØ¯ØŒ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ø§Ù‡Ù…ÛŒØª Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ù‡Ù…Ú†Ù†ÛŒÙ†ØŒ Ø§Ú¯Ø± Ù…Ù†Ø§Ø¨Ø¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ø§Ø´Ø¯ØŒ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©â€ŒØªØ± Ú©Ù…Ú© Ú©Ù†Ø¯.\n",
    "\n",
    "    Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ù‚Øª Ø¹Ø¯Ø¯ÛŒ Ù†ØµÙÙ‡ (FP16) Ú†Ù‡ ØªØ§Ø«ÛŒØ±ÛŒ Ø¨Ø± Ú©Ø§Ø±Ø§ÛŒÛŒ Ù…Ø¯Ù„ Ø¯Ø§Ø±Ø¯ØŸ\n",
    "    Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ù‚Øª Ø¹Ø¯Ø¯ÛŒ Ù†ØµÙÙ‡ Ø¨Ù‡ Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø¯Ù„ Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¯Ø± Ø§ÛŒÙ† Ø­Ø§Ù„Øª Ø­Ø§ÙØ¸Ù‡ Ú©Ù…ØªØ±ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ Ø²Ù…Ø§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©ÙˆØªØ§Ù‡â€ŒØªØ± Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ Ø¯Ø± Ø­Ø§Ù„ÛŒ Ú©Ù‡ Ø¯Ù‚Øª Ù…Ø¯Ù„ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ ØªØ­Øª ØªØ§Ø«ÛŒØ± Ù‚Ø±Ø§Ø± Ù†Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯. Ø§ÛŒÙ† Ø±ÙˆØ´ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø±ÛŒØ¹ Ø¯Ø§Ø±Ù†Ø¯ Ø¨Ø³ÛŒØ§Ø± Ù…ÙÛŒØ¯ Ø§Ø³Øª.\n",
    "\n",
    "    Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ Ø³Ø±ÛŒ Ø³Ù…ÙˆÙ„â€ŒØ§Ù„â€ŒØ§Ù…2 Ùˆ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø¢Ù†\n",
    "    Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ù…ÙˆÙ„â€ŒØ§Ù„â€ŒØ§Ù…2 Ø¨Ø±Ø§ÛŒ Ù…ØµØ±Ù Ú©Ù…ØªØ± Ù…Ù†Ø§Ø¨Ø¹ Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ùˆ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ú©ÙˆØ§Ù†ØªÛŒØ²Ø§Ø³ÛŒÙˆÙ† Ùˆ Ø¢Ø¯Ø§Ù¾ØªÙˆØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯. Ø§ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª Ø§Ù†Ø¬Ø§Ù… ÙˆØ¸Ø§ÛŒÙ Ù…Ø®ØªÙ„Ù Ù…Ø§Ù†Ù†Ø¯ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ùˆ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø­Ø¯ÙˆØ¯ Ø¯Ø§Ø±Ù†Ø¯. Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø§ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø´Ø§Ù…Ù„ Ú©Ø§Ù‡Ø´ Ø¯Ù‚Øª Ùˆ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø¯Ù„ Ø¨Ù‡ Ù…Ù†Ø¸ÙˆØ± Ø¨Ù‡Ø¨ÙˆØ¯ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø§Ø³Øª.\n",
    "\n",
    "    ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú© Ø¨Ø§ Ø¯Ù‚Øª Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„\n",
    "    Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú© Ø¨Ø§ Ø¯Ù‚Øª Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ú©ÙˆØ§Ù†ØªÛŒØ²Ø§Ø³ÛŒÙˆÙ†ØŒ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ùˆ Ø¢Ø¯Ø§Ù¾ØªÙˆØ±Ù‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ø§ÛŒÙ† Ø±ÙˆØ´â€ŒÙ‡Ø§ Ø¨Ù‡ Ù…Ø¯Ù„ Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ ØªØ§ Ø¨Ø§ Ù…Ù†Ø§Ø¨Ø¹ Ú©Ù…ØªØ± Ùˆ Ø¨Ø¯ÙˆÙ† Ú©Ø§Ù‡Ø´ Ø²ÛŒØ§Ø¯ Ø¯Ù‚ØªØŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ù†Ø§Ø³Ø¨ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡Ø¯. Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ø¯ Ø¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ù…ÙˆÙ„â€ŒØ§Ù„â€ŒØ§Ù…2 Ø§Ø² Ø§ÛŒÙ† ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.\n",
    "\n",
    "    Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ø³Ø®Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ ÛŒØ§ Ù†Ø³Ø®Ù‡ Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ù…Ø¯Ù„\n",
    "    Ù†Ø³Ø®Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ø¨Ø±Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØ¹Ø§Ù…Ù„ Ø¨ÛŒØ´ØªØ± Ø¨Ø§ Ø¯Ø³ØªÙˆØ±Ø§Øª Ø¯Ø§Ø±Ù†Ø¯ØŒ Ø¨Ù‡ØªØ± Ø§Ø³Øª. Ø§ÛŒÙ† Ù†Ø³Ø®Ù‡ Ø¨Ù‡ Ù…Ø¯Ù„ Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø¯Ø± Ø§Ù†Ø¬Ø§Ù… ÙˆØ¸Ø§ÛŒÙ Ø®Ø§Øµ Ø¨Ø§ Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ø¶Ø­ Ø¨Ù‡ØªØ± Ø¹Ù…Ù„ Ú©Ù†Ø¯. Ø§Ú¯Ø± ÙÙ‚Ø· Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ ÙˆØ¸Ø§ÛŒÙ Ø¹Ù…ÙˆÙ…ÛŒ Ø¯Ø§Ø±ÛŒÙ…ØŒ Ù†Ø³Ø®Ù‡ Ø³Ø§Ø¯Ù‡â€ŒØªØ± Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ú©Ø§ÙÛŒ Ø¨Ø§Ø´Ø¯.\n",
    "\n",
    "\n",
    "\"\"\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7omaBSVSkoVo",
    "outputId": "6c618fa9-9f96-4878-9649-7be817f0b4ef"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "    Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…â€ŒÙ…Ù†Ø¸ÙˆØ±Ù‡ Ø¨Ø²Ø±Ú¯ (Ø¨Ø¯ÙˆÙ† Ø¢Ù…ÙˆØ²Ø´) Ø¯Ø± Ú†Ù‡ Ø³Ù†Ø§Ø±ÛŒÙˆÛŒÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³ØªØŸ\n",
      "    Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ø§Ù…â€ŒÙ…Ù†Ø¸ÙˆØ±Ù‡ Ø¨Ø²Ø±Ú¯ Ø¨Ø±Ø§ÛŒ ÙˆØ¸Ø§ÛŒÙ Ø¹Ù…ÙˆÙ…ÛŒ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÙˆØ¹ Ø¯Ø§Ø±Ù†Ø¯ Ù…Ù†Ø§Ø³Ø¨ Ù‡Ø³ØªÙ†Ø¯. Ø¯Ø± ØµÙˆØ±ØªÛŒ Ú©Ù‡ Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒ Ø¯Ø§Ø±ÛŒÙ… Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ ÛŒÚ© Ù…Ø¯Ù„ Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ù†ÙˆØ§Ø¹ Ù…Ø®ØªÙ„Ù ÙˆØ¸Ø§ÛŒÙ Ø¯Ø§Ø±ÛŒÙ…ØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª. Ø§ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¬Ø¯Ø¯ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø¯Ø± Ø¨Ø³ÛŒØ§Ø±ÛŒ Ø§Ø² Ù…ÙˆØ§Ø±Ø¯ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø®ÙˆØ¨ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯.\n",
      "\n",
      "    Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©â€ŒØªØ± Ø¯Ø± Ú†Ù‡ Ø´Ø±Ø§ÛŒØ·ÛŒ Ù…Ù†Ø·Ù‚ÛŒ Ø§Ø³ØªØŸ\n",
      "    Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©â€ŒØªØ± Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ Ø¯Ø± ÛŒÚ© ÙˆØ¸ÛŒÙÙ‡ Ø®Ø§Øµ Ø¯Ø§Ø±ÛŒÙ…ØŒ Ø¨Ø§ÛŒØ¯ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ø´ÙˆÙ†Ø¯. Ø¯Ø± ØµÙˆØ±ØªÛŒ Ú©Ù‡ Ø¨Ø®ÙˆØ§Ù‡ÛŒÙ… Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø¯Ø§Ù…Ù†Ù‡ Ø®Ø§Øµ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´ÙˆØ¯ØŒ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ø§Ù‡Ù…ÛŒØª Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ù‡Ù…Ú†Ù†ÛŒÙ†ØŒ Ø§Ú¯Ø± Ù…Ù†Ø§Ø¨Ø¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ø§Ø´Ø¯ØŒ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©â€ŒØªØ± Ú©Ù…Ú© Ú©Ù†Ø¯.\n",
      "\n",
      "    Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ù‚Øª Ø¹Ø¯Ø¯ÛŒ Ù†ØµÙÙ‡ (FP16) Ú†Ù‡ ØªØ§Ø«ÛŒØ±ÛŒ Ø¨Ø± Ú©Ø§Ø±Ø§ÛŒÛŒ Ù…Ø¯Ù„ Ø¯Ø§Ø±Ø¯ØŸ\n",
      "    Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ù‚Øª Ø¹Ø¯Ø¯ÛŒ Ù†ØµÙÙ‡ Ø¨Ù‡ Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø¯Ù„ Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¯Ø± Ø§ÛŒÙ† Ø­Ø§Ù„Øª Ø­Ø§ÙØ¸Ù‡ Ú©Ù…ØªØ±ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ Ø²Ù…Ø§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©ÙˆØªØ§Ù‡â€ŒØªØ± Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ Ø¯Ø± Ø­Ø§Ù„ÛŒ Ú©Ù‡ Ø¯Ù‚Øª Ù…Ø¯Ù„ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ ØªØ­Øª ØªØ§Ø«ÛŒØ± Ù‚Ø±Ø§Ø± Ù†Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯. Ø§ÛŒÙ† Ø±ÙˆØ´ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø±ÛŒØ¹ Ø¯Ø§Ø±Ù†Ø¯ Ø¨Ø³ÛŒØ§Ø± Ù…ÙÛŒØ¯ Ø§Ø³Øª.\n",
      "\n",
      "    Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ Ø³Ø±ÛŒ Ø³Ù…ÙˆÙ„â€ŒØ§Ù„â€ŒØ§Ù…2 Ùˆ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø¢Ù†\n",
      "    Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ù…ÙˆÙ„â€ŒØ§Ù„â€ŒØ§Ù…2 Ø¨Ø±Ø§ÛŒ Ù…ØµØ±Ù Ú©Ù…ØªØ± Ù…Ù†Ø§Ø¨Ø¹ Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ùˆ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ú©ÙˆØ§Ù†ØªÛŒØ²Ø§Ø³ÛŒÙˆÙ† Ùˆ Ø¢Ø¯Ø§Ù¾ØªÙˆØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯. Ø§ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª Ø§Ù†Ø¬Ø§Ù… ÙˆØ¸Ø§ÛŒÙ Ù…Ø®ØªÙ„Ù Ù…Ø§Ù†Ù†Ø¯ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ùˆ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø­Ø¯ÙˆØ¯ Ø¯Ø§Ø±Ù†Ø¯. Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø§ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø´Ø§Ù…Ù„ Ú©Ø§Ù‡Ø´ Ø¯Ù‚Øª Ùˆ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø¯Ù„ Ø¨Ù‡ Ù…Ù†Ø¸ÙˆØ± Ø¨Ù‡Ø¨ÙˆØ¯ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø§Ø³Øª.\n",
      "\n",
      "    ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú© Ø¨Ø§ Ø¯Ù‚Øª Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„\n",
      "    Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú© Ø¨Ø§ Ø¯Ù‚Øª Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ú©ÙˆØ§Ù†ØªÛŒØ²Ø§Ø³ÛŒÙˆÙ†ØŒ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ùˆ Ø¢Ø¯Ø§Ù¾ØªÙˆØ±Ù‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ø§ÛŒÙ† Ø±ÙˆØ´â€ŒÙ‡Ø§ Ø¨Ù‡ Ù…Ø¯Ù„ Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ ØªØ§ Ø¨Ø§ Ù…Ù†Ø§Ø¨Ø¹ Ú©Ù…ØªØ± Ùˆ Ø¨Ø¯ÙˆÙ† Ú©Ø§Ù‡Ø´ Ø²ÛŒØ§Ø¯ Ø¯Ù‚ØªØŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ù†Ø§Ø³Ø¨ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡Ø¯. Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ø¯ Ø¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ù…ÙˆÙ„â€ŒØ§Ù„â€ŒØ§Ù…2 Ø§Ø² Ø§ÛŒÙ† ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.\n",
      "\n",
      "    Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ø³Ø®Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ ÛŒØ§ Ù†Ø³Ø®Ù‡ Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ù…Ø¯Ù„\n",
      "    Ù†Ø³Ø®Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ø¨Ø±Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØ¹Ø§Ù…Ù„ Ø¨ÛŒØ´ØªØ± Ø¨Ø§ Ø¯Ø³ØªÙˆØ±Ø§Øª Ø¯Ø§Ø±Ù†Ø¯ØŒ Ø¨Ù‡ØªØ± Ø§Ø³Øª. Ø§ÛŒÙ† Ù†Ø³Ø®Ù‡ Ø¨Ù‡ Ù…Ø¯Ù„ Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø¯Ø± Ø§Ù†Ø¬Ø§Ù… ÙˆØ¸Ø§ÛŒÙ Ø®Ø§Øµ Ø¨Ø§ Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ø¶Ø­ Ø¨Ù‡ØªØ± Ø¹Ù…Ù„ Ú©Ù†Ø¯. Ø§Ú¯Ø± ÙÙ‚Ø· Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ ÙˆØ¸Ø§ÛŒÙ Ø¹Ù…ÙˆÙ…ÛŒ Ø¯Ø§Ø±ÛŒÙ…ØŒ Ù†Ø³Ø®Ù‡ Ø³Ø§Ø¯Ù‡â€ŒØªØ± Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ú©Ø§ÙÛŒ Ø¨Ø§Ø´Ø¯.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7QWVmp_sPHf"
   },
   "source": [
    "*Ø¨Ø®Ø´ Ø³ÙˆÙ…:*\n",
    "---\n",
    "# Ù¾Ø§Ø³Ø® Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯:"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.nn.utils import prune\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch.nn as nn\n",
    "from transformers import pipeline\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./fine_tuned_model\")\n",
    "\n",
    "def apply_l1_pruning(model, amount=0.3):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            prune.l1_unstructured(module, name=\"weight\", amount=amount)\n",
    "\n",
    "apply_l1_pruning(model, amount=0.3)\n",
    "model.save_pretrained(\"./fine_tuned_pruned_model\")\n",
    "def calculate_sparsity(model):\n",
    "    total_params = 0\n",
    "    total_zeros = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            weight = module.weight\n",
    "            total_params += weight.numel()  \n",
    "            total_zeros += torch.sum(weight == 0).item() \n",
    "            layer_sparsity = torch.sum(weight == 0).item() / weight.numel()\n",
    "            print(f\"Sparsity of {name}: {layer_sparsity:.4f}\")\n",
    "\n",
    "    overall_sparsity = total_zeros / total_params\n",
    "    print(f\"Overall sparsity: {overall_sparsity:.4f}\")\n",
    "    return overall_sparsity\n",
    "calculate_sparsity(model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BinVlGMpfI8A",
    "outputId": "0fdee18a-f053-4e85-db32-c9a4d6115ab8"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sparsity of model.layers.0.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.0.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.0.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.0.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.0.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.0.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.0.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.0.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.0.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.0.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.0.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.1.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.1.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.1.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.1.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.1.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.1.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.1.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.1.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.1.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.1.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.1.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.2.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.2.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.2.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.2.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.2.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.2.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.2.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.2.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.2.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.2.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.2.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.3.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.3.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.3.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.3.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.3.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.3.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.3.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.3.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.3.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.3.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.3.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.4.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.4.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.4.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.4.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.4.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.4.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.4.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.4.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.4.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.4.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.4.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.5.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.5.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.5.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.5.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.5.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.5.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.5.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.5.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.5.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.5.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.5.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.6.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.6.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.6.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.6.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.6.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.6.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.6.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.6.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.6.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.6.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.6.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.7.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.7.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.7.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.7.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.7.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.7.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.7.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.7.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.7.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.7.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.7.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.8.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.8.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.8.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.8.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.8.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.8.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.8.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.8.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.8.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.8.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.8.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.9.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.9.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.9.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.9.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.9.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.9.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.9.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.9.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.9.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.9.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.9.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.10.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.10.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.10.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.10.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.10.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.10.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.10.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.10.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.10.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.10.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.10.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.11.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.11.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.11.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.11.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.11.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.11.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.11.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.11.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.11.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.11.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.11.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.12.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.12.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.12.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.12.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.12.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.12.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.12.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.12.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.12.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.12.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.12.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.13.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.13.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.13.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.13.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.13.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.13.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.13.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.13.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.13.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.13.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.13.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.14.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.14.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.14.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.14.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.14.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.14.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.14.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.14.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.14.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.14.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.14.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.15.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.15.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.15.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.15.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.15.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.15.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.15.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.15.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.15.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.15.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.15.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.16.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.16.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.16.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.16.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.16.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.16.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.16.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.16.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.16.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.16.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.16.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.17.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.17.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.17.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.17.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.17.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.17.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.17.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.17.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.17.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.17.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.17.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.18.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.18.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.18.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.18.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.18.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.18.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.18.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.18.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.18.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.18.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.18.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.19.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.19.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.19.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.19.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.19.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.19.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.19.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.19.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.19.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.19.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.19.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.20.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.20.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.20.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.20.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.20.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.20.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.20.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.20.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.20.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.20.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.20.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.21.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.21.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.21.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.21.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.21.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.21.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.21.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.21.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.21.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.21.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.21.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.22.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.22.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.22.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.22.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.22.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.22.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.22.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.22.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.22.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.22.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.22.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.23.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.23.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.23.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.23.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.23.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.23.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.23.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.23.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.23.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.23.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.23.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.24.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.24.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.24.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.24.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.24.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.24.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.24.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.24.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.24.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.24.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.24.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.25.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.25.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.25.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.25.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.25.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.25.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.25.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.25.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.25.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.25.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.25.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.26.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.26.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.26.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.26.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.26.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.26.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.26.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.26.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.26.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.26.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.26.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.27.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.27.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.27.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.27.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.27.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.27.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.27.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.27.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.27.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.27.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.27.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.28.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.28.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.28.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.28.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.28.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.28.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.28.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.28.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.28.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.28.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.28.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.29.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.29.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.29.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.29.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.29.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.29.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.29.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.29.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.29.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.29.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.29.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.30.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.30.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.30.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.30.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.30.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.30.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.30.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.30.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.30.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.30.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.30.mlp.down_proj: 0.3000\n",
      "Sparsity of model.layers.31.self_attn.q_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.31.self_attn.q_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.31.self_attn.q_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.31.self_attn.k_proj: 0.3000\n",
      "Sparsity of model.layers.31.self_attn.v_proj.base_layer: 0.3000\n",
      "Sparsity of model.layers.31.self_attn.v_proj.lora_A.default: 0.3000\n",
      "Sparsity of model.layers.31.self_attn.v_proj.lora_B.default: 0.3000\n",
      "Sparsity of model.layers.31.self_attn.o_proj: 0.3000\n",
      "Sparsity of model.layers.31.mlp.gate_proj: 0.3000\n",
      "Sparsity of model.layers.31.mlp.up_proj: 0.3000\n",
      "Sparsity of model.layers.31.mlp.down_proj: 0.3000\n",
      "Sparsity of lm_head: 0.3000\n",
      "Overall sparsity: 0.3000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"./fine_tuned_pruned_model\")\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "rouge1_scores = []\n",
    "rouge2_scores = []\n",
    "rougeL_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    sample_article = test_data[i][\"article\"]\n",
    "    expected_summary = test_data[i][\"highlights\"]\n",
    "\n",
    "    generated_summary = summarizer(sample_article, max_length=150, min_length=50, do_sample=False)\n",
    "\n",
    "    generated_summary_text = generated_summary[0]['summary_text']\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_scores = scorer.score(expected_summary, generated_summary_text)\n",
    "\n",
    "    rouge1_scores.append(rouge_scores['rouge1'].fmeasure)\n",
    "    rouge2_scores.append(rouge_scores['rouge2'].fmeasure)\n",
    "    rougeL_scores.append(rouge_scores['rougeL'].fmeasure)\n",
    "\n",
    "    references = [expected_summary]\n",
    "    candidates = [generated_summary_text]\n",
    "\n",
    "    P, R, F1 = score(candidates, references, lang='en')\n",
    "\n",
    "    precision_scores.append(P.mean().item()) \n",
    "    recall_scores.append(R.mean().item())\n",
    "    f1_scores.append(F1.mean().item())\n",
    "\n",
    "avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores)\n",
    "avg_rouge2 = sum(rouge2_scores) / len(rouge2_scores)\n",
    "avg_rougeL = sum(rougeL_scores) / len(rougeL_scores)\n",
    "\n",
    "avg_precision = sum(precision_scores) / len(precision_scores)\n",
    "avg_recall = sum(recall_scores) / len(recall_scores)\n",
    "avg_f1 = sum(f1_scores) / len(f1_scores)\n",
    "print(\"\\nAverage ROUGE Scores:\")\n",
    "print(f\"ROUGE-1: {avg_rouge1:.4f}\")\n",
    "print(f\"ROUGE-2: {avg_rouge2:.4f}\")\n",
    "print(f\"ROUGE-L: {avg_rougeL:.4f}\")\n",
    "\n",
    "print(\"\\nAverage BERTScore:\")\n",
    "print(f\"Precision: {avg_precision:.4f}, Recall: {avg_recall:.4f}, F1: {avg_f1:.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gwgkoho6l53y",
    "outputId": "68b4e52c-be3a-4b9d-faa1-c69511809d06"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loading adapter weights from ./fine_tuned_pruned_model led to unexpected keys not found in the model:  ['model.layers.0.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.0.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.0.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.0.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.0.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.0.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.0.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.0.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.1.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.1.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.1.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.1.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.1.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.1.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.1.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.1.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.2.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.2.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.2.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.2.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.2.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.2.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.2.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.2.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.3.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.3.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.3.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.3.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.3.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.3.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.3.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.3.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.4.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.4.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.4.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.4.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.4.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.4.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.4.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.4.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.5.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.5.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.5.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.5.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.5.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.5.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.5.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.5.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.6.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.6.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.6.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.6.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.6.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.6.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.6.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.6.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.7.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.7.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.7.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.7.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.7.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.7.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.7.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.7.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.8.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.8.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.8.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.8.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.8.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.8.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.8.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.8.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.9.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.9.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.9.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.9.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.9.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.9.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.9.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.9.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.10.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.10.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.10.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.10.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.10.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.10.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.10.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.10.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.11.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.11.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.11.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.11.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.11.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.11.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.11.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.11.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.12.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.12.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.12.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.12.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.12.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.12.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.12.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.12.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.13.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.13.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.13.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.13.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.13.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.13.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.13.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.13.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.14.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.14.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.14.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.14.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.14.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.14.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.14.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.14.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.15.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.15.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.15.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.15.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.15.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.15.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.15.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.15.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.16.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.16.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.16.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.16.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.16.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.16.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.16.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.16.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.17.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.17.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.17.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.17.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.17.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.17.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.17.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.17.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.18.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.18.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.18.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.18.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.18.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.18.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.18.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.18.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.19.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.19.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.19.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.19.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.19.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.19.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.19.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.19.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.20.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.20.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.20.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.20.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.20.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.20.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.20.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.20.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.21.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.21.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.21.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.21.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.21.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.21.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.21.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.21.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.22.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.22.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.22.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.22.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.22.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.22.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.22.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.22.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.23.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.23.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.23.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.23.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.23.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.23.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.23.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.23.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.24.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.24.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.24.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.24.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.24.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.24.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.24.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.24.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.25.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.25.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.25.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.25.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.25.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.25.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.25.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.25.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.26.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.26.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.26.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.26.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.26.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.26.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.26.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.26.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.27.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.27.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.27.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.27.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.27.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.27.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.27.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.27.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.28.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.28.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.28.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.28.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.28.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.28.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.28.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.28.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.29.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.29.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.29.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.29.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.29.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.29.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.29.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.29.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.30.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.30.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.30.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.30.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.30.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.30.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.30.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.30.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.31.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.31.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.31.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.31.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.31.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.31.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.31.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.31.self_attn.v_proj.lora_B.default.weight_orig']. \n",
      "The model 'LlamaForCausalLM' is not supported for summarization. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 720, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 511, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 958, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 245, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 442, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 604, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1033, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 491, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 399, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 151, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 150, but your input_length is only 147. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=73)\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 646, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 613, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1235, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 376, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1340, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 904, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1501, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1156, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 522, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1181, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 991, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1208, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 457, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 509, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1295, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 368, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 568, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 802, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 831, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 480, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1967, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 619, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 570, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 416, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1015, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1327, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1511, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 687, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 2457, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 293, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1937, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 392, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 465, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 944, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 275, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 375, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1258, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 620, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 254, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1165, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 879, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 807, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 623, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 954, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 343, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 295, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 950, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 652, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 595, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 309, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1632, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 184, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 152, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 255, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 175, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1220, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 474, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 289, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 241, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 382, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 759, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1325, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 150, but your input_length is only 127. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=63)\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 758, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 354, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 767, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1030, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 178, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1613, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 379, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 482, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 512, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 202, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1244, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 438, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 537, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 464, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 498, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 215, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 612, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 952, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1086, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 559, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1239, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 308, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 515, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1281, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Average ROUGE Scores:\n",
      "ROUGE-1: 0.1347\n",
      "ROUGE-2: 0.0695\n",
      "ROUGE-L: 0.1004\n",
      "\n",
      "Average BERTScore:\n",
      "Precision: 0.8034, Recall: 0.8861, F1: 0.8426\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./fine_tuned_pruned_model\")\n",
    "def preprocess_function(examples):\n",
    "    output_texts = []\n",
    "    for i in range(len(examples['article'])):\n",
    "        article_text = examples['article'][i]\n",
    "        highlight_text = examples['highlights'][i]\n",
    "        text = f\"### Article: {article_text} \\n ### Summary: {highlight_text}\"\n",
    "        output_texts.append(text)\n",
    "    print(f\"Type of output_texts: {type(output_texts)}\")\n",
    "    print(f\"Sample of output_texts: {output_texts[:2]}\")  \n",
    "    return tokenizer(output_texts, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",               \n",
    "    evaluation_strategy=\"epoch\",          \n",
    "    learning_rate=2e-5,                   \n",
    "    per_device_train_batch_size=2,        \n",
    "    per_device_eval_batch_size=2,         \n",
    "    num_train_epochs=5,                   \n",
    "    weight_decay=0.01,                    \n",
    "    logging_dir='./logs',                 \n",
    "    logging_steps=200,                    \n",
    "    save_steps=1000,                      \n",
    "    save_total_limit=2,                   \n",
    "    fp16=True,                            \n",
    "    gradient_accumulation_steps=8,        \n",
    "    max_grad_norm=1.0,                    \n",
    "    dataloader_num_workers=4,             \n",
    ")\n",
    "\n",
    "peft_config =LoraConfig(\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        r=64,\n",
    "        bias=\"none\",\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,                \n",
    "    args=training_args,         \n",
    "    train_dataset=train_data,   \n",
    "    eval_dataset=val_data,      \n",
    "    peft_config=peft_config,    \n",
    "    tokenizer=tokenizer,        \n",
    "    dataset_text_field=\"article\",  \n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model(\"./fine_tuned_pruned_model\")\n",
    "results = trainer.evaluate()\n",
    "print(f\"Evaluation Results: {results}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 726,
     "referenced_widgets": [
      "5ee3d1c1d052451ea261197cb3766d31",
      "353d5d42749f4325afe266d69c7a9160",
      "943f0f4b48af4b76b46f21f7630ca330",
      "8f8dad2609c14532822d83980ec70d64",
      "644dbea1ca3241f4813d84640e700b32",
      "c33d5d56896c4cae96990509e97b7a82",
      "457de2cbb68348358193375eef33ab54",
      "0f6c82407a32472c836bc7e13389b56d",
      "919084c557ac4659834b49a8b287c99c",
      "3c576e151a074222b1ff7d53f022b525",
      "9a8016d4af6e4ec8bb39e4509f7193b2",
      "654ee06a022b415889fb58a8b2844f58",
      "016a37c16b5b493883266dfa8752942c",
      "cce0e4d65d564f7d86cc7698f0b8e256",
      "23962af1e37c44119c5f3a758163cbec",
      "66184be99e50474a803d4eb8773c66dd",
      "163db47e910a4fdb8bdc634426274b99",
      "03bdb2056c884e7083ec677edc202678",
      "e8b61d810ec14f55b9863f472517dd30",
      "e8a765fdb96442cfb9aff168e831828b",
      "3af560e00a394bf4888df621d65be6d5",
      "fe2dca9ff372452f84ed26ea75bcfca1"
     ]
    },
    "id": "Va4x1J4xjbPh",
    "outputId": "94148579-1231-4fa3-8130-7e3fac72b83e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loading adapter weights from ./fine_tuned_pruned_model led to unexpected keys not found in the model:  ['model.layers.0.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.0.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.0.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.0.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.0.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.0.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.0.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.0.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.1.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.1.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.1.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.1.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.1.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.1.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.1.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.1.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.2.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.2.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.2.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.2.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.2.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.2.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.2.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.2.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.3.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.3.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.3.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.3.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.3.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.3.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.3.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.3.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.4.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.4.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.4.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.4.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.4.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.4.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.4.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.4.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.5.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.5.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.5.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.5.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.5.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.5.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.5.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.5.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.6.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.6.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.6.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.6.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.6.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.6.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.6.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.6.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.7.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.7.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.7.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.7.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.7.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.7.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.7.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.7.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.8.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.8.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.8.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.8.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.8.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.8.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.8.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.8.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.9.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.9.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.9.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.9.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.9.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.9.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.9.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.9.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.10.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.10.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.10.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.10.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.10.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.10.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.10.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.10.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.11.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.11.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.11.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.11.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.11.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.11.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.11.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.11.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.12.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.12.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.12.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.12.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.12.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.12.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.12.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.12.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.13.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.13.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.13.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.13.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.13.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.13.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.13.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.13.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.14.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.14.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.14.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.14.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.14.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.14.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.14.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.14.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.15.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.15.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.15.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.15.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.15.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.15.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.15.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.15.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.16.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.16.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.16.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.16.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.16.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.16.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.16.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.16.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.17.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.17.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.17.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.17.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.17.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.17.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.17.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.17.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.18.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.18.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.18.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.18.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.18.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.18.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.18.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.18.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.19.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.19.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.19.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.19.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.19.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.19.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.19.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.19.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.20.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.20.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.20.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.20.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.20.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.20.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.20.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.20.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.21.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.21.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.21.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.21.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.21.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.21.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.21.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.21.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.22.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.22.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.22.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.22.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.22.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.22.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.22.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.22.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.23.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.23.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.23.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.23.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.23.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.23.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.23.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.23.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.24.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.24.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.24.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.24.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.24.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.24.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.24.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.24.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.25.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.25.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.25.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.25.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.25.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.25.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.25.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.25.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.26.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.26.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.26.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.26.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.26.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.26.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.26.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.26.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.27.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.27.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.27.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.27.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.27.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.27.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.27.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.27.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.28.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.28.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.28.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.28.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.28.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.28.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.28.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.28.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.29.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.29.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.29.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.29.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.29.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.29.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.29.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.29.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.30.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.30.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.30.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.30.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.30.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.30.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.30.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.30.self_attn.v_proj.lora_B.default.weight_orig', 'model.layers.31.self_attn.q_proj.lora_A.default.weight_mask', 'model.layers.31.self_attn.q_proj.lora_A.default.weight_orig', 'model.layers.31.self_attn.q_proj.lora_B.default.weight_mask', 'model.layers.31.self_attn.q_proj.lora_B.default.weight_orig', 'model.layers.31.self_attn.v_proj.lora_A.default.weight_mask', 'model.layers.31.self_attn.v_proj.lora_A.default.weight_orig', 'model.layers.31.self_attn.v_proj.lora_B.default.weight_mask', 'model.layers.31.self_attn.v_proj.lora_B.default.weight_orig']. \n",
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:223: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ee3d1c1d052451ea261197cb3766d31"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "654ee06a022b415889fb58a8b2844f58"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:290: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:449: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='678' max='1560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 678/1560 38:43 < 50:31, 0.29 it/s, Epoch 2.17/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>113.521000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T19:48:18.894205Z",
     "start_time": "2024-12-24T19:48:18.889207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\"\"\n",
    "Ù…Ø¯Ù„ÛŒ Ú© Ù…Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯Ù… Ù‚Ø¨Ù„ Ø§Ø² Ù‡Ø±Ø³ Ø³ÛŒÙˆ Ú©Ø±Ø¯Ù… Ùˆ Ø¯Ø§Ø¯Ù… Ø¨Ù‡ ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ù‡Ø±Ø³ Ú©Ø±Ø¯Ù† Ùˆ Ø¨Ø¹Ø¯ Ø§Ø² Ù‡Ø±Ø³ Ù…Ø¯Ù„ Ø±Ùˆ Ø³ÛŒÙˆ Ú©Ø±Ø¯Ù… Ùˆ Ø¯Ø± Ù…Ø±Ø­Ù„Ù‡ Ø¨Ø¹Ø¯ Ø¯Ù‚Øª Ùˆ Ù¾Ø§Ø±Ø§Ù…ØªØ± Ù‡Ø§Ø±Ùˆ Ø­Ø³Ø§Ø¨ Ú©Ø±Ø¯Ù‡ ÙˆÙ„ÛŒ ØªØºÛŒÛŒØ±ÛŒ Ù†Ú©Ø±Ø¯ Ø³Ø±Ú†ÛŒ Ú©Ù‡ Ø§Ù†Ø¬Ø§Ù… Ø¯Ø§Ø¯Ù… Ú¯ÙØªÙ‡ Ø´Ø¯ Ú© ÛŒØ§ ØªØ¹Ø¯Ø§Ø¯ Û³Û° Ø¯Ø±ØµØ¯ Ú©Ù… Ù‡Ø³Øª Ùˆ Ù†ØªÙˆØ§Ù†Ø³ØªÙ‡ Ø§Ø³Øª ÙˆØ²Ù† Ù‡Ø§ÛŒ Ù…Ù‡Ù… Ø±Ø§ Ù‡Ø±Ø³ Ú©Ù†Ù‡ Ùˆ ÛŒØ§ Ø§Ø² Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒÛŒ Ú© Ø¯Ø± Ù‚Ø³Ù…Øª Ø§Ù…ÙˆØ²Ø´ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ Ú© Ø¨Ø§Ø¹Ø« Ø´Ø¯Ù‡ Ù…Ø¯Ù„ ØªØ­Øª ØªØ§Ø«ÛŒØ± Ù‡Ø±Ø³ Ù‚Ø±Ø§Ø± Ù†Ú¯ÛŒØ±Ù‡ Ù…Ø«Ù„ Ù†Ø±Ø® ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ùˆ Ø¨Ù‚ÛŒÙ‡ Ù…ÙˆØ§Ø±Ø¯ ÙˆÙ„ÛŒ Ú†ÛŒØ²ÛŒ Ú© Ø¨ÙˆØ¯ Ø¨Ø¹Ø¯ Ø§Ø² Ù‡Ø±Ø³ Ø³Ø±Ø¹Øª Ù…Ø­Ø³Ø§Ø¨ Ù¾Ø§Ø±Ø§Ù…ØªØ± Ù‡Ø§ Ùˆ Ø§Ù…ÙˆØ²Ø´ Ù…Ø¬Ø¯Ø¯ Ø®ÛŒÙ„ÛŒ Ú©Ù†Ø¯ ØªØ± Ø´Ø¯ Ù„Ø·ÙØ§ Ù…ÙˆØ§Ø±Ø¯ÛŒ Ú© Ú¯ÙØªÙ‡ Ø´Ø¯ Ùˆ Ø²Ù…Ø§Ù† Ø®ÛŒÙ„ÛŒ Ø²ÛŒØ§Ø¯ÛŒ Ø§Ø²Ù… Ú¯Ø±ÙØª Ø±Ùˆ Ù„Ø­Ø§Ø¸ Ø¨ÙØ±Ù…Ø§ÛŒÛŒØ¯ Ùˆ Ù†Ù…Ø±Ù‡ Ø§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†ØªÛŒØ­Ù‡ Ø¨Ø¯Ø³Øª Ø§Ù…Ø¯Ù‡ Ø¨Ø¯ÛŒØ¯ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø§ÛŒÙ†Ú©Ù‡ Ø·Ø¨Ù‚ ÙÙ„ÙˆÛŒ Ø³ÙˆØ§Ù„ Ø¨Ø§ÛŒØ¯ Ø¯Ù‚Øª Ú©Ù… Ù…ÛŒØ´Ø¯ Ùˆ Ø¨Ø¹Ø¯ Ø§Ø² Ø§Ù…ÙˆØ²Ø´ Ø¨Ø§ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ Ù…Ø¬Ø¯Ø¯ Ø¯Ø±Ø³Øª Ù…ÛŒØ´Ø¯.\n",
    "\"\"\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ù…Ø¯Ù„ÛŒ Ú© Ù…Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯Ù… Ù‚Ø¨Ù„ Ø§Ø² Ù‡Ø±Ø³ Ø³ÛŒÙˆ Ú©Ø±Ø¯Ù… Ùˆ Ø¯Ø§Ø¯Ù… Ø¨Ù‡ ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ù‡Ø±Ø³ Ú©Ø±Ø¯Ù† Ùˆ Ø¨Ø¹Ø¯ Ø§Ø² Ù‡Ø±Ø³ Ù…Ø¯Ù„ Ø±Ùˆ Ø³ÛŒÙˆ Ú©Ø±Ø¯Ù… Ùˆ Ø¯Ø± Ù…Ø±Ø­Ù„Ù‡ Ø¨Ø¹Ø¯ Ø¯Ù‚Øª Ùˆ Ù¾Ø§Ø±Ø§Ù…ØªØ± Ù‡Ø§Ø±Ùˆ Ø­Ø³Ø§Ø¨ Ú©Ø±Ø¯Ù‡ ÙˆÙ„ÛŒ ØªØºÛŒÛŒØ±ÛŒ Ù†Ú©Ø±Ø¯ Ø³Ø±Ú†ÛŒ Ú©Ù‡ Ø§Ù†Ø¬Ø§Ù… Ø¯Ø§Ø¯Ù… Ú¯ÙØªÙ‡ Ø´Ø¯ Ú© ÛŒØ§ ØªØ¹Ø¯Ø§Ø¯ Û³Û° Ø¯Ø±ØµØ¯ Ú©Ù… Ù‡Ø³Øª Ùˆ Ù†ØªÙˆØ§Ù†Ø³ØªÙ‡ Ø§Ø³Øª ÙˆØ²Ù† Ù‡Ø§ÛŒ Ù…Ù‡Ù… Ø±Ø§ Ù‡Ø±Ø³ Ú©Ù†Ù‡ Ùˆ ÛŒØ§ Ø§Ø² Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒÛŒ Ú© Ø¯Ø± Ù‚Ø³Ù…Øª Ø§Ù…ÙˆØ²Ø´ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ Ú© Ø¨Ø§Ø¹Ø« Ø´Ø¯Ù‡ Ù…Ø¯Ù„ ØªØ­Øª ØªØ§Ø«ÛŒØ± Ù‡Ø±Ø³ Ù‚Ø±Ø§Ø± Ù†Ú¯ÛŒØ±Ù‡ Ù…Ø«Ù„ Ù†Ø±Ø® ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ùˆ Ø¨Ù‚ÛŒÙ‡ Ù…ÙˆØ§Ø±Ø¯ ÙˆÙ„ÛŒ Ú†ÛŒØ²ÛŒ Ú© Ø¨ÙˆØ¯ Ø¨Ø¹Ø¯ Ø§Ø² Ù‡Ø±Ø³ Ø³Ø±Ø¹Øª Ù…Ø­Ø³Ø§Ø¨ Ù¾Ø§Ø±Ø§Ù…ØªØ± Ù‡Ø§ Ùˆ Ø§Ù…ÙˆØ²Ø´ Ù…Ø¬Ø¯Ø¯ Ø®ÛŒÙ„ÛŒ Ú©Ù†Ø¯ ØªØ± Ø´Ø¯ Ù„Ø·ÙØ§ Ù…ÙˆØ§Ø±Ø¯ÛŒ Ú© Ú¯ÙØªÙ‡ Ø´Ø¯ Ùˆ Ø²Ù…Ø§Ù† Ø®ÛŒÙ„ÛŒ Ø²ÛŒØ§Ø¯ÛŒ Ø§Ø²Ù… Ú¯Ø±ÙØª Ø±Ùˆ Ù„Ø­Ø§Ø¸ Ø¨ÙØ±Ù…Ø§ÛŒÛŒØ¯ Ùˆ Ù†Ù…Ø±Ù‡ Ø§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†ØªÛŒØ­Ù‡ Ø¨Ø¯Ø³Øª Ø§Ù…Ø¯Ù‡ Ø¨Ø¯ÛŒØ¯ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø§ÛŒÙ†Ú©Ù‡ Ø·Ø¨Ù‚ ÙÙ„ÙˆÛŒ Ø³ÙˆØ§Ù„ Ø¨Ø§ÛŒØ¯ Ø¯Ù‚Øª Ú©Ù… Ù…ÛŒØ´Ø¯ Ùˆ Ø¨Ø¹Ø¯ Ø§Ø² Ø§Ù…ÙˆØ²Ø´ Ø¨Ø§ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ Ù…Ø¬Ø¯Ø¯ Ø¯Ø±Ø³Øª Ù…ÛŒØ´Ø¯.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T19:48:21.717485Z",
     "start_time": "2024-12-24T19:48:21.710667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\"\"\n",
    "\n",
    "Ø³Ù‡ ØªÚ©Ù†ÛŒÚ© Ù‡Ø±Ø³ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ Ø¨Ù‡ Ù‡Ù…Ø±Ø§Ù‡ Ù…Ø²Ø§ÛŒØ§ Ùˆ Ù…Ø¹Ø§ÛŒØ¨ \n",
    "\n",
    "    Ù‡Ø±Ø³ Ø¨Ø¯ÙˆÙ† Ø³Ø§Ø®ØªØ§Ø± (Unstructured Pruning): ÙˆØ²Ù†â€ŒÙ‡Ø§ Ø¨Ù‡â€ŒØ·ÙˆØ± ØªØµØ§Ø¯ÙÛŒ Ø­Ø°Ù Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯. Ù…Ø²ÛŒØª: Ø³Ø§Ø¯Ú¯ÛŒ Ùˆ Ú©Ø§Ù‡Ø´ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø¯Ù„. Ù…Ø¹Ø§ÛŒØ¨: Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø² Ø¯Ø³Øª Ø¯Ø§Ø¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ù‡Ù… Ùˆ Ú©Ø§Ù‡Ø´ Ú©Ø§Ø±Ø§ÛŒÛŒ.\n",
    "    Ù‡Ø±Ø³ Ø³Ø§Ø®ØªØ§Ø±ÛŒ (Structured Pruning): Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ ÛŒØ§ ÙÛŒÙ„ØªØ±Ù‡Ø§ Ø¨Ù‡â€ŒØ·ÙˆØ± Ú©Ø§Ù…Ù„ Ø­Ø°Ù Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯. Ù…Ø²ÛŒØª: Ø­ÙØ¸ Ø³Ø§Ø®ØªØ§Ø± Ù…Ø¯Ù„ Ùˆ Ú©Ø§Ù‡Ø´ Ù‡Ø²ÛŒÙ†Ù‡ Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ. Ù…Ø¹Ø§ÛŒØ¨: Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ø¨ÛŒØ´ØªØ± Ùˆ Ø§Ø­ØªÙ…Ø§Ù„ Ú©Ø§Ù‡Ø´ Ø§Ù†Ø¹Ø·Ø§Ùâ€ŒÙ¾Ø°ÛŒØ±ÛŒ.\n",
    "    Ù‡Ø±Ø³ Ù…Ø­Ù„ÛŒ (Local Pruning): Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ùˆ Ø¯Ø± Ù†ÙˆØ§Ø­ÛŒ Ø®Ø§Øµ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ù…Ø²ÛŒØª: Ø­ÙØ¸ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ù‡Ù… Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±. Ù…Ø¹Ø§ÛŒØ¨: Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ø¨ÛŒØ´ØªØ± Ùˆ Ø¹Ø¯Ù… ØªØ¹Ù…ÛŒÙ…â€ŒÙ¾Ø°ÛŒØ±ÛŒ.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "  Ù‡Ø±Ø³ Ù…Ø¯Ù„ Ø¯Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø¯ÛŒÚ¯Ø± Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ Ú†Ù‡ Ù…Ø²Ø§ÛŒØ§ Ùˆ Ù…Ø¹Ø§ÛŒØ¨ÛŒ Ø¯Ø§Ø±Ø¯ \n",
    "    \n",
    "    Ø¯Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø¯ÛŒÚ¯Ø± Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒØŒ Ù‡Ø±Ø³ Ù…Ø¯Ù„ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù…Ù†Ø¬Ø± Ø¨Ù‡ Ú©Ø§Ù‡Ø´ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø¯Ù„ Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´ÙˆØ¯ØŒ Ø§Ù…Ø§ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ù‚Øª Ù…Ø¯Ù„ Ú©Ø§Ù‡Ø´ ÛŒØ§Ø¨Ø¯. ÙØ§Ú©ØªÙˆØ±Ú¯ÛŒØ±ÛŒ Ø±ØªØ¨Ù‡ Ù¾Ø§ÛŒÛŒÙ† Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ Ù…Ø¯Ù„ Ø±Ø§ Ú©Ø§Ù‡Ø´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ùˆ Ø¯Ù‚Øª Ø±Ø§ Ø­ÙØ¸ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ø§Ù…Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡â€ŒØªØ±ÛŒ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ø¯. Ø¯ÛŒØ³ØªÛŒÙ„Ø³ÛŒÙˆÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©ØªØ±ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø´Ø§Ø¨Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ØªØ± Ø±Ø§ Ø­ÙØ¸ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ØŒ ÙˆÙ„ÛŒ Ø¨Ù‡ ÛŒÚ© Ù…Ø¯Ù„ Ù…Ø¹Ù„Ù… Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ø¯ Ùˆ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ù‚Øª Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ù‡Ø¯. Ú©ÙˆØ§Ù†ØªÛŒØ²Ø§Ø³ÛŒÙˆÙ† Ø­Ø¬Ù… Ø­Ø§ÙØ¸Ù‡ Ù…Ø¯Ù„ Ø±Ø§ Ú©Ø§Ù‡Ø´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ùˆ Ø³Ø±Ø¹Øª Ø§Ø¬Ø±Ø§ Ø±Ø§ Ø¨Ø§Ù„Ø§ Ù…ÛŒâ€ŒØ¨Ø±Ø¯ØŒ Ø§Ù…Ø§ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ù‚Øª Ø±Ø§ ØªØ­Øª ØªØ§Ø«ÛŒØ± Ù‚Ø±Ø§Ø± Ø¯Ù‡Ø¯ Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø± Ø®Ø§ØµÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯.\n",
    "    \n",
    "    \n",
    "    ØªØ§Ø«ÛŒØ± Ù‡Ø±Ø³ Ø¨Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ú†Ú¯ÙˆÙ†Ù‡ Ø§Ø³ØªØŸ Ú†Ú¯ÙˆÙ†Ù‡ Ù‡Ø±Ø³ Ø¨Ø§Ø¹Ø« Ú©Ø§Ù‡Ø´ Ø­Ø§ÙØ¸Ù‡ Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŸ \n",
    "    Ù‡Ø±Ø³ Ù…Ø¯Ù„ Ø¨Ø§Ø¹Ø« Ú©Ø§Ù‡Ø´ Ø­Ø§ÙØ¸Ù‡ Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ø­Ø°Ù Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ ØºÛŒØ±Ø¶Ø±ÙˆØ±ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ Ú©Ù‡ Ø§ÛŒÙ† Ø§Ù…Ø± Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¯Ø± Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±Ù‡Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯ Ù…Ù†Ø¬Ø± Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ø¨Ø§ Ø§ÛŒÙ† Ø­Ø§Ù„ØŒ Ù‡Ø±Ø³ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ù‚Øª Ù…Ø¯Ù„ Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ù‡Ø¯ Ú†ÙˆÙ† Ø¨Ø±Ø®ÛŒ Ø§Ø² Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù…Ù‡Ù… Ø¨Ø±Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø§Ø² Ø¨ÛŒÙ† Ù…ÛŒâ€ŒØ±ÙˆÙ†Ø¯. Ø­Ø°Ù ÙˆØ²Ù†â€ŒÙ‡Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¸Ø±ÙÛŒØª Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚ Ú©Ø§Ù‡Ø´ Ø¯Ù‡Ø¯. Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ†ØŒ Ù‡Ø±Ø³ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ Ø¯Ù‚Øª Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯ ØªØ§ Ù‡Ù…Ø²Ù…Ø§Ù† Ø¨Ø§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø¨Ø¹ØŒ Ø¯Ù‚Øª Ù…Ø¯Ù„ Ø­ÙØ¸ Ø´ÙˆØ¯. Ø¯Ø± Ú©Ù„ØŒ Ù‡Ø±Ø³ ØªØ§Ø«ÛŒØ± Ù…Ø«Ø¨Øª Ø¨Ø± Ø³Ø±Ø¹Øª Ùˆ Ø­Ø§ÙØ¸Ù‡ Ø¯Ø§Ø±Ø¯ Ø§Ù…Ø§ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø± Ø¯Ù‚Øª Ø§Ø«Ø± Ù…Ù†ÙÛŒ Ø¨Ú¯Ø°Ø§Ø±Ø¯.\n",
    "    \n",
    "    Ú†Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ù…Ø¬Ø¯Ø¯ Ù¾Ø³ Ø§Ø² Ù‡Ø±Ø³ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡ Ø±Ø§ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ù‡Ø¯ØŸ \n",
    "    ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ù…Ø¬Ø¯Ø¯ Ù¾Ø³ Ø§Ø² Ù‡Ø±Ø³ Ø¨Ø§Ø¹Ø« Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ù…Ø¯Ù„ Ø¨ØªÙˆØ§Ù†Ø¯ Ø§Ø² Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†Ø¯. Ø§ÛŒÙ† ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ù‡ Ù…Ø¯Ù„ Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ø±Ø§ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ ÛŒØ§Ø¯ Ø¨Ú¯ÛŒØ±Ø¯ Ùˆ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ù‡Ø¯. Ù‡Ù…Ú†Ù†ÛŒÙ†ØŒ Ù¾Ø³ Ø§Ø² Ø­Ø°Ù ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ ØºÛŒØ±Ø¶Ø±ÙˆØ±ÛŒØŒ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ù…Ø¬Ø¯Ø¯ ØªØ¹Ø§Ø¯Ù„ Ø¨ÛŒÙ† Ø¯Ù‚Øª Ùˆ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¯Ø± Ù†ØªÛŒØ¬Ù‡ØŒ Ù…Ø¯Ù„ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ù‡ Ø­Ø¯Ø§Ú©Ø«Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø®ÙˆØ¯ Ø¯Ø³Øª ÛŒØ§Ø¨Ø¯ Ùˆ Ø¯Ù‚Øª Ø±Ø§ Ø­ÙØ¸ ÛŒØ§ Ø­ØªÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø®Ø´Ø¯.\n",
    "\"\"\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Ø³Ù‡ ØªÚ©Ù†ÛŒÚ© Ù‡Ø±Ø³ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ Ø¨Ù‡ Ù‡Ù…Ø±Ø§Ù‡ Ù…Ø²Ø§ÛŒØ§ Ùˆ Ù…Ø¹Ø§ÛŒØ¨ \n",
      "\n",
      "    Ù‡Ø±Ø³ Ø¨Ø¯ÙˆÙ† Ø³Ø§Ø®ØªØ§Ø± (Unstructured Pruning): ÙˆØ²Ù†â€ŒÙ‡Ø§ Ø¨Ù‡â€ŒØ·ÙˆØ± ØªØµØ§Ø¯ÙÛŒ Ø­Ø°Ù Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯. Ù…Ø²ÛŒØª: Ø³Ø§Ø¯Ú¯ÛŒ Ùˆ Ú©Ø§Ù‡Ø´ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø¯Ù„. Ù…Ø¹Ø§ÛŒØ¨: Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø² Ø¯Ø³Øª Ø¯Ø§Ø¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ù‡Ù… Ùˆ Ú©Ø§Ù‡Ø´ Ú©Ø§Ø±Ø§ÛŒÛŒ.\n",
      "    Ù‡Ø±Ø³ Ø³Ø§Ø®ØªØ§Ø±ÛŒ (Structured Pruning): Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ ÛŒØ§ ÙÛŒÙ„ØªØ±Ù‡Ø§ Ø¨Ù‡â€ŒØ·ÙˆØ± Ú©Ø§Ù…Ù„ Ø­Ø°Ù Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯. Ù…Ø²ÛŒØª: Ø­ÙØ¸ Ø³Ø§Ø®ØªØ§Ø± Ù…Ø¯Ù„ Ùˆ Ú©Ø§Ù‡Ø´ Ù‡Ø²ÛŒÙ†Ù‡ Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ. Ù…Ø¹Ø§ÛŒØ¨: Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ø¨ÛŒØ´ØªØ± Ùˆ Ø§Ø­ØªÙ…Ø§Ù„ Ú©Ø§Ù‡Ø´ Ø§Ù†Ø¹Ø·Ø§Ùâ€ŒÙ¾Ø°ÛŒØ±ÛŒ.\n",
      "    Ù‡Ø±Ø³ Ù…Ø­Ù„ÛŒ (Local Pruning): Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ùˆ Ø¯Ø± Ù†ÙˆØ§Ø­ÛŒ Ø®Ø§Øµ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ù…Ø²ÛŒØª: Ø­ÙØ¸ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ù‡Ù… Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±. Ù…Ø¹Ø§ÛŒØ¨: Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ø¨ÛŒØ´ØªØ± Ùˆ Ø¹Ø¯Ù… ØªØ¹Ù…ÛŒÙ…â€ŒÙ¾Ø°ÛŒØ±ÛŒ.\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "  Ù‡Ø±Ø³ Ù…Ø¯Ù„ Ø¯Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø¯ÛŒÚ¯Ø± Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ Ú†Ù‡ Ù…Ø²Ø§ÛŒØ§ Ùˆ Ù…Ø¹Ø§ÛŒØ¨ÛŒ Ø¯Ø§Ø±Ø¯ \n",
      "    \n",
      "    Ø¯Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø¯ÛŒÚ¯Ø± Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒØŒ Ù‡Ø±Ø³ Ù…Ø¯Ù„ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù…Ù†Ø¬Ø± Ø¨Ù‡ Ú©Ø§Ù‡Ø´ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø¯Ù„ Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´ÙˆØ¯ØŒ Ø§Ù…Ø§ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ù‚Øª Ù…Ø¯Ù„ Ú©Ø§Ù‡Ø´ ÛŒØ§Ø¨Ø¯. ÙØ§Ú©ØªÙˆØ±Ú¯ÛŒØ±ÛŒ Ø±ØªØ¨Ù‡ Ù¾Ø§ÛŒÛŒÙ† Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ Ù…Ø¯Ù„ Ø±Ø§ Ú©Ø§Ù‡Ø´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ùˆ Ø¯Ù‚Øª Ø±Ø§ Ø­ÙØ¸ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ø§Ù…Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡â€ŒØªØ±ÛŒ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ø¯. Ø¯ÛŒØ³ØªÛŒÙ„Ø³ÛŒÙˆÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©ØªØ±ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø´Ø§Ø¨Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ØªØ± Ø±Ø§ Ø­ÙØ¸ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ØŒ ÙˆÙ„ÛŒ Ø¨Ù‡ ÛŒÚ© Ù…Ø¯Ù„ Ù…Ø¹Ù„Ù… Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ø¯ Ùˆ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ù‚Øª Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ù‡Ø¯. Ú©ÙˆØ§Ù†ØªÛŒØ²Ø§Ø³ÛŒÙˆÙ† Ø­Ø¬Ù… Ø­Ø§ÙØ¸Ù‡ Ù…Ø¯Ù„ Ø±Ø§ Ú©Ø§Ù‡Ø´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ùˆ Ø³Ø±Ø¹Øª Ø§Ø¬Ø±Ø§ Ø±Ø§ Ø¨Ø§Ù„Ø§ Ù…ÛŒâ€ŒØ¨Ø±Ø¯ØŒ Ø§Ù…Ø§ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ù‚Øª Ø±Ø§ ØªØ­Øª ØªØ§Ø«ÛŒØ± Ù‚Ø±Ø§Ø± Ø¯Ù‡Ø¯ Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø± Ø®Ø§ØµÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯.\n",
      "    \n",
      "    \n",
      "    ØªØ§Ø«ÛŒØ± Ù‡Ø±Ø³ Ø¨Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ú†Ú¯ÙˆÙ†Ù‡ Ø§Ø³ØªØŸ Ú†Ú¯ÙˆÙ†Ù‡ Ù‡Ø±Ø³ Ø¨Ø§Ø¹Ø« Ú©Ø§Ù‡Ø´ Ø­Ø§ÙØ¸Ù‡ Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŸ \n",
      "    Ù‡Ø±Ø³ Ù…Ø¯Ù„ Ø¨Ø§Ø¹Ø« Ú©Ø§Ù‡Ø´ Ø­Ø§ÙØ¸Ù‡ Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ø­Ø°Ù Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ ØºÛŒØ±Ø¶Ø±ÙˆØ±ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ Ú©Ù‡ Ø§ÛŒÙ† Ø§Ù…Ø± Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¯Ø± Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±Ù‡Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯ Ù…Ù†Ø¬Ø± Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ø¨Ø§ Ø§ÛŒÙ† Ø­Ø§Ù„ØŒ Ù‡Ø±Ø³ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ù‚Øª Ù…Ø¯Ù„ Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ù‡Ø¯ Ú†ÙˆÙ† Ø¨Ø±Ø®ÛŒ Ø§Ø² Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù…Ù‡Ù… Ø¨Ø±Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø§Ø² Ø¨ÛŒÙ† Ù…ÛŒâ€ŒØ±ÙˆÙ†Ø¯. Ø­Ø°Ù ÙˆØ²Ù†â€ŒÙ‡Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¸Ø±ÙÛŒØª Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚ Ú©Ø§Ù‡Ø´ Ø¯Ù‡Ø¯. Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ†ØŒ Ù‡Ø±Ø³ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ Ø¯Ù‚Øª Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯ ØªØ§ Ù‡Ù…Ø²Ù…Ø§Ù† Ø¨Ø§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø¨Ø¹ØŒ Ø¯Ù‚Øª Ù…Ø¯Ù„ Ø­ÙØ¸ Ø´ÙˆØ¯. Ø¯Ø± Ú©Ù„ØŒ Ù‡Ø±Ø³ ØªØ§Ø«ÛŒØ± Ù…Ø«Ø¨Øª Ø¨Ø± Ø³Ø±Ø¹Øª Ùˆ Ø­Ø§ÙØ¸Ù‡ Ø¯Ø§Ø±Ø¯ Ø§Ù…Ø§ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø± Ø¯Ù‚Øª Ø§Ø«Ø± Ù…Ù†ÙÛŒ Ø¨Ú¯Ø°Ø§Ø±Ø¯.\n",
      "    \n",
      "    Ú†Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ù…Ø¬Ø¯Ø¯ Ù¾Ø³ Ø§Ø² Ù‡Ø±Ø³ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡ Ø±Ø§ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ù‡Ø¯ØŸ \n",
      "    ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ù…Ø¬Ø¯Ø¯ Ù¾Ø³ Ø§Ø² Ù‡Ø±Ø³ Ø¨Ø§Ø¹Ø« Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ù…Ø¯Ù„ Ø¨ØªÙˆØ§Ù†Ø¯ Ø§Ø² Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†Ø¯. Ø§ÛŒÙ† ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ù‡ Ù…Ø¯Ù„ Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ø±Ø§ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ ÛŒØ§Ø¯ Ø¨Ú¯ÛŒØ±Ø¯ Ùˆ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ù‡Ø¯. Ù‡Ù…Ú†Ù†ÛŒÙ†ØŒ Ù¾Ø³ Ø§Ø² Ø­Ø°Ù ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ ØºÛŒØ±Ø¶Ø±ÙˆØ±ÛŒØŒ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ù…Ø¬Ø¯Ø¯ ØªØ¹Ø§Ø¯Ù„ Ø¨ÛŒÙ† Ø¯Ù‚Øª Ùˆ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¯Ø± Ù†ØªÛŒØ¬Ù‡ØŒ Ù…Ø¯Ù„ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ù‡ Ø­Ø¯Ø§Ú©Ø«Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø®ÙˆØ¯ Ø¯Ø³Øª ÛŒØ§Ø¨Ø¯ Ùˆ Ø¯Ù‚Øª Ø±Ø§ Ø­ÙØ¸ ÛŒØ§ Ø­ØªÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø®Ø´Ø¯.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xI_2knW0NkyY"
   },
   "source": [
    "# **Ù†Ú©Ø§Øª Ù…Ù‡Ù…**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEig2qIiMDhR"
   },
   "source": [
    "<div dir=\"rtl\" style=\"font-family: Vazir; width: 85%; font-size: 16px;\">\n",
    "\n",
    "</div>\n",
    "<h4 dir=\"rtl\" style=\"font-family: Vazir; width: 85%;\">ÙØ§ÛŒÙ„ Ø§Ø±Ø³Ø§Ù„ÛŒ Ø´Ù…Ø§ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ ÙØ±Ù…Øª Ø²ÛŒØ± Ù†Ø§Ù…Ú¯Ø°Ø§Ø±ÛŒ Ø´ÙˆØ¯: <code>NLP_CA4_LASTNAME_STUDENTID.ipynb</code></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuwVuIa0MDhR"
   },
   "source": [
    "<h4 dir=\"rtl\" style=\"font-family: Vazir; width: 85%;\">Ù†Ø­ÙˆÙ‡ Ø§Ù†Ø¬Ø§Ù… Ø§ÛŒÙ† ØªÙ…Ø±ÛŒÙ†:</h4>\n",
    "<ul dir=\"rtl\" style=\"font-family: Vazir; width: 85%; font-size: 16px;\"> <li>Ø¨Ø±Ø®ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù†ÙˆØ´ØªÙ† Ú©Ø¯ Ù¾Ø§ÛŒØªÙˆÙ† Ùˆ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¯Ø§Ø±Ù†Ø¯ØŒ Ùˆ Ø¨Ù‚ÛŒÙ‡ Ø¢Ù†Ù‡Ø§ Ø¯Ø§Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ù†ÙˆØ´ØªØ§Ø±ÛŒ Ù‡Ø³ØªÙ†Ø¯. Ø¨Ø±Ø§ÛŒ Ù…Ø³Ø§Ø¦Ù„ Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒØŒ Ø¨Ø§ÛŒØ¯ ØªÙ…Ø§Ù… Ø¨Ù„ÙˆÚ©â€ŒÙ‡Ø§ÛŒ Ú©Ø¯ÛŒ Ú©Ù‡ Ø¨Ø§ <code>#WRITE YOUR CODE HERE</code> Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯.</li> <li>Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒØŒ Ø¨Ø§ÛŒØ¯ Ù…ØªÙ†ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯ \"Ù¾Ø§Ø³Ø® Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯...\" Ø±Ø§ Ø¨Ø§ Ù¾Ø§Ø³Ø® ÙˆØ§Ù‚Ø¹ÛŒ Ø®ÙˆØ¯ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒØ¯.</li> </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efm7DICPMDhS"
   },
   "source": [
    "<h4 dir=\"rtl\" style=\"font-family: Vazir; width: 85%;\">ØµØ¯Ø§Ù‚Øª Ø¹Ù„Ù…ÛŒ:</h4> <ul dir=\"rtl\" style=\"font-family: Vazir; width: 85%; font-size: 16px;\"> <li>Ù…Ø§ Ù†ÙˆØªâ€ŒØ¨ÙˆÚ©â€ŒÙ‡Ø§ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´Ø®ØµÛŒ Ø§Ø² Ø¯Ø§Ù†Ø´Ø¬ÙˆÛŒØ§Ù† Ú©Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª ØªØµØ§Ø¯ÙÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ØŒ Ø¨Ø±Ø±Ø³ÛŒ Ø®ÙˆØ§Ù‡ÛŒÙ… Ú©Ø±Ø¯. Ø§ÛŒÙ† Ø¨Ø±Ø±Ø³ÛŒâ€ŒÙ‡Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ Ú©Ù‡ Ú©Ø¯ÛŒ Ú©Ù‡ Ù†ÙˆØ´ØªÛŒØ¯ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© Ø´Ù…Ø§ Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø§Ú¯Ø± Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ ØµØ­ÛŒØ­ Ø±Ø§ Ø¯Ø± Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© Ø®ÙˆØ¯ Ø¨Ø¯ÙˆÙ† Ú©Ø¯ÛŒ Ú©Ù‡ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ø¢Ù† Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†Ø¯ ØªØ­ÙˆÛŒÙ„ Ø¯Ù‡ÛŒØ¯ØŒ Ø§ÛŒÙ† ÛŒÚ© Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒ Ø§Ø² Ø¹Ø¯Ù… ØµØ¯Ø§Ù‚Øª Ø¹Ù„Ù…ÛŒ Ù…Ø­Ø³ÙˆØ¨ Ù…ÛŒâ€ŒØ´ÙˆØ¯.</li> <li>Ù…Ø§ Ù‡Ù…Ú†Ù†ÛŒÙ† Ø¨Ø±Ø±Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±ÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø³Ø±Ù‚Øª Ø¹Ù„Ù…ÛŒ Ø¯Ø± Ù†ÙˆØªâ€ŒØ¨ÙˆÚ©â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÙ„Ø¨ Ø§Ù†Ø¬Ø§Ù… Ø®ÙˆØ§Ù‡ÛŒÙ… Ø¯Ø§Ø¯. Ú©Ù¾ÛŒ Ú©Ø±Ø¯Ù† Ú©Ø¯ Ø§Ø² Ø¯ÛŒÚ¯Ø±Ø§Ù† Ù†ÛŒØ² ÛŒÚ© Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒ Ø§Ø² Ø¹Ø¯Ù… ØµØ¯Ø§Ù‚Øª Ø¹Ù„Ù…ÛŒ Ù…Ø­Ø³ÙˆØ¨ Ù…ÛŒâ€ŒØ´ÙˆØ¯.</li> </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqNfFt5AMDhS"
   },
   "source": [
    "<h4 dir=\"rtl\" style=\"font-family: Vazir; width: 85%;\">ØªÙˆØ¶ÛŒØ­Ø§Øª ØªÚ©Ù…ÛŒÙ„ÛŒ:</h4> <ul dir=\"rtl\" style=\"font-family: Vazir; width: 85%; font-size: 16px;\">\n",
    "<li>\n",
    "Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ùˆ Ø¯Ù‚Øª Ø¨Ø±Ø±Ø³ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ Ø§Ø² Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø®ÙˆØ±Ø¯Ø§Ø± Ø§Ø³Øª. Ø¨Ù‡ ØªÙ…Ø±ÛŒÙ†â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª Ú©Ø§ØºØ°ÛŒ ØªØ­ÙˆÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆÙ†Ø¯ ÛŒØ§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¹Ú©Ø³ Ø¯Ø± Ø³Ø§ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´ÙˆÙ†Ø¯ØŒ ØªØ±ØªÛŒØ¨ Ø§Ø«Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ Ù†Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.</li>\n",
    "<li>\n",
    " Ù‡Ù…Ù‡â€ŒÛŒ Ú©Ø¯Ù‡Ø§ÛŒ Ù¾ÛŒÙˆØ³Øª Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø§ÛŒØ³ØªÛŒ Ù‚Ø§Ø¨Ù„ÛŒØª Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø¬Ø¯Ø¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯. Ø¯Ø± ØµÙˆØ±ØªÛŒ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ Ù…Ø¬Ø¯Ø¯ Ø¢Ù†â€ŒÙ‡Ø§ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø®Ø§ØµÛŒ Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯ØŒ Ø¨Ø§ÛŒØ³ØªÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø±Ø§ Ù†ÛŒØ² Ø¯Ø± Ú¯Ø²Ø§Ø±Ø´ Ø®ÙˆØ¯ Ø°Ú©Ø± Ú©Ù†ÛŒØ¯.  Ø¯Ù‚Øª Ú©Ù†ÛŒØ¯ Ú©Ù‡  ØªÙ…Ø§Ù…ÛŒ Ú©Ø¯Ù‡Ø§ Ø¨Ø§ÛŒØ¯ ØªÙˆØ³Ø· Ø´Ù…Ø§ Ø§Ø¬Ø±Ø§ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ù†Ø¯ Ùˆ Ù†ØªØ§ÛŒØ¬ Ø§Ø¬Ø±Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ Ú©Ø¯Ù‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ÛŒ Ù…Ø´Ø®Øµ Ø¨Ø§Ø´Ø¯. Ø¨Ù‡ Ú©Ø¯Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ù†ØªØ§ÛŒØ¬ Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ù†â€ŒÙ‡Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ Ø§Ø±Ø³Ø§Ù„ÛŒ Ù…Ø´Ø®Øµ Ù†Ø¨Ø§Ø´Ø¯ Ù†Ù…Ø±Ù‡â€ŒØ§ÛŒ ØªØ¹Ù„Ù‚ Ù†Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯.\n",
    "</li>\n",
    "<li>\n",
    "ØªÙ…Ø±ÛŒÙ† ØªØ§ ÛŒÚ© Ù‡ÙØªÙ‡ Ø¨Ø¹Ø¯ Ø§Ø² Ù…Ù‡Ù„Øª ØªØ¹ÛŒÛŒÙ† Ø´Ø¯Ù‡ Ø¨Ø§ ØªØ§Ø®ÛŒØ± ØªØ­ÙˆÛŒÙ„ Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ø¯Ù‚Øª Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ø´Ù…Ø§ Ø¬Ù…Ø¹Ø§Ù‹ Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… ØªÚ©Ø§Ù„ÛŒÙØŒ Û±Û´ Ø±ÙˆØ² Ø²Ù…Ø§Ù† ØªØ­ÙˆÛŒÙ„ Ø¨Ø¯ÙˆÙ† Ø¬Ø±ÛŒÙ…Ù‡ Ø¯Ø§Ø±ÛŒØ¯ Ú©Ù‡ ØªÙ†Ù‡Ø§ Ø§Ø² Û· Ø±ÙˆØ² Ø¢Ù† Ø¨Ø±Ø§ÛŒ Ù‡Ø± ØªÙ…Ø±ÛŒÙ† Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯. Ø¯Ø± ØµÙˆØ±ØªÛŒ Ú©Ù‡ Ø§ÛŒÙ† Û±Û´ Ø±ÙˆØ² Ø¨Ù‡ Ø§ØªÙ…Ø§Ù… Ø±Ø³ÛŒØ¯Ù‡ Ø¨Ø§Ø´Ø¯ØŒ Ø¨Ù‡ Ø§Ø²Ø§ÛŒ Ù‡Ø± Ø±ÙˆØ² ØªØ§Ø®ÛŒØ± Ø¯Ù‡ Ø¯Ø±ØµØ¯ Ø¬Ø±ÛŒÙ…Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
    "</li>\n",
    "<li>ØªÙˆØ¬Ù‡ Ú©Ù†ÛŒØ¯ Ø§ÛŒÙ† ØªÙ…Ø±ÛŒÙ† Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ ØµÙˆØ±Øª ØªÚ©â€ŒÙ†ÙØ±Ù‡ Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯ Ùˆ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø¨Ø§ÛŒØ¯ Ù†ØªÛŒØ¬Ù‡ ÙØ¹Ø§Ù„ÛŒØª ÙØ±Ø¯ Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ø¨Ø§Ø´Ø¯ (Ù‡Ù…ÙÚ©Ø±ÛŒ Ùˆ Ø¨Ù‡ Ø§ØªÙØ§Ù‚ Ù‡Ù… Ù†ÙˆØ´ØªÙ† ØªÙ…Ø±ÛŒÙ† Ù†ÛŒØ² Ù…Ù…Ù†ÙˆØ¹ Ø§Ø³Øª). Ø¯Ø± ØµÙˆØ±Øª Ù…Ø´Ø§Ù‡Ø¯Ù‡\n",
    " ØªØ´Ø§Ø¨Ù‡ Ø¨Ù‡ Ù‡Ù…Ù‡ Ø§ÙØ±Ø§Ø¯ Ù…Ø´Ø§Ø±Ú©Øªâ€ŒÚ©Ù†Ù†Ø¯Ù‡ØŒ Ù†Ù…Ø±Ù‡ ØªÙ…Ø±ÛŒÙ† ØµÙØ± Ùˆ Ø¨Ù‡ Ø§Ø³ØªØ§Ø¯ Ú¯Ø²Ø§Ø±Ø´ Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø¯.\n",
    " </li>\n",
    " <li>Ø¨Ø±Ø§ÛŒ Ù…Ø·Ø§Ù„Ø¹Ù‡ Ø¨ÛŒØ´ØªØ± Ø¯Ø±Ø¨Ø§Ø±Ù‡â€ŒÛŒ ÙØ±Ù…Øª Ù…Ø§Ø±Ú©â€ŒØ¯ÙˆÙ† Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² <a href=\"https://github.com/tajaddini/Persian-Markdown/blob/master/learn-MD.md\">Ø§ÛŒÙ† Ù„ÛŒÙ†Ú©</a> Ù…Ø·Ø§Ù„Ø¹Ù‡ Ú©Ù†ÛŒØ¯.\n",
    " </li>\n",
    "\n",
    " </ul>\n",
    " </div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "e9694627796b4f5786ff700dab3b170b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b5ccba4f497a4c0c97ef8e6a96469844",
       "IPY_MODEL_2bd1d8c3555f41ceabfb1573912152d9",
       "IPY_MODEL_06074ba7900949d9b2519dfea83c94e4"
      ],
      "layout": "IPY_MODEL_2379ccf18d0f4b6bb934486b0619adf0"
     }
    },
    "b5ccba4f497a4c0c97ef8e6a96469844": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_630bbc44049a46e3b325760b73e24a56",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_183c716e62684f8a8852618d4451991e",
      "value": "Map:â€‡100%"
     }
    },
    "2bd1d8c3555f41ceabfb1573912152d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_307d91a57fe44fc2a1290144f035bddb",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_42ab117718da4cb09cdb2055f766ec1f",
      "value": 500
     }
    },
    "06074ba7900949d9b2519dfea83c94e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_febf915104234064b548caeae5822c88",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c822d8858bb346e2b6cd554e5472675a",
      "value": "â€‡500/500â€‡[00:00&lt;00:00,â€‡14786.07â€‡examples/s]"
     }
    },
    "2379ccf18d0f4b6bb934486b0619adf0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "630bbc44049a46e3b325760b73e24a56": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "183c716e62684f8a8852618d4451991e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "307d91a57fe44fc2a1290144f035bddb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42ab117718da4cb09cdb2055f766ec1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "febf915104234064b548caeae5822c88": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c822d8858bb346e2b6cd554e5472675a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "18073111638147ff9f0955bbf81d0b05": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_90d61c7523294e328ee30706f5a2d5db",
       "IPY_MODEL_a458ea4c5e38449d9d3bcf340b4f5380",
       "IPY_MODEL_fc8f2111100a4ae8b719e942fe7e0ff3"
      ],
      "layout": "IPY_MODEL_7bb7bf42314e4c9f9273a6ebecb3cdb9"
     }
    },
    "90d61c7523294e328ee30706f5a2d5db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56cbaac128e24d6e86ac5f24dae3451d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_dbdd1eb2ab104058b225892890743e43",
      "value": "tokenizer_config.json:â€‡100%"
     }
    },
    "a458ea4c5e38449d9d3bcf340b4f5380": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b698bcc7fb8a45afaca5f3725a496a8b",
      "max": 25,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1cf14c31ed624840a9ea685001badedc",
      "value": 25
     }
    },
    "fc8f2111100a4ae8b719e942fe7e0ff3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b699f76445694685a79b974c496aa5c7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9f596f30b7244f19ba3e146a4f478991",
      "value": "â€‡25.0/25.0â€‡[00:00&lt;00:00,â€‡714B/s]"
     }
    },
    "7bb7bf42314e4c9f9273a6ebecb3cdb9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56cbaac128e24d6e86ac5f24dae3451d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbdd1eb2ab104058b225892890743e43": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b698bcc7fb8a45afaca5f3725a496a8b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1cf14c31ed624840a9ea685001badedc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b699f76445694685a79b974c496aa5c7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f596f30b7244f19ba3e146a4f478991": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d239422e9076457cbb57b5fd8e42d4b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a86c70356888413e9b583650cbd36627",
       "IPY_MODEL_f455532c7c0e4559a9961a83d0ba957b",
       "IPY_MODEL_2a6c76f5f3334f83bd32141470b2037e"
      ],
      "layout": "IPY_MODEL_2932f7c4450e47d49bb0bfc9e5b59123"
     }
    },
    "a86c70356888413e9b583650cbd36627": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a09bff9b10034f3a936532a2ad59e1fe",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_07cd0c71457c47c6853e9db6f341aad5",
      "value": "config.json:â€‡100%"
     }
    },
    "f455532c7c0e4559a9961a83d0ba957b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c12126e4d094ebba02c8ebac5901485",
      "max": 482,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c56a8d81f12f4622a61fea35f90fd294",
      "value": 482
     }
    },
    "2a6c76f5f3334f83bd32141470b2037e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94e47b6e9fba461d93686337d9cc2df1",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_277316b857694074ab7a596825887979",
      "value": "â€‡482/482â€‡[00:00&lt;00:00,â€‡8.56kB/s]"
     }
    },
    "2932f7c4450e47d49bb0bfc9e5b59123": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a09bff9b10034f3a936532a2ad59e1fe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07cd0c71457c47c6853e9db6f341aad5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c12126e4d094ebba02c8ebac5901485": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c56a8d81f12f4622a61fea35f90fd294": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "94e47b6e9fba461d93686337d9cc2df1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "277316b857694074ab7a596825887979": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd5a7d13ac2f4cb3b3b3c5ffb4f88e5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2321c7ce6343443882c0e294451cc404",
       "IPY_MODEL_c6b54372970549bfbb2d4c8b77128fc6",
       "IPY_MODEL_23d7e33aaa3a4d96a782491688748e09"
      ],
      "layout": "IPY_MODEL_5d22dcb79a134ca281a3d50a805ab4b7"
     }
    },
    "2321c7ce6343443882c0e294451cc404": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2f1fcc486a8460ca049b97279bcf6d5",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cc6efec711f44fba9a7f4eb0035b3d34",
      "value": "vocab.json:â€‡100%"
     }
    },
    "c6b54372970549bfbb2d4c8b77128fc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf490ff44ef947e1986a0517c004a095",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a4b6c0aed69247c4bdd0610449db1166",
      "value": 898823
     }
    },
    "23d7e33aaa3a4d96a782491688748e09": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff18ad906a0c497a91ef3bdf8cafb7c8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cefec0596137440cbd8e54b5fc738029",
      "value": "â€‡899k/899kâ€‡[00:00&lt;00:00,â€‡1.31MB/s]"
     }
    },
    "5d22dcb79a134ca281a3d50a805ab4b7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2f1fcc486a8460ca049b97279bcf6d5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc6efec711f44fba9a7f4eb0035b3d34": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf490ff44ef947e1986a0517c004a095": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4b6c0aed69247c4bdd0610449db1166": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ff18ad906a0c497a91ef3bdf8cafb7c8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cefec0596137440cbd8e54b5fc738029": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f657ee09a724d29a00071ee7c6bd78b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_899248dc8031417da6225c1dc3e35547",
       "IPY_MODEL_d31ec9b854ab4c14a18b9c4244c4de09",
       "IPY_MODEL_1846f523c01b4bc3a5af821fb056b0dc"
      ],
      "layout": "IPY_MODEL_c2118dd6916d4a8b89d0b4dfa70060e0"
     }
    },
    "899248dc8031417da6225c1dc3e35547": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14e255109295400587d4f38d8ccc8b75",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_24294a1a72f64d658f4cf8bea5153555",
      "value": "merges.txt:â€‡100%"
     }
    },
    "d31ec9b854ab4c14a18b9c4244c4de09": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6dc977c1d42948d7a3abd0b409a45ee7",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f4e17b485e764d84b8c592383300903b",
      "value": 456318
     }
    },
    "1846f523c01b4bc3a5af821fb056b0dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f17a236f4874cf0ab1e0a221f4d3ba2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_087000335fc44e99a64cb7bdd58e5b48",
      "value": "â€‡456k/456kâ€‡[00:00&lt;00:00,â€‡1.07MB/s]"
     }
    },
    "c2118dd6916d4a8b89d0b4dfa70060e0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14e255109295400587d4f38d8ccc8b75": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24294a1a72f64d658f4cf8bea5153555": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6dc977c1d42948d7a3abd0b409a45ee7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4e17b485e764d84b8c592383300903b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5f17a236f4874cf0ab1e0a221f4d3ba2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "087000335fc44e99a64cb7bdd58e5b48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9cb8c4f02f58498ab92931b0970e9fdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_592d98108542433cb3a4ea93cce0b535",
       "IPY_MODEL_1e10429495eb4ee6b67d988cc505da44",
       "IPY_MODEL_1052aa85173a4978a09f10475e333eff"
      ],
      "layout": "IPY_MODEL_3854edd65288486ea8603dab10fe70a0"
     }
    },
    "592d98108542433cb3a4ea93cce0b535": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_597982f47ea24974827927d0bbe1fd97",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0b94ce4927654d89b89f3af141bb9cd7",
      "value": "tokenizer.json:â€‡100%"
     }
    },
    "1e10429495eb4ee6b67d988cc505da44": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_076e03cf988f49229a375134d8c42c8e",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0baf4fd20d4142c6a611c5e9c28130a8",
      "value": 1355863
     }
    },
    "1052aa85173a4978a09f10475e333eff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9fe0351536b4842a8915797af3fb31d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d87cac6b2d21481eb02424d60815ae36",
      "value": "â€‡1.36M/1.36Mâ€‡[00:01&lt;00:00,â€‡1.19MB/s]"
     }
    },
    "3854edd65288486ea8603dab10fe70a0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "597982f47ea24974827927d0bbe1fd97": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b94ce4927654d89b89f3af141bb9cd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "076e03cf988f49229a375134d8c42c8e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0baf4fd20d4142c6a611c5e9c28130a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d9fe0351536b4842a8915797af3fb31d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d87cac6b2d21481eb02424d60815ae36": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be58fa99be5047618084db9a572296ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_80c700c897e94d3983646cfc32c83120",
       "IPY_MODEL_242f980b60ed401dbaeb3cb6c33f7a84",
       "IPY_MODEL_ac94fbee2609457aa24d64ffbeee9214"
      ],
      "layout": "IPY_MODEL_e60fc2ef178445b9ac4e052a160d0144"
     }
    },
    "80c700c897e94d3983646cfc32c83120": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74bfb5fab9da4f05ba3477aecb317966",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7189308a93e741dab59f7bcb0e92f6d2",
      "value": "model.safetensors:â€‡100%"
     }
    },
    "242f980b60ed401dbaeb3cb6c33f7a84": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d79f1f78bb774e4bb779b28ae0439b81",
      "max": 1421700479,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_efca7867bf7f49d1b2f8263181dd2466",
      "value": 1421700479
     }
    },
    "ac94fbee2609457aa24d64ffbeee9214": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da5a2d88353c4b1cae7f75f57f59e82d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cdb4681e2112474697e64ae77b34fbf6",
      "value": "â€‡1.42G/1.42Gâ€‡[00:07&lt;00:00,â€‡115MB/s]"
     }
    },
    "e60fc2ef178445b9ac4e052a160d0144": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74bfb5fab9da4f05ba3477aecb317966": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7189308a93e741dab59f7bcb0e92f6d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d79f1f78bb774e4bb779b28ae0439b81": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efca7867bf7f49d1b2f8263181dd2466": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "da5a2d88353c4b1cae7f75f57f59e82d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdb4681e2112474697e64ae77b34fbf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7caada25255a4a2ea79fd4946350ce6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bcabe00f8cd44488a60fe2ef9720d544",
       "IPY_MODEL_4be3c92d41484d9990e2f427f70c05fb",
       "IPY_MODEL_3e7ea66a14d344e29137dfa1b70ae242"
      ],
      "layout": "IPY_MODEL_78152d8d7f4d42f082d958eefff2c456"
     }
    },
    "bcabe00f8cd44488a60fe2ef9720d544": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6702447046f4c0eb22443e46b8d267c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fd5f54010d134e788b24dedaff4a245c",
      "value": "README.md:â€‡100%"
     }
    },
    "4be3c92d41484d9990e2f427f70c05fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e88f13cba91d469b908a97a2c349c401",
      "max": 3266,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c123173aa3fb48fd842c3d432e0c1852",
      "value": 3266
     }
    },
    "3e7ea66a14d344e29137dfa1b70ae242": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_573cb53a00784628b8b1a70e9b44a819",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_591ecaf181ce46998684df7398bd0d04",
      "value": "â€‡3.27k/3.27kâ€‡[00:00&lt;00:00,â€‡209kB/s]"
     }
    },
    "78152d8d7f4d42f082d958eefff2c456": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6702447046f4c0eb22443e46b8d267c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd5f54010d134e788b24dedaff4a245c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e88f13cba91d469b908a97a2c349c401": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c123173aa3fb48fd842c3d432e0c1852": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "573cb53a00784628b8b1a70e9b44a819": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "591ecaf181ce46998684df7398bd0d04": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1204782198724a6489a97a1360def9b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c2288099b79b4f01b989110606af3f99",
       "IPY_MODEL_5258ad3d9c614684901455cdccca5464",
       "IPY_MODEL_0081b87457d74ff296ccf0bf7a44c1ea"
      ],
      "layout": "IPY_MODEL_c29abfebe6d64184aec032e1fc5f386a"
     }
    },
    "c2288099b79b4f01b989110606af3f99": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6866f5e2121c45c99056d17aff0389e3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6223496a27a74c018d32c640def1602c",
      "value": "train-00000-of-00001.parquet:â€‡100%"
     }
    },
    "5258ad3d9c614684901455cdccca5464": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e192f92c737245bcb543ade156c17734",
      "max": 3314963,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6591d105216c4cffad68fe6a9f08b5e0",
      "value": 3314963
     }
    },
    "0081b87457d74ff296ccf0bf7a44c1ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8691d7f7c463456e8d8a61edd8e14424",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_180a7f59f3504de39ceeaf196c344349",
      "value": "â€‡3.31M/3.31Mâ€‡[00:00&lt;00:00,â€‡14.5MB/s]"
     }
    },
    "c29abfebe6d64184aec032e1fc5f386a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6866f5e2121c45c99056d17aff0389e3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6223496a27a74c018d32c640def1602c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e192f92c737245bcb543ade156c17734": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6591d105216c4cffad68fe6a9f08b5e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8691d7f7c463456e8d8a61edd8e14424": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "180a7f59f3504de39ceeaf196c344349": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e2a6aaa33ea48579b2e48156809677e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_56752dbb306c491b96950db734080ea6",
       "IPY_MODEL_5f4b7c1b6638482e9f91ff02350f796c",
       "IPY_MODEL_f444c7714a3e497b974bb6cba3f94f0f"
      ],
      "layout": "IPY_MODEL_f0b196963d82478cbfaeb8952f226d40"
     }
    },
    "56752dbb306c491b96950db734080ea6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b76e1b20069349b385b879c3a508683d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c27391262e87428b97bf2af3c9ebf4f8",
      "value": "validation-00000-of-00001.parquet:â€‡100%"
     }
    },
    "5f4b7c1b6638482e9f91ff02350f796c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4be7077397484a66be454d94fdb7d29a",
      "max": 430645,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c53e5ad6d48c42879c70286d8b5e026d",
      "value": 430645
     }
    },
    "f444c7714a3e497b974bb6cba3f94f0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76dcb0f4857f4b00ae053048bc7b2439",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c3bc90276a734f058b59568bdbf5cb76",
      "value": "â€‡431k/431kâ€‡[00:00&lt;00:00,â€‡21.7MB/s]"
     }
    },
    "f0b196963d82478cbfaeb8952f226d40": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b76e1b20069349b385b879c3a508683d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c27391262e87428b97bf2af3c9ebf4f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4be7077397484a66be454d94fdb7d29a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c53e5ad6d48c42879c70286d8b5e026d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "76dcb0f4857f4b00ae053048bc7b2439": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3bc90276a734f058b59568bdbf5cb76": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0b384c1a1fe04a88b99402d863be256b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ee8a859a7e3f4051af73afe3596284c6",
       "IPY_MODEL_472d3e34c7be4f7ab1880cc1a2590ec3",
       "IPY_MODEL_0e71556a6d18400daa83b898c37fbfc8"
      ],
      "layout": "IPY_MODEL_066074ed0023419fa79c3dc0735836ef"
     }
    },
    "ee8a859a7e3f4051af73afe3596284c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc734652ac54484ba21e111aa1124b7c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_1219365db1ee430e820c57cc69766d21",
      "value": "test-00000-of-00001.parquet:â€‡100%"
     }
    },
    "472d3e34c7be4f7ab1880cc1a2590ec3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45ff2cd9367448208c03418cccb1e163",
      "max": 423065,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_676acf218792492eae3b6a76fd27a76f",
      "value": 423065
     }
    },
    "0e71556a6d18400daa83b898c37fbfc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ea4a612a0c44b8d9e403e31665b6ee8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b4932ec1661f419cbe9355bf0213a4a3",
      "value": "â€‡423k/423kâ€‡[00:00&lt;00:00,â€‡26.8MB/s]"
     }
    },
    "066074ed0023419fa79c3dc0735836ef": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc734652ac54484ba21e111aa1124b7c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1219365db1ee430e820c57cc69766d21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "45ff2cd9367448208c03418cccb1e163": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "676acf218792492eae3b6a76fd27a76f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3ea4a612a0c44b8d9e403e31665b6ee8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4932ec1661f419cbe9355bf0213a4a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5773a61f5e83417b87da26415ed9f64e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e301df9235a14e21b912aee03994bc54",
       "IPY_MODEL_f2daa4e9e411415ca1d16879be88d1d6",
       "IPY_MODEL_f9ba0df5051149a29f4a3ba34c6b17f7"
      ],
      "layout": "IPY_MODEL_a306af4e7f5d4ed5a0e695b6cba1438f"
     }
    },
    "e301df9235a14e21b912aee03994bc54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd068ea7c9d84b54aa7c2d08e93e0c55",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d5ff20bcb8304853aad3a37bd8d62206",
      "value": "Generatingâ€‡trainâ€‡split:â€‡100%"
     }
    },
    "f2daa4e9e411415ca1d16879be88d1d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88c543eac77548f9a568c04d95026500",
      "max": 26384,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09800f60c0ac4fc8b80fb8ed792ae5df",
      "value": 26384
     }
    },
    "f9ba0df5051149a29f4a3ba34c6b17f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39bb3ee089844427b02fd004abe24fb2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9c732a1cc6a64c89950a69b5b3ca3f7e",
      "value": "â€‡26384/26384â€‡[00:00&lt;00:00,â€‡132912.25â€‡examples/s]"
     }
    },
    "a306af4e7f5d4ed5a0e695b6cba1438f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd068ea7c9d84b54aa7c2d08e93e0c55": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5ff20bcb8304853aad3a37bd8d62206": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88c543eac77548f9a568c04d95026500": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09800f60c0ac4fc8b80fb8ed792ae5df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "39bb3ee089844427b02fd004abe24fb2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c732a1cc6a64c89950a69b5b3ca3f7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "351b7477ea0049a6852f0cc80c64f785": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_72ab6d70b7c7432a840a691e267ea7f8",
       "IPY_MODEL_6d15bbf859de4125a090d4dfc7e52d91",
       "IPY_MODEL_4bcf1637435c4b3eb7840bb3a309a50a"
      ],
      "layout": "IPY_MODEL_a1ce14a7425d477bb45ce7d417dc21fb"
     }
    },
    "72ab6d70b7c7432a840a691e267ea7f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ff0cbc21fdb4733972f56ac299c12dc",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0b4672e88cea4a7bbf3d7c5b035c3367",
      "value": "Generatingâ€‡validationâ€‡split:â€‡100%"
     }
    },
    "6d15bbf859de4125a090d4dfc7e52d91": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3dde3fbd007941bb94e814586a556a73",
      "max": 3296,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5f254fa72f6f4e9281da4fbbaa1e8ec5",
      "value": 3296
     }
    },
    "4bcf1637435c4b3eb7840bb3a309a50a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a5d4411b8244d79bd515f563ee07f91",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_81ac9011c8ef4cffb1a6f7ca8eca94f6",
      "value": "â€‡3296/3296â€‡[00:00&lt;00:00,â€‡57929.80â€‡examples/s]"
     }
    },
    "a1ce14a7425d477bb45ce7d417dc21fb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ff0cbc21fdb4733972f56ac299c12dc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b4672e88cea4a7bbf3d7c5b035c3367": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3dde3fbd007941bb94e814586a556a73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f254fa72f6f4e9281da4fbbaa1e8ec5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8a5d4411b8244d79bd515f563ee07f91": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81ac9011c8ef4cffb1a6f7ca8eca94f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "efef75d0e65c4048b6cf3dbf600e1503": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e8b4ec3474a14e2e893feac4b0429d33",
       "IPY_MODEL_c2afb53b64ff42fdbbca34b950072055",
       "IPY_MODEL_c365d5e6d609433aa4f5777f70fdfa13"
      ],
      "layout": "IPY_MODEL_0ebc9049dce948faac4eb677ead240c8"
     }
    },
    "e8b4ec3474a14e2e893feac4b0429d33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33b97d361e5640e791e455878cd72afb",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_40f17fa1eb3248b8b725b4333173a5ff",
      "value": "Generatingâ€‡testâ€‡split:â€‡100%"
     }
    },
    "c2afb53b64ff42fdbbca34b950072055": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ab0ea6224964bbab151ebef3c6ef23c",
      "max": 3296,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2d1a9ce408094d1dbf00bfb87a068b73",
      "value": 3296
     }
    },
    "c365d5e6d609433aa4f5777f70fdfa13": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7bfaaff485e64f7fb4bba5a42f33b629",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cb08945e33c14d88b9cf82ca58e357e2",
      "value": "â€‡3296/3296â€‡[00:00&lt;00:00,â€‡70846.90â€‡examples/s]"
     }
    },
    "0ebc9049dce948faac4eb677ead240c8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33b97d361e5640e791e455878cd72afb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40f17fa1eb3248b8b725b4333173a5ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ab0ea6224964bbab151ebef3c6ef23c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d1a9ce408094d1dbf00bfb87a068b73": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7bfaaff485e64f7fb4bba5a42f33b629": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb08945e33c14d88b9cf82ca58e357e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e1cb8126fd34316a399d45119233698": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a8c13cd56ad445a3a0eee1944d616b54",
       "IPY_MODEL_823ff306347e4b89a922914b2e799d20",
       "IPY_MODEL_d3d120d6aab1489bba742bed82be3663"
      ],
      "layout": "IPY_MODEL_980d1bf3e8b34d6d85df0126020ee64f"
     }
    },
    "a8c13cd56ad445a3a0eee1944d616b54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd14e958c84e4975bc8391ae766833b0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6bbfe0e4aafd4b0a889167a1120b9957",
      "value": "README.md:â€‡100%"
     }
    },
    "823ff306347e4b89a922914b2e799d20": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ee55133e5ea479d9582a8ecc4b68074",
      "max": 12330,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_93ff055c233f4074b698547455cf85cf",
      "value": 12330
     }
    },
    "d3d120d6aab1489bba742bed82be3663": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df4a322fdbd04a10860c8a3d03b8e584",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c7bfaf4f6a0742c4ab71ae2151646c3f",
      "value": "â€‡12.3k/12.3kâ€‡[00:00&lt;00:00,â€‡717kB/s]"
     }
    },
    "980d1bf3e8b34d6d85df0126020ee64f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd14e958c84e4975bc8391ae766833b0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bbfe0e4aafd4b0a889167a1120b9957": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6ee55133e5ea479d9582a8ecc4b68074": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93ff055c233f4074b698547455cf85cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "df4a322fdbd04a10860c8a3d03b8e584": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7bfaf4f6a0742c4ab71ae2151646c3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b5d45d3637448c8a379fa31de96fe33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_660d1ba3ad464a1fb05562852893acee",
       "IPY_MODEL_970e5a5684a64ee7ba5ebf9f0e3db14c",
       "IPY_MODEL_6356ea46d8674dab9b9eb610e30e5247"
      ],
      "layout": "IPY_MODEL_af26c7aed95240dfadc723d799153e70"
     }
    },
    "660d1ba3ad464a1fb05562852893acee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc4fef0370ab42ea8ddeb0fc65a3b6db",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_1dd751001a6c49fb908c0d82cef674ea",
      "value": "conll2003.py:â€‡100%"
     }
    },
    "970e5a5684a64ee7ba5ebf9f0e3db14c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93ffbea052b24d4fb4371a8a7d964db6",
      "max": 9570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e3f71056b3f6478f96c66f21bd1966ec",
      "value": 9570
     }
    },
    "6356ea46d8674dab9b9eb610e30e5247": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f210ca931aa44d83a9cb4e38d20d85cf",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d8773a146c85401eaca7b27e2e60f521",
      "value": "â€‡9.57k/9.57kâ€‡[00:00&lt;00:00,â€‡719kB/s]"
     }
    },
    "af26c7aed95240dfadc723d799153e70": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc4fef0370ab42ea8ddeb0fc65a3b6db": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1dd751001a6c49fb908c0d82cef674ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93ffbea052b24d4fb4371a8a7d964db6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3f71056b3f6478f96c66f21bd1966ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f210ca931aa44d83a9cb4e38d20d85cf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8773a146c85401eaca7b27e2e60f521": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a1cad5fde8f4cb6a5b7113f3668499b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ca4da00629df41b19ca878ccc50c3d47",
       "IPY_MODEL_6170cfb70e344f04bda70ee1b6e06d1a",
       "IPY_MODEL_d1c789f25bba4bac9fade77b51f1a8ba"
      ],
      "layout": "IPY_MODEL_d15765fa3759480d8d4a20f3076140e4"
     }
    },
    "ca4da00629df41b19ca878ccc50c3d47": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2c138db0ab148f7a675173b658f25a2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0538617c89204a4d81c51eab56ec8b20",
      "value": "Downloadingâ€‡data:â€‡100%"
     }
    },
    "6170cfb70e344f04bda70ee1b6e06d1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6ab15911ade4ab49c254f2d35ec526a",
      "max": 982975,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_22633176e9cd45bba5c5f40b82323ac2",
      "value": 982975
     }
    },
    "d1c789f25bba4bac9fade77b51f1a8ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c94f00ff7314a0088f85abf3cb6ca30",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e10ff2bfcafe4b958e0f2ebacb449692",
      "value": "â€‡983k/983kâ€‡[00:00&lt;00:00,â€‡5.43MB/s]"
     }
    },
    "d15765fa3759480d8d4a20f3076140e4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2c138db0ab148f7a675173b658f25a2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0538617c89204a4d81c51eab56ec8b20": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b6ab15911ade4ab49c254f2d35ec526a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22633176e9cd45bba5c5f40b82323ac2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6c94f00ff7314a0088f85abf3cb6ca30": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e10ff2bfcafe4b958e0f2ebacb449692": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e78555d73b4d4b219e8f24b051f3cb9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ee755bbe9772403aa8fb11cc38e1b527",
       "IPY_MODEL_ccee26c5278f43c2a6d905d64d681834",
       "IPY_MODEL_dd6d881ab3d64210bf33879d8b7f26d9"
      ],
      "layout": "IPY_MODEL_8a68efc546af451e9ddc97acc1212843"
     }
    },
    "ee755bbe9772403aa8fb11cc38e1b527": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7e08ab0594948829138409404fcc159",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_22b61430c18d490a9e2da6dd6c908f15",
      "value": "Generatingâ€‡trainâ€‡split:â€‡100%"
     }
    },
    "ccee26c5278f43c2a6d905d64d681834": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75b0d5cbdfcf4ed29f4a1c66f45a0a56",
      "max": 14041,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b5cdb8fdc5114ffda6d6f6f9811b80af",
      "value": 14041
     }
    },
    "dd6d881ab3d64210bf33879d8b7f26d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a37ddf293b074744b167aaec6010b0ad",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fa4e4fbee31946db97c9b920043285b7",
      "value": "â€‡14041/14041â€‡[00:03&lt;00:00,â€‡4637.87â€‡examples/s]"
     }
    },
    "8a68efc546af451e9ddc97acc1212843": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7e08ab0594948829138409404fcc159": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22b61430c18d490a9e2da6dd6c908f15": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75b0d5cbdfcf4ed29f4a1c66f45a0a56": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5cdb8fdc5114ffda6d6f6f9811b80af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a37ddf293b074744b167aaec6010b0ad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa4e4fbee31946db97c9b920043285b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "efa64a232dd447b98d04dc484c20ac16": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_642f89f482924223a6dc0a9cb44567c2",
       "IPY_MODEL_e93ead4cb03d4dec88dad637fa73b01e",
       "IPY_MODEL_57ad02fe9363477cba106bf18b05a738"
      ],
      "layout": "IPY_MODEL_01db17a99d5540dd81f2d4841452945f"
     }
    },
    "642f89f482924223a6dc0a9cb44567c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4302b9fb8ed0470b8a53755aade7b080",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c5dc97f74d0545d8b6833737e67c1274",
      "value": "Generatingâ€‡validationâ€‡split:â€‡100%"
     }
    },
    "e93ead4cb03d4dec88dad637fa73b01e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d6fd2c7600e45178cd8ec8fd21e15c3",
      "max": 3250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6ced072c075d4d44aee0b6e9260f383d",
      "value": 3250
     }
    },
    "57ad02fe9363477cba106bf18b05a738": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8fba092d15b941bebe7f054729d3d88d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ccfc5899af0d4ae78e3ac10f4ec9c25f",
      "value": "â€‡3250/3250â€‡[00:01&lt;00:00,â€‡2284.18â€‡examples/s]"
     }
    },
    "01db17a99d5540dd81f2d4841452945f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4302b9fb8ed0470b8a53755aade7b080": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5dc97f74d0545d8b6833737e67c1274": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d6fd2c7600e45178cd8ec8fd21e15c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ced072c075d4d44aee0b6e9260f383d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8fba092d15b941bebe7f054729d3d88d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccfc5899af0d4ae78e3ac10f4ec9c25f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e79b8697b65f487b81268f8f966546c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_39be24d48be94c509700c1196bf6f992",
       "IPY_MODEL_624b8f69d3804ffe8a49143ea91f90cc",
       "IPY_MODEL_770e519121c34cf9abe80d1d4b84a0a2"
      ],
      "layout": "IPY_MODEL_e95fd5d405f74514a571ee3e71a7dda2"
     }
    },
    "39be24d48be94c509700c1196bf6f992": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11117652e28047d988aa4897766c58f8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9733c58d2941491e868db3a3c6448209",
      "value": "Generatingâ€‡testâ€‡split:â€‡100%"
     }
    },
    "624b8f69d3804ffe8a49143ea91f90cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa601664bdae4d1cab1709dce8b7677f",
      "max": 3453,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2ddd0ee8cbe443a7916e791db747bbd0",
      "value": 3453
     }
    },
    "770e519121c34cf9abe80d1d4b84a0a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b071c191fa8947cdbe9dbd0c3bd36ef9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6de100dda56c456b9aa75162a8cef5c6",
      "value": "â€‡3453/3453â€‡[00:01&lt;00:00,â€‡2342.01â€‡examples/s]"
     }
    },
    "e95fd5d405f74514a571ee3e71a7dda2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11117652e28047d988aa4897766c58f8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9733c58d2941491e868db3a3c6448209": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa601664bdae4d1cab1709dce8b7677f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ddd0ee8cbe443a7916e791db747bbd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b071c191fa8947cdbe9dbd0c3bd36ef9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6de100dda56c456b9aa75162a8cef5c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e90d96525b434f2e91736d030129b935": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc1215796e3c4e2588a922ee7e5a0d8c",
       "IPY_MODEL_5a1c0565b3574d3d826f597942aeacc6",
       "IPY_MODEL_8b641f0a4b664c048fb4dc63d3152e21"
      ],
      "layout": "IPY_MODEL_52f616c9e004473e891376d48d3b034f"
     }
    },
    "fc1215796e3c4e2588a922ee7e5a0d8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99cf32c1b07c4b0a966f3e9359e03a89",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8006ce3b7b8740b7a31d0f2878695da0",
      "value": ""
     }
    },
    "5a1c0565b3574d3d826f597942aeacc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77692a74cf9d4b18bb6abef4f4c01b06",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_65cc0c0f112647df89cda1ce613e057b",
      "value": 0
     }
    },
    "8b641f0a4b664c048fb4dc63d3152e21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_853df5f5b24a487eab1eb212d953cad4",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b0b6aa3442b642c19a83a69e1f098efd",
      "value": "â€‡0/0â€‡[00:00&lt;?,â€‡?it/s]"
     }
    },
    "52f616c9e004473e891376d48d3b034f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99cf32c1b07c4b0a966f3e9359e03a89": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8006ce3b7b8740b7a31d0f2878695da0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "77692a74cf9d4b18bb6abef4f4c01b06": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "65cc0c0f112647df89cda1ce613e057b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "853df5f5b24a487eab1eb212d953cad4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0b6aa3442b642c19a83a69e1f098efd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce8fabadfb0b49c399264e03c5c80512": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a2f33b7c0b8148ba87c35c29a032b837",
       "IPY_MODEL_1a4bd0c6b90744058263256a92f85fb4",
       "IPY_MODEL_38b1f2749c2c491e8178ff727eeceb63"
      ],
      "layout": "IPY_MODEL_351f39be330f45c69372637194c370af"
     }
    },
    "a2f33b7c0b8148ba87c35c29a032b837": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce713fc43e414c3b82b33a0c29a32db9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c1f857b71c554182be6412cf74bc29c4",
      "value": "tokenizer_config.json:â€‡100%"
     }
    },
    "1a4bd0c6b90744058263256a92f85fb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc96f05b39514f2fa1f9556f3ff26722",
      "max": 25,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0e5455fcda034a7c96ff6ff473fdbd89",
      "value": 25
     }
    },
    "38b1f2749c2c491e8178ff727eeceb63": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3195f2f67e33454bbca7f19c9c5fbd0a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_be656821ff4748199a15d0dd4bd166dc",
      "value": "â€‡25.0/25.0â€‡[00:00&lt;00:00,â€‡1.90kB/s]"
     }
    },
    "351f39be330f45c69372637194c370af": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce713fc43e414c3b82b33a0c29a32db9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1f857b71c554182be6412cf74bc29c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc96f05b39514f2fa1f9556f3ff26722": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e5455fcda034a7c96ff6ff473fdbd89": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3195f2f67e33454bbca7f19c9c5fbd0a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be656821ff4748199a15d0dd4bd166dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b8c2e9cad9a4f6a945f94ea5cf531e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fdf8b0fa4e0e4d8da06aed72c9561f6a",
       "IPY_MODEL_d255dfb86b4d462e84883acad0cd1cbb",
       "IPY_MODEL_f75b8522cea143fc86eca83aab1b18bf"
      ],
      "layout": "IPY_MODEL_980e3c44abbd49cc852af65838efe594"
     }
    },
    "fdf8b0fa4e0e4d8da06aed72c9561f6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3f0f4e29b484597af7fbc7241740cc4",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_762d54fc44444633acef4634b8ecf849",
      "value": "sentencepiece.bpe.model:â€‡100%"
     }
    },
    "d255dfb86b4d462e84883acad0cd1cbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f476ceb4a404b55878fde3ab336c6d4",
      "max": 5069051,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8bb5fab06baf426081ad003ed56ecf3a",
      "value": 5069051
     }
    },
    "f75b8522cea143fc86eca83aab1b18bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5e47ee35b874ba6a7f435a1b1fd8c55",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_995fc8fed17e43dca6b6a8b634c063d8",
      "value": "â€‡5.07M/5.07Mâ€‡[00:00&lt;00:00,â€‡12.9MB/s]"
     }
    },
    "980e3c44abbd49cc852af65838efe594": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3f0f4e29b484597af7fbc7241740cc4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "762d54fc44444633acef4634b8ecf849": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f476ceb4a404b55878fde3ab336c6d4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bb5fab06baf426081ad003ed56ecf3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f5e47ee35b874ba6a7f435a1b1fd8c55": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "995fc8fed17e43dca6b6a8b634c063d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b778bb683adc4a96ae39a98c4f348b6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2d57fbffabdd4014b250141a3598c59c",
       "IPY_MODEL_26ca477c68084b938aed846905ab07ff",
       "IPY_MODEL_c6383433cf40443a8d94068c463d318c"
      ],
      "layout": "IPY_MODEL_a4ff9e79ab244fd1998b87ca3af31779"
     }
    },
    "2d57fbffabdd4014b250141a3598c59c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c752a7d2e29a40379165ecc78c95900b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_bff1276dee3141fb89a25b0260e98160",
      "value": "tokenizer.json:â€‡100%"
     }
    },
    "26ca477c68084b938aed846905ab07ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59feaf523a1c4f1d9e4a80a45989cafc",
      "max": 9096718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2384fda426f54d03a57d620a0ac3058f",
      "value": 9096718
     }
    },
    "c6383433cf40443a8d94068c463d318c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7be3b29483f8492c93ba4a6844f28e09",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a894ef720a464d97aa058d692986a2d2",
      "value": "â€‡9.10M/9.10Mâ€‡[00:00&lt;00:00,â€‡19.9MB/s]"
     }
    },
    "a4ff9e79ab244fd1998b87ca3af31779": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c752a7d2e29a40379165ecc78c95900b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bff1276dee3141fb89a25b0260e98160": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59feaf523a1c4f1d9e4a80a45989cafc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2384fda426f54d03a57d620a0ac3058f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7be3b29483f8492c93ba4a6844f28e09": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a894ef720a464d97aa058d692986a2d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "135ad4f73aa14752aef9f17395f141ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9119f811bbb74dafa56c716b9ac7ab7d",
       "IPY_MODEL_011ef2810e604f638e1b6409c5da3e12",
       "IPY_MODEL_0ef9fefd6cce471ba7b7c1f6388c22b0"
      ],
      "layout": "IPY_MODEL_8de229941d9349c7995e9784a3435cb5"
     }
    },
    "9119f811bbb74dafa56c716b9ac7ab7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_192b22f0af3f4a669f118d1146472898",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2685df12faf84d50abcbc0f8d831eec8",
      "value": "config.json:â€‡100%"
     }
    },
    "011ef2810e604f638e1b6409c5da3e12": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ac0975ac6834d8084337138df628829",
      "max": 615,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f8cdb01566444ebf91bff5b033bc8458",
      "value": 615
     }
    },
    "0ef9fefd6cce471ba7b7c1f6388c22b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cac20a4b199d4129aff696b17af4cc69",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f762c14507bf4af99c449bbb01992f24",
      "value": "â€‡615/615â€‡[00:00&lt;00:00,â€‡39.9kB/s]"
     }
    },
    "8de229941d9349c7995e9784a3435cb5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "192b22f0af3f4a669f118d1146472898": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2685df12faf84d50abcbc0f8d831eec8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ac0975ac6834d8084337138df628829": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8cdb01566444ebf91bff5b033bc8458": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cac20a4b199d4129aff696b17af4cc69": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f762c14507bf4af99c449bbb01992f24": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "05ca30b2b0a8417986902dcfb4be483d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_31a500ef0eb8433bb3c6adc06a28a68e",
       "IPY_MODEL_313cfcef43f14fdab8658988443938a5",
       "IPY_MODEL_8486b3704212407a9c87d5f548f7e36a"
      ],
      "layout": "IPY_MODEL_957f1247667249bca7f6397a16b69ce6"
     }
    },
    "31a500ef0eb8433bb3c6adc06a28a68e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfe113f5e0ad4162a76db9d6dc4d6e55",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e1892d6ebc714348bbc6794c17693ff6",
      "value": "model.safetensors:â€‡100%"
     }
    },
    "313cfcef43f14fdab8658988443938a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b49958cceae6434988bdff8808443546",
      "max": 1115567652,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c9bfd2dfbd1f4a46b24b6df332e95a3a",
      "value": 1115567652
     }
    },
    "8486b3704212407a9c87d5f548f7e36a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24535e1ab4944c3280b5a8e26cab0eae",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_3a0986e168f84358ba6c4b505a0eacbe",
      "value": "â€‡1.12G/1.12Gâ€‡[00:07&lt;00:00,â€‡70.5MB/s]"
     }
    },
    "957f1247667249bca7f6397a16b69ce6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfe113f5e0ad4162a76db9d6dc4d6e55": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1892d6ebc714348bbc6794c17693ff6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b49958cceae6434988bdff8808443546": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9bfd2dfbd1f4a46b24b6df332e95a3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "24535e1ab4944c3280b5a8e26cab0eae": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a0986e168f84358ba6c4b505a0eacbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eab432c4acb04f0b936a0bd5899f29bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5196cb64fb4f4bda97c6545dc9f65e81",
       "IPY_MODEL_ffee2c1d9ef8400095373494e131c6c5",
       "IPY_MODEL_380aec84eb1544b3999a732ec671c385"
      ],
      "layout": "IPY_MODEL_0202d562c6484b79970cc687f9818e53"
     }
    },
    "5196cb64fb4f4bda97c6545dc9f65e81": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_006ba9e9a1184ad0964b7cdbdade1ea3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e480823dfc724f928c40c05b3a9b6baa",
      "value": "tokenizer_config.json:â€‡100%"
     }
    },
    "ffee2c1d9ef8400095373494e131c6c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04f407a173584ca286d66bf25175dc08",
      "max": 25,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b763559aad484f3a99f3b9bb6e8faef8",
      "value": 25
     }
    },
    "380aec84eb1544b3999a732ec671c385": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45f8a1fc9f384dab945e2db2da9979b6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_be7fe67b4b1048909d17d3f42e3c4359",
      "value": "â€‡25.0/25.0â€‡[00:00&lt;00:00,â€‡1.92kB/s]"
     }
    },
    "0202d562c6484b79970cc687f9818e53": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "006ba9e9a1184ad0964b7cdbdade1ea3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e480823dfc724f928c40c05b3a9b6baa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "04f407a173584ca286d66bf25175dc08": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b763559aad484f3a99f3b9bb6e8faef8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "45f8a1fc9f384dab945e2db2da9979b6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be7fe67b4b1048909d17d3f42e3c4359": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7862d5423844ef297e6ea1556cc247f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f650743c65b04be584e5efb68ce6428b",
       "IPY_MODEL_9f4be734797d44659f1cc7fff4388c9a",
       "IPY_MODEL_34bfd5c375e94d2d9c4530c8abe142f2"
      ],
      "layout": "IPY_MODEL_17e38805f88548c4909bbb6f9309a62c"
     }
    },
    "f650743c65b04be584e5efb68ce6428b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4de0c773fe59434c8fa8f9ecef17da4d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b170865c91794352addec7549f7f7edb",
      "value": "config.json:â€‡100%"
     }
    },
    "9f4be734797d44659f1cc7fff4388c9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6de28b34e8374a72b5694e4478446cd3",
      "max": 482,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_89f10c4cfaa44424adc54328a62c2b88",
      "value": 482
     }
    },
    "34bfd5c375e94d2d9c4530c8abe142f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82ab2586529248f18555f8cdee44e3e1",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0f97fa14fcb04fc6baf86b3e8579a9c8",
      "value": "â€‡482/482â€‡[00:00&lt;00:00,â€‡35.1kB/s]"
     }
    },
    "17e38805f88548c4909bbb6f9309a62c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4de0c773fe59434c8fa8f9ecef17da4d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b170865c91794352addec7549f7f7edb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6de28b34e8374a72b5694e4478446cd3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89f10c4cfaa44424adc54328a62c2b88": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "82ab2586529248f18555f8cdee44e3e1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f97fa14fcb04fc6baf86b3e8579a9c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "413bab98de724648a1c0268851d353d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ac432e42ed5f4b398890a07dd8e0b25c",
       "IPY_MODEL_e3c47102172144f1a859bb52441695e1",
       "IPY_MODEL_d45e11c95e9a43faa1c67b98b5b54f4c"
      ],
      "layout": "IPY_MODEL_b77865c232734782ab7875a89365bad9"
     }
    },
    "ac432e42ed5f4b398890a07dd8e0b25c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbe55f668dcc4a36a3a937dec252e09c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_97739abf70e849b3afe47969d93d15ae",
      "value": "vocab.json:â€‡100%"
     }
    },
    "e3c47102172144f1a859bb52441695e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_152964a4a68a4bf5b30a7a43fc4a7a32",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_17c163e26dd74c81bcffc84a9e3ac304",
      "value": 898823
     }
    },
    "d45e11c95e9a43faa1c67b98b5b54f4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3a919fa9f5d414483373a4fd16ad551",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4c421abe451d432d9313d1ea1a0ce50d",
      "value": "â€‡899k/899kâ€‡[00:00&lt;00:00,â€‡42.3MB/s]"
     }
    },
    "b77865c232734782ab7875a89365bad9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbe55f668dcc4a36a3a937dec252e09c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97739abf70e849b3afe47969d93d15ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "152964a4a68a4bf5b30a7a43fc4a7a32": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17c163e26dd74c81bcffc84a9e3ac304": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3a919fa9f5d414483373a4fd16ad551": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c421abe451d432d9313d1ea1a0ce50d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ddea80f1bd44bf2a3f47532230554ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_72e832e88bba421f91f73387ad6fbf9f",
       "IPY_MODEL_554288cc81ff470abee2fcb950da5d87",
       "IPY_MODEL_8c62428b3635486986f5069a8625afa3"
      ],
      "layout": "IPY_MODEL_7d691f3bc547472097fbe59ef85f8583"
     }
    },
    "72e832e88bba421f91f73387ad6fbf9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59d5c60c520c4b00916e43bdaee592df",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_057987f750d74e439eacbc7ec5bb645b",
      "value": "merges.txt:â€‡100%"
     }
    },
    "554288cc81ff470abee2fcb950da5d87": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5977480e65fd418bbcaf96a9943e1c2e",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_01489587cb41469ca5905f08a0301aea",
      "value": 456318
     }
    },
    "8c62428b3635486986f5069a8625afa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_044bbc64e2e044cb809cba03e119d99d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_beed7bd115844affa65a31b0a00bf63b",
      "value": "â€‡456k/456kâ€‡[00:00&lt;00:00,â€‡29.2MB/s]"
     }
    },
    "7d691f3bc547472097fbe59ef85f8583": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59d5c60c520c4b00916e43bdaee592df": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "057987f750d74e439eacbc7ec5bb645b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5977480e65fd418bbcaf96a9943e1c2e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "01489587cb41469ca5905f08a0301aea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "044bbc64e2e044cb809cba03e119d99d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "beed7bd115844affa65a31b0a00bf63b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "853441bf4798409b96442626fcd898ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e0c1bcee7c845e998d2a313dd705dac",
       "IPY_MODEL_90ad93fb42bf40bf82f4aeeec2a1e35d",
       "IPY_MODEL_432395dc6aa04dbba7242d1994cf9138"
      ],
      "layout": "IPY_MODEL_9d0cc52f7c4c4cbdacaa98a0d354e44a"
     }
    },
    "1e0c1bcee7c845e998d2a313dd705dac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18c9681cdb844845ae2e61bfadf22ef1",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_48704318a284471ea88f61b111114080",
      "value": "tokenizer.json:â€‡100%"
     }
    },
    "90ad93fb42bf40bf82f4aeeec2a1e35d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5fa883f7aa2244ab8b839713c3a3038b",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14ca400510c845d9bef73c448f0bd7c1",
      "value": 1355863
     }
    },
    "432395dc6aa04dbba7242d1994cf9138": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee9e83493a8a41e5b2d71651d76f2503",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c59280b697fb4f78976b95d3bad62360",
      "value": "â€‡1.36M/1.36Mâ€‡[00:00&lt;00:00,â€‡15.1MB/s]"
     }
    },
    "9d0cc52f7c4c4cbdacaa98a0d354e44a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18c9681cdb844845ae2e61bfadf22ef1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48704318a284471ea88f61b111114080": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5fa883f7aa2244ab8b839713c3a3038b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14ca400510c845d9bef73c448f0bd7c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ee9e83493a8a41e5b2d71651d76f2503": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c59280b697fb4f78976b95d3bad62360": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "484385bb0f964adfbbb894fbe6a1a6cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e0a3e168a37a4799b5708e4134bf582e",
       "IPY_MODEL_43762be424e84b93a81effc525c22fd3",
       "IPY_MODEL_c0698dae2e8a45138fbc7ca8a3a83607"
      ],
      "layout": "IPY_MODEL_3529dee8539c41e4893ab21f06686fbe"
     }
    },
    "e0a3e168a37a4799b5708e4134bf582e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7bb879d313f543d7a28aea2a9867fc78",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_85a4db0019994a5daedc3eaaa5bd782b",
      "value": "model.safetensors:â€‡100%"
     }
    },
    "43762be424e84b93a81effc525c22fd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41c37905f551467d966c94e2ea10e858",
      "max": 1421700479,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d4c6e32402d74a84b6d6aea59884d59b",
      "value": 1421700479
     }
    },
    "c0698dae2e8a45138fbc7ca8a3a83607": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10310e310dcf49fca5088ad989f07cf6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_29c25c51eb604113b32e927b7f28429d",
      "value": "â€‡1.42G/1.42Gâ€‡[00:06&lt;00:00,â€‡213MB/s]"
     }
    },
    "3529dee8539c41e4893ab21f06686fbe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bb879d313f543d7a28aea2a9867fc78": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85a4db0019994a5daedc3eaaa5bd782b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41c37905f551467d966c94e2ea10e858": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4c6e32402d74a84b6d6aea59884d59b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "10310e310dcf49fca5088ad989f07cf6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29c25c51eb604113b32e927b7f28429d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ee3d1c1d052451ea261197cb3766d31": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_353d5d42749f4325afe266d69c7a9160",
       "IPY_MODEL_943f0f4b48af4b76b46f21f7630ca330",
       "IPY_MODEL_8f8dad2609c14532822d83980ec70d64"
      ],
      "layout": "IPY_MODEL_644dbea1ca3241f4813d84640e700b32"
     }
    },
    "353d5d42749f4325afe266d69c7a9160": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c33d5d56896c4cae96990509e97b7a82",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_457de2cbb68348358193375eef33ab54",
      "value": "Map:â€‡100%"
     }
    },
    "943f0f4b48af4b76b46f21f7630ca330": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f6c82407a32472c836bc7e13389b56d",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_919084c557ac4659834b49a8b287c99c",
      "value": 5000
     }
    },
    "8f8dad2609c14532822d83980ec70d64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c576e151a074222b1ff7d53f022b525",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9a8016d4af6e4ec8bb39e4509f7193b2",
      "value": "â€‡5000/5000â€‡[00:11&lt;00:00,â€‡408.21â€‡examples/s]"
     }
    },
    "644dbea1ca3241f4813d84640e700b32": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c33d5d56896c4cae96990509e97b7a82": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "457de2cbb68348358193375eef33ab54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f6c82407a32472c836bc7e13389b56d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "919084c557ac4659834b49a8b287c99c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3c576e151a074222b1ff7d53f022b525": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a8016d4af6e4ec8bb39e4509f7193b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "654ee06a022b415889fb58a8b2844f58": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_016a37c16b5b493883266dfa8752942c",
       "IPY_MODEL_cce0e4d65d564f7d86cc7698f0b8e256",
       "IPY_MODEL_23962af1e37c44119c5f3a758163cbec"
      ],
      "layout": "IPY_MODEL_66184be99e50474a803d4eb8773c66dd"
     }
    },
    "016a37c16b5b493883266dfa8752942c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_163db47e910a4fdb8bdc634426274b99",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_03bdb2056c884e7083ec677edc202678",
      "value": "Map:â€‡100%"
     }
    },
    "cce0e4d65d564f7d86cc7698f0b8e256": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8b61d810ec14f55b9863f472517dd30",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e8a765fdb96442cfb9aff168e831828b",
      "value": 500
     }
    },
    "23962af1e37c44119c5f3a758163cbec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3af560e00a394bf4888df621d65be6d5",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fe2dca9ff372452f84ed26ea75bcfca1",
      "value": "â€‡500/500â€‡[00:01&lt;00:00,â€‡456.96â€‡examples/s]"
     }
    },
    "66184be99e50474a803d4eb8773c66dd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "163db47e910a4fdb8bdc634426274b99": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03bdb2056c884e7083ec677edc202678": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8b61d810ec14f55b9863f472517dd30": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8a765fdb96442cfb9aff168e831828b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3af560e00a394bf4888df621d65be6d5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe2dca9ff372452f84ed26ea75bcfca1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
